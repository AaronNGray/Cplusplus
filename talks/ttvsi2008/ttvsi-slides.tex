\documentclass[compress,dvips,color=usenames,xcolor=dvipsnames]{beamer}

\usepackage{pstricks}
\usepackage{pst-tree}
\usepackage{pst-node}
\usepackage{proof}
\usepackage{alltt}

\newcommand{\ctt}[1]{\texttt{\structcol #1}}

%% Comment this out to get CM sans-serif
\usepackage{euler} % like default CM, but with different, nice maths font

%%
% Use this (Boadilla) if you don't like the right sidebar
\usetheme{Boadilla}
%\usetheme{Goettingen} %nice toc sidebar on right
%%
% Use default for ultra-minimalist look
%\usetheme{default}

\useinnertheme{circles}
\usefonttheme[onlymath]{serif}
\setbeamertemplate{navigation symbols}{}

\newcommand{\ints}{\ensuremath{\mathbb{Z}}}
\newcommand{\nats}{\ensuremath{\mathbb{N}}}
\newcommand{\reals}{\ensuremath{\mathbb{R}}}
\newcommand{\rats}{\ensuremath{\mathbb{Q}}}
\newcommand{\bools}{\ensuremath{\mathbb{B}}}
\newcommand{\cpp}{\mbox{C\hspace{-.1em}+\hspace{-.05em}+}}

\newcommand{\strong}[1]{{\structcol #1}}
\newcommand{\stronger}[1]{\emph{\structcol #1}}
\newcommand{\strongest}[1]{\textbf{\structcol #1}}

\title{Defining a \cpp{} Semantics}
\subtitle{Topics in Operational Confusion}
\author{Michael Norrish}
\institute[NICTA]{Canberra Research Lab., NICTA}
\titlegraphic{\includegraphics[width=0.2\textwidth]{Nicta_vert.eps}}
\date{26 March 2008}

\definecolor{nblue}{rgb}{0.0,0.310,0.490}
\newrgbcolor{nictablue}{0.0 0.310 0.490}
\setbeamercolor{math text}{fg=nictablue}
\newcommand{\structcol}{\usebeamercolor[fg]{structure}}

\begin{document}
\frame{\titlepage}
\section{Introduction}
\begin{frame}{Outline}\tableofcontents\end{frame}

\begin{frame}{Why? What? How?}
In 2005, UK company QinetiQ approached me to write a semantics
  for \cpp{}

\bigskip
Decided early on to avoid static semantics\\[1mm]
  \quad\quad\dots {\footnotesize which lets me ignore operator and function overloading}

\bigskip
Aim to build on my PhD's C semantics
\end{frame}

\begin{frame}{Result}

A deeper appreciation of \cpp's features.

\bigskip
Some 12\hspace{.1em}000 lines of HOL4 source code (mainly definitions).

\bigskip
A report (120pp) describing the above in English.

\bigskip
Legal back-and-forth squeezed time available: work was done in 9
increasingly intense months.

\end{frame}

\begin{frame}{The Good, the Bad and the Ugly}

A Conclusion in Advance:
\begin{itemize}
\item I produced a good picture of the dynamics of real \cpp
\item I didn't have time to fill in anything like all the details
\item I have no theorems to show you
\item The community wants to make \cpp{} even more complicated
\end{itemize}

\end{frame}

\section{The Structure of an Operational Semantics}
\begin{frame}{Outline}\tableofcontents[current]\end{frame}

\begin{frame}{\cpp{} Builds on C}

\cpp{} inherits a great deal from its ancestor C.

\bigskip
The basic semantics of expression evaluation, and interactions with
memory are taken from C essentially unchanged.

\bigskip
Control-flow is complicated by constructors, destructors and
exceptions, but there are no new statement forms in \cpp.

\bigskip My existing C semantics is a reasonable starting point.

\bigskip \footnotesize
Bonus:\\
\quad my 1998 HOL source upgrades to work with the HOL4 of 2007!

\end{frame}

\begin{frame}{Original C Semantics---Expressions}

Annoying Fact \#1:
\begin{quote}
   The evaluation of sub-expressions can happen in arbitrary order,
   possibly interleaving across sub-expressions.
\end{quote}

\bigskip
The natural expression of this are the small-step rules
\[
\infer{
  \langle e_1 \oplus e_2, \sigma_0\rangle \rightarrow_e
  \langle e_1' \oplus e_2, \sigma\rangle
}{
  \langle e_1, \sigma_0\rangle \rightarrow_e \langle e_1',\sigma\rangle
} \qquad
\infer{
  \langle e_1 \oplus e_2, \sigma_0\rangle \rightarrow_e
  \langle e_1 \oplus e_2', \sigma\rangle
}{
  \langle e_2, \sigma_0\rangle \rightarrow_e \langle e_2',\sigma\rangle
}
\]

\bigskip Apart from the fact that there is a shared state being
updated ($\sigma_0$ changes to $\sigma$), these are just like rules
for parallel reduction in CCS or the $\pi$-calculus.
\end{frame}

\begin{frame}{Original C Semantics---Statements}
  In 1995, it seemed natural to model statements in a big-step
  style.\\
  In 1995, I was young and na\"\i{}ve.

\bigskip
The big-step style makes handling scopes easy (the semantics itself
provides you with a free stack):
\[
\infer{
  \langle \textsf{Block}(s), \sigma_0\rangle
  \;\Downarrow_s\;
  \sigma[\textsf{vars} := \sigma_0.\textsf{vars}]
}{
  \langle s, \sigma_0\rangle \;\Downarrow_s\; \sigma
}
\]
where the states ($\sigma_0$, $\sigma$) contain a $\textsf{vars}$
component recording addresses and type information for variables in
scope.

\end{frame}

\begin{frame}{Original C Semantics---Function Calls}

  In a big-step style, function calls (which are expressions)
  naturally become ``atomic'':
  \[
  \infer{
    \langle \textsf{Fncall}(f,\vec{x}), \sigma_0 \rangle \rightarrow_e
    \langle \textsf{result}(\sigma),
    \sigma[\textsf{vars} := \sigma_0.\textsf{vars}]
    \rangle
  }{
    \langle \textsf{body}(f), \sigma'\rangle \;\Downarrow_s\; \sigma
  }
\]
where $\sigma'$ is like $\sigma_0$ but has extra variables
corresponding to $f$'s formal parameters bound to values from
$\vec{x}$.

\bigskip
``Atomic'' function calls are probably what C requires, and are
\strong{definitely} what \cpp{} requires.


\end{frame}

\begin{frame}{Original C Semantics---Statement Uglinesses}

  Expressions embedded inside statements require a call to the
  reflexive, transitive closure of the $\rightarrow_e$ relation:

\[
\infer{
  \langle\textsf{while}\;g \;\textsf{do}\;s,\sigma_0\rangle
  \;\Downarrow_s\;
  \sigma
}{
  \langle g, \sigma_0 \rangle \rightarrow_e^* \langle 0, \sigma\rangle
}
\]

\bigskip It is also impossible to model programs (like servers) that
deliberately loop.

\end{frame}

\begin{frame}{Making Statements Small-step}

If the rule-system doesn't give you a stack for free, you have to
model it explicitly:
\[
\infer{
  \langle \textsf{Block}(s), \sigma_0 \rangle \rightarrow_s
  \langle s, \sigma\rangle
}{
  \sigma =
  \sigma_0[\textsf{stk} := \sigma_0.\textsf{vars} :: \sigma_0.\textsf{stk}]
}
\]
\onslide<2->
But wait!  How will we know when to pop the stack?

\onslide<3->
\bigskip
One traditional approach to small-step statements is to use a
$\textsf{Skip}$ statement to mark the successful end of an
evaluation.

\bigskip But if $s$ is evaluated all the way to $\textsf{Skip}$,
how will we then know that there was a requirement to pop?

\end{frame}

\begin{frame}{Explicit Stacks}
Roughly the way I ended up doing it:
\[
\begin{array}{c}
\infer{
  \langle \textsf{Block}_\bot(s), \sigma_0 \rangle \rightarrow_s
  \langle \textsf{Block}_\top(s), \sigma\rangle
}{
  \sigma =
  \sigma_0[\textsf{stk} := \sigma_0.\textsf{vars} :: \sigma_0.\textsf{stk}]
}\\[5mm]
\infer{
  \langle \textsf{Block}_\top(s_0), \sigma_0\rangle \rightarrow_s
  \langle \textsf{Block}_\top(s), \sigma\rangle
}{
  \langle s_0,\sigma_0 \rangle \rightarrow_s \langle s, \sigma\rangle
}\\[5mm]
\infer{
  \langle\textsf{Block}_\top(\textsf{Skip}), \sigma\rangle
  \rightarrow_s
  \langle
     \textsf{Skip},
     \sigma[\textsf{stk} := t, \textsf{vars} := h]
  \rangle
}{\sigma.\textsf{stk} = h :: t}
\end{array}
\]

(Have to assume that all $\textsf{Block}$ forms are initially
$\textsf{Block}_\bot$.)

\bigskip
But what of ``atomic'' functions?
\end{frame}

\begin{frame}{Atomic Function Calls}

Scenario to avoid is having the expression
\[
f(x) + g(y)
\]
take a step inside $f$ followed by a step inside $g$.

\end{frame}

\begin{frame}{Atomic Function Calls with Continuations}

Drop the $s$ and $e$ subscripts on $\rightarrow$.

\medskip
Instead, have one arrow, and tags on the syntax $\textsf{St}$ and
$\textsf{Ex}$.

\bigskip
The revised rule for sub-expression evaluation on the left:
\[
\infer{
  \langle \textsf{Ex}(e_1 + e_2), \sigma_0 \rangle
  \rightarrow
  \langle \textsf{Ex}(e_1' + e_2), \sigma \rangle
}{
  \langle \textsf{Ex}(e_1), \sigma_0\rangle
  \rightarrow
  \langle \textsf{Ex}(e_1'), \sigma \rangle
}
\]

\bigskip
Function call rule:
\[
\infer{
  \langle \textsf{Ex}(\textsf{FnCall}(f,\vec{x})), \sigma_0\rangle
  \rightarrow
  \langle \textsf{St}(\textsf{body}(f), (\lambda x. x)), \sigma'\rangle
}{
  \mbox{$\sigma'$ has $f$'s parameters installed etc}
}
\]


\end{frame}

\begin{frame}{Atomic Function Calls with Continuations}
If a sub-expression involved a function call:
\[
\infer{
  \langle \textsf{Ex}(e_1 + e_2), \sigma_0 \rangle
  \rightarrow
  \langle \textsf{St}(s, (\lambda x.\, c(x) + e_2)), \sigma\rangle
}{
  \langle \textsf{Ex}(e_1), \sigma_0 \rangle
  \rightarrow
  \langle \textsf{St}(s, c), \sigma \rangle
}
\]
$c$ is also a ``context''.  $(\lambda x.\,c(x) + e_2)$ is a function
on syntax.

\bigskip
When a $\textsf{St}(s,c)$ form becomes
$\textsf{St}(\textsf{Return}(v),c)$, can pass the return value $v$ to
the containing expression by moving to $c(v)$.

\end{frame}

\begin{frame}{Teetering on the Knife-edge of Madness}
Getting even this far makes the whole enterprise feel disastrously
complicated.

\bigskip
Perhaps a ``pure continuation'' system is possible.\\
{\structcol
\strongest{Slogan:}
\parbox[t]{0.7\textwidth}{\itshape replace recursion within syntax with
  a ``list'' of steps still to perform.}}

\bigskip
For example,
\[
\infer{
  \langle \textsf{St}(\textsf{Block}(s), c), \sigma_0\rangle
  \rightarrow
  \langle \textsf{St}(s \;\textbf{;}\;\textsf{Pop}, c), \sigma\rangle
}{
  \sigma = \sigma_0[\textsf{stk} :=
       \sigma_0.\textsf{vars} :: \sigma_0.\textsf{stk}]
}
\]
($\textsf{Pop}$ is a new piece of ``syntax'' invented
specially)

\bigskip
\strongest{Against:}
\begin{itemize}
\item Handling interleaving of sub-expression evaluation looks
  complicated
\item The semantics grows ever harder for the reader to appreciate
\end{itemize}

\end{frame}

\section{Namespaces}
\begin{frame}{Outline}\tableofcontents[current]\end{frame}

\begin{frame}{Variable-tracking the Young and Na\"\i{}ve Way}

This works for C:
  \begin{itemize}
  \item Maintain \strong{global} and \strong{current} maps for
    variables
    \begin{itemize}
    \item these are maps from names to types and addresses
    \end{itemize}
  \item When entering a function, initialise \strong{current} with
    \strong{global} map
  \item When a variable is declared, update \strong{current}.
  \end{itemize}

\end{frame}

\begin{frame}[containsverbatim]{Namespaces}

Superficially, a \cpp{} namespace is just like an SML structure.

\bigskip
The task is to come up with a semantics that correctly handles both

\bigskip
\quad\begin{minipage}{0.4\textwidth}
\structcol
\begin{alltt}
val x = 3
structure S1 = struct
  val x = 4
  fun f y = x + y
end
\end{alltt}
\end{minipage}
and\hspace{1cm}
\begin{minipage}{0.4\textwidth}
\structcol
\begin{alltt}
val x = 3
structure S2 = struct
  fun f y = x + y
  val x = 4
end
\end{alltt}
\end{minipage}

\bigskip When ``entering'' \ctt{S2.f}, it is not correct to overlay
the global environment with that belonging to \ctt{S2}.

\end{frame}

\begin{frame}[containsverbatim]{Name Resolution as a Separate Phase}

  Before the dynamics can be allowed to fire, all names have to be
  resolved.

\bigskip
My semantics models this as a source-to-source transformation (a
partial function).

\bigskip
For example,
{\structcol
\begin{alltt}
   int x = 3;
   namespace ns1 \{
     int f(int n) \{ return n + x; \}
     int x = 4;
   \}
\end{alltt}}
needs to become (strictly, ill-formed)
{\structcol
\begin{alltt}
   int ::x = 3;
   int ::ns1::f(int n) \{ return n + ::x; \}
   int ::ns1::x = 4;
\end{alltt}}

\end{frame}

\begin{frame}[containsverbatim]{Namespaces Can be Extended Later}

Existing namespace contents take precedence when names are resolved:
{\structcol
\begin{alltt}
   namespace ns \{ int {\red{}x}; \}

   int x;

   namespace ns \{
     int f(int n) \{ return n + {\red{}x}; \}
   \}
\end{alltt}}

Similar things happen with classes and delayed definitions of member
functions.

\end{frame}

\begin{frame}[containsverbatim]{Classes Mean Complication}
Name resolution gets worse when classes are involved.

\bigskip
Most egregiously,
{\structcol
\begin{alltt}
   int x;

   class C \{
     int f(int n) \{ return n + {\red{}x}; \}
     int {\red{}x};
   \};
\end{alltt}
}
The \texttt{\red x} in \ctt{f} refers to the \texttt{\red x} below it.

\end{frame}

\begin{frame}{More Class-based Horror}

\begin{itemize}
\item Classes' member variables (\emph{eg} \texttt{\red x}) are not a global
  variables of fixed location
\begin{itemize}
\item they are names that must be dynamically
  evaluated with respect to a particular class instance/value.
\end{itemize}

\medskip
\item Classes can be nested within other classes
  \begin{itemize}
  \item but inner classes must be ordered so their names mask
    external classes of the same name
  \end{itemize}

\medskip
\item Classes themselves may be declared (`dynamically') within a
  function body
  \begin{itemize}
  \item but their free names must resolve statically
  \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{\cpp{} Name Resolution in Brief}

My semantics does not attempt
\begin{itemize}
\item to describe interactions with \ctt{friend} declarations;
\item to handle namespace renaming; nor
\item to model the equivalent of SML's \ctt{open}
\end{itemize}

\bigskip
Even then, it's quite complicated enough!

\bigskip
I did validate it on some examples though...


\end{frame}

\section{Building on the Shoulders of Giants}
\begin{frame}{Outline}\tableofcontents[current]\end{frame}

\subsection{Multiple Inheritance}
\begin{frame}{Multiple Inheritance Done Right}

Multiple inheritance is a scary, scary thing.

\bigskip
Stroustrup argues its case quite well in his books.

\bigskip
And luckily, \\[1em]
\quad\begin{minipage}{0.9\textwidth}
Daniel Wasserrab, Tobias Nipkow, Gregor Snelting and Frank Tip.\\
{\structcol An Operational Semantics and Type Safety Proof for
  Multiple Inheritance in \cpp{}.} In \emph{OOPSLA~'06}.
\end{minipage}\\[1em]
explains it beautifully.

\end{frame}

\begin{frame}{Multiple Inheritance}

A funny thing about OO-polymorphism:
\begin{itemize}
\item An object's \strong{dynamic} type never changes
\item An object's \strong{static} type changes all the time
\end{itemize}

\bigskip
The Wasserrab-method represents an object's types as a path through
an inheritance tree
\[
\langle \textit{most-derived}, \textit{its-parent}, \cdots,
\textit{least-derived}\rangle
\]
The \strong{dynamic} type is the first element of the path.\\
\medskip
The \strong{static} type is the last element of the path.

\bigskip
The whole path is necessary to handle multiple ancestors of the same
type.  Special magic also handles shared (= \ctt{virtual}) ancestors.

\end{frame}

\begin{frame}{Advantage of Theft Over Honest Toil}

  The \emph{OOPSLA} paper presents a simplified model (and proves
  theorems).

  \bigskip
  I adopted it wholesale, and then added complications.

  \bigskip\bigskip
  \strongest{Object Layout}\\[1em]
\begin{itemize}
\item  Class members occur inside classes, not on the end of pointers to
  the heap.

  \medskip
\item  Ancestor classes actually live inside derived classes.

  \medskip
\item  A class in memory may not occupy contiguous memory.

  \medskip
\item  Members of a class can have their address taken.
\end{itemize}

\end{frame}

\subsection{Templates}
\begin{frame}{Templates}

Templates are like SML functors on steroids:
\begin{itemize}
\item provide parametric polymorphism: \ctt{List<int>},
  \ctt{List<char *>} etc
\item can be recursive and higher-order
\item multiple ``functor'' definitions are chosen from depending on
  the specificity of the argument match
\item no signatures on arguments (makes debugging a pain!)
\end{itemize}

\bigskip
Template instantiation happens as part of ``compilation''.

\medskip
\quad\quad \textit{(How might a \cpp{} interpreter handle templates?)}

\bigskip
Here, the inspiration was

\medskip
\quad\begin{minipage}{0.9\textwidth}
Jeremy Siek and Walid Taha.\\
{\structcol A Semantic Analysis of \cpp{} Templates}.  In \emph{ECOOP}~2006.
\end{minipage}\\[1em]

\end{frame}

\begin{frame}[containsverbatim]{Interpreting Templates?}

Template instantiation must occur before dynamic behaviours are
executed:
{\structcol
\begin{alltt}
  template <class T> class List \{
    T item;
    List *next;
    static int node_count;
  \};
  template<class T> int List<T>::node_count = 0;

  int main(void)
  \{
    List<int> mylist;
    {\magenta// \textit{List<int>::node_count must exist and be}}
    {\magenta// \textit{initialised before main is entered}}
  \}
\end{alltt}}

\end{frame}

\begin{frame}[containsverbatim]{Templates as Name Resolution}

  Templates are instantiated on a need-to-use basis.

  \bigskip
  If a member function is never used for a particular instantiation, the
  code for that function mustn't be instantiated.

  \bigskip
  This makes a difference if the uninstantiated function calls a
  function on the argument type that doesn't exist.
{\structcol
\begin{alltt}
   int List<T>::foo(T *tptr)
   \{
     return tptr->bar();
     {\magenta// \textit{T had better be a class type with a member}}
     {\magenta// \textit{function with name bar}}
   \}
\end{alltt}}

\end{frame}

\begin{frame}{The Theoretically Interesting Bit About Templates}

\begin{itemize}
\item Template instantiation (of argument patterns) defines a weak partial
  order
  \begin{itemize}
  \item $\tau_1 \preceq \tau_2$ if $\exists \sigma. \;\;\sigma(\tau_1) = \tau_2$
  \end{itemize}

\bigskip
\item Validation Proof Opportunity!  Prove reflexivity, anti-symmetry
  and transitivity.
\begin{itemize}
\item A long, tedious proof.
\item Complicated by partiality of
  instantiation.
\item Made tedious by many syntactic forms of \cpp{}
  types.
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[containsverbatim]{Adding to Siek and Taha}

Siek and Taha don't handle template arguments to templates.

{\small\structcol
\begin{alltt}
  template <template <class, int> class U> struct X
  \{
    U<int,4> data;
  \};

  template <class T, int N> struct Array
  \{
    T array[N];
  \};

  int main()
  \{
    X<Array> foo;
    foo.data.array[0] = 3;
  \}
\end{alltt}}

\bigskip
Adding these requires a slightly different instantiation process.

\end{frame}

\section{Object Lifetimes and Exceptions---Painful Interactions}
\begin{frame}{Outline}\tableofcontents[current]\end{frame}
\begin{frame}{Object Lifetimes}
\begin{itemize}
\item User-supplied constructors are run when classes are created
  \begin{itemize}
  \item Constructors for sub-objects and ancestors also run
  \end{itemize}

\bigskip
\item User-supplied destructors are run on all objects in the \strong{reverse}
  order of their construction.
\end{itemize}

\end{frame}

\begin{frame}[containsverbatim]{Object Lifetime in a Normal Evaluation}

{\structcol
\begin{alltt}
   struct Base \{
     int x;
     Base(int y) : x(y) \{\}
   \};

   struct Member \{
     char c[100];
     Member(char d) \{ SomeClass s; ... \}
   \};

   struct Derived : public Base \{
     Member m;
     ...
     Derived(int i, char c) : Base(i), m(c) \{ ... \}
   \};
\end{alltt}}

\end{frame}

\defverbatim[colored]\myprog{%
\begin{center}
\begin{minipage}{0.45\textwidth}
\structcol\scriptsize
\begin{alltt}
struct Base \{
  int x;
  Base(int y) : x(y) \{\}
\};
\end{alltt}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\structcol\scriptsize
\begin{alltt}
struct Member \{
  char c[100];
  Member(char d) \{ SomeClass s; ... \}
\};
\end{alltt}
\end{minipage}\\[3ex]
\begin{minipage}{0.75\textwidth}
\scriptsize\structcol
\begin{alltt}
struct Derived : public Base \{
  Member m;
  ...
  Derived(int i, char c) : Base(i), m(c) \{ ... \}
\}
\end{alltt}
\end{minipage}
\end{center}
}

\begin{frame}
\frametitle{Object Lifetime in a Normal Evaluation}

\myprog

\begin{overprint}
\onslide<1>
In the block
{\structcol
\begin{alltt}
   \{ Derived d(3,'c'); ... \}
\end{alltt}}
the local variable \ctt{s} in constructor
\ctt{Member} will be destroyed after that constructor
finishes.

\bigskip At the end of the block, \ctt{Member}, \ctt{Base} and then
\ctt{Derived} will have their destructors called in that order.
\onslide<2> ...

\bigskip
At the end of the block, \ctt{Member}, \ctt{Base} and then
\ctt{Derived} will have their destructors called in that order.

\bigskip
This is easy enough to implement: part of the stack-frame for a block
records a stack of objects as they are created.
\end{overprint}
\end{frame}

\begin{frame}[fragile]
\frametitle{Exceptions}

Similar to SML exceptions.

\bigskip
Exceptions can carry data of any type.

\bigskip
Handlers can match on the type of the carried data. Thus:

{\structcol
\begin{alltt}
  int main(void)
  \{
    try \{ throw 3; \}
    catch (int x) \{ return x; \}
    catch (...) \{ return -1; \}
    return 0;
  \}
\end{alltt}}

(Not that using \ctt{int} as the exception type is good practice.)

\end{frame}

\begin{frame}{Modelling Exceptions}

Exceptions seem easy to model:

\bigskip
\begin{itemize}
\item C semantics handled \ctt{break} and \ctt{return}, and
  exceptions' effect on control-flow is similar

\bigskip
\item \cpp{} semantics already carries types of everything around, so
  dynamically examining types in handlers is straightforward
\end{itemize}

\end{frame}

\begin{frame}{Exceptions Cause Pain}
\myprog

If the body of \ctt{Member} raises an exception:
\begin{enumerate}
\item At the end of \ctt{Member}, \ctt{s} has its destructor called
\begin{itemize}
  \item this is the usual time for its destruction
\end{itemize}
\item Body of \ctt{Derived} is skipped
\item Ancestral \ctt{Base} has its destructor called
  \begin{itemize}
  \item this is \stronger{not} \ctt{Base}'s scheduled time for destruction
  \end{itemize}
\end{enumerate}

\end{frame}



\begin{frame}{Proofs? Theorems?  Validation!?}

Yes.

\bigskip
But they're not very interesting:
\begin{itemize}
\item ground evaluation of name resolution on a simple program
\item a number of small sanity check theorems
  \begin{itemize}
  \item \emph{eg}. the ``what is this type's alignment'' relation is
    deterministic
  \item converting an l-value to its ``value'' is deterministic and
    doesn't change the state
  \end{itemize}
  \item the template pattern subsumption relation is a partial order
\end{itemize}
\end{frame}

\begin{frame}{What's the Take-home Message?}

It's possible to write a big, complicated operational semantics that
purports to describe aspects of big complicated languages like \cpp{}.

\onslide<2->
\bigskip
Validation of big, complicated semantics is a major issue; I've barely
scraped the surface of what might be done.

\onslide<3->
\bigskip
It's possible to capture the ghastlinesses that ``pramatists'' come
up with.  
\begin{itemize}
\item Given time and smarts, it's possible to do this moderately
elegantly. 
\end{itemize}

\onslide<4->
\bigskip
There may be interesting theorems to be proved about aspects of
\cpp{}. 
\begin{itemize}
\item demonstrated already by the work I drew on
\item may be possible to say something smart about object lifetimes
\end{itemize}
  

\end{frame}




\end{document}
