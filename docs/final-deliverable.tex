\documentclass[11pt]{article}

\usepackage{charter}
\usepackage{alltt}
\usepackage{url}
\usepackage{proof}
\usepackage{amsfonts}
\usepackage{underscore}
\usepackage{pstricks}
\usepackage{pst-node}
\usepackage{makeidx}

\include{cpp-macros}

\newcommand{\ie}{\emph{i.e.}}
\newcommand{\eg}{\emph{e.g.}}
\newcommand{\naive}{na\"\i{}ve}
\newcommand{\lbr}{\texttt{\{}}
\newcommand{\rbr}{\texttt{\}}}
\newcommand{\HOLfile}[1]{HOL:\texttt{#1}}

\title{A Formal Semantics for \cpp}
\author{Michael Norrish\thanks{
  This work has been performed under funding from QinetiQ's Systems
  Assurance Group under the UK MOD Output 3a research project entitled
  \emph{Robust Languages}.}\\{\small \texttt{Michael.Norrish@nicta.com.au}}}
\date{}

\makeindex

\begin{document}
\maketitle

\tableofcontents
\listoffigures

\section{Introduction}

This document presents the substance of the mechanised \cpp{}
semantics that is developed in the accompanying HOL source files (see
Appendix~\ref{sec:sources}).  Those files sum to over 12$\,$000 lines;
this document tries to cover both the important parts in detail, and
to describe the less important parts at a high level.

The HOL mechanisation itself is necessarily the only \emph{formal}
part of the deliverable.  This document quotes from the sources
liberally, and aims to make these relatively easily understood by
accompanying HOL extracts with English prose.  Where prose and rule
appear to conflict, this will almost certainly reflect a problem with
the prose and not the rule.  The rule has been type-checked, and in
some cases, will have also been validated to some extent.  (See
Section~\ref{sec:validation} for more on validation.)

In addition to the ISO~Standard itself~\cite{cpp-standard-iso14882},
the report draws on a number of other sources.  The annotated
bibliography in the appendix describes all of these.

\vspace{1ex}
\noindent This document supercedes all previous deliverables.

\subsection{Reading  HOL Source Code}

This report contains a large number of extracts from the HOL source
code found in the \texttt{holsrcs} directory of the deliverable.
HOL's Description manual~\cite{HOLdescription} has full details for
the following, which is a brief summary of HOL syntax and semantics.

Where quotations are made from underlying HOL sources, the origin of
the quotation will be identified using the form \HOLfile{thyname}.
The source code for theory \texttt{thyname} is available in the file
\begin{alltt}
   holsrcs/thynameScript.sml
\end{alltt}
When compiled, the corresponding theory will have a readable
signature in the file
\begin{alltt}
   holsrcs/thynameTheory.sig
\end{alltt}


\subsubsection{HOL Syntax}

HOL is a powerful logical language, equipped with the usual features
of predicate logic (quantifiers such as $\forall$ and propositional
connectives such as $\lor$ and $\Rightarrow$), as well as a rich,
typed term language.

\paragraph{Numbers} HOL has three different numeric types: natural
numbers~(\texttt{num}), integers~(\texttt{int}) and real
numbers~(\texttt{real}).  The latter are not used in the C++
formalisation.  All types support the standard arithmetic operators,
such as addition~(\texttt{+}), subtraction~(\texttt{-}) and
multiplication~(\texttt{*}).  In addition, HOL supports types of
fixed-width memory ``words''.

\paragraph{Pairs} The type of pairs of $\sigma$s and $\tau$s is
written \texttt{$\sigma$~\#~$\tau$}.  Pair values are written inside
parentheses, with components separated by commas, \eg, \texttt{(1,4)}.
\index{FST@\texttt{FST}} The function \texttt{FST} returns the first
component of a tuple, and \index{SND@\texttt{SND}}\texttt{SND} returns
the second.

\paragraph{Lists} The type of lists of elements drawn from a type
$\alpha$ is written $\alpha\;\texttt{list}$. Lists can either be empty
(\texttt{[]}) or the result of ``cons''-ing an element onto the front
of an existing list.  The list consisting of element \texttt{h}
followed by list \texttt{t} is written \texttt{h::t}. A literal list
of a fixed number of elements can also be written between square
brackets, with successive elements separated by semi-colons.  Thus,
\begin{alltt}
   [1; 2; 3]
\end{alltt}
is an alternative to writing
\begin{alltt}
   1 :: 2 :: 3 :: []
\end{alltt}
Lists come equipped with various standard functional language
operations such as \index{EL (list operation)@\texttt{EL} (list
  operation)}%
\index{CONS (list operation)@\texttt{CONS} (list operation)}%
\index{FOLDL (list operation)@\texttt{FOLDL} (list operation)}%
\index{++ (list operation)@\texttt{++} (list operation)}%
\index{ZIP (list operation)@\texttt{ZIP} (list operation)}%
\index{LAST (list operation)@\texttt{LAST} (list operation)}%
\index{MAP (list operation)@\texttt{MAP} (list operation)}%
\index{MEM (list operation)@\texttt{MEM} (list operation)}%
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
   ++    : 'a list -> 'a list -> 'a list
   CONS  : 'a -> 'a list -> 'a list
   EL    : num -> 'a list -> 'a
   FOLDL : ('a -> 'b -> 'a) -> 'a -> 'b list -> 'a
   LAST  : 'a list -> 'a
   MAP   : ('a -> 'b) -> 'a list -> 'b list
   MEM   : 'a -> 'a list -> bool
   ZIP   : 'a list -> 'b list -> ('a # 'b) list
\end{alltt}
\end{minipage}
\end{center}
The list append operation (\texttt{++}) is written as an infix.

\paragraph{Options} The option type has two constructors
\index{NONE (option constructor)@\texttt{NONE} (option constructor)}%
\index{SOME (option constructor)@\texttt{SOME} (option constructor)}%
\begin{verbatim}
   NONE : 'a option
   SOME : 'a -> 'a option
\end{verbatim}
allowing one to encode a type that represents all of the values of an
existing type, and an extra value, usually representing failure or
absence.  The %
\index{THE (HOL function)@\texttt{THE} (HOL function)}%
\texttt{THE} function reverses the action of \texttt{SOME}.  If
applied to \texttt{NONE}, its value is unspecified.

\paragraph{Finite Maps}\index{finite maps}
The finite map is a form of function where the domain is guaranteed to
be finite.  The type of finite maps from $\sigma$ to $\tau$ is written
\texttt{:$\sigma$~|->~$\tau$}.  The HOL syntax for the application of
a finite map \texttt{fm} to an element \texttt{x}, is \texttt{fm~'~x},
with an apostrophe separating function and argument.  (Note that the
result of the application is unspecified if the argument is not in the
map's domain.)

The empty finite map (one with no domain) is \texttt{FEMPTY}, and
updating a map \texttt{fm} so that its value at \texttt{k} is
\texttt{v} (ignoring whether or not \texttt{fm} may have already had a
value for \texttt{k}), is written \texttt{fm |+ (k,v)}.  The function
\texttt{FDOM} returns the domain of a finite map.\index{FDOM@\texttt{FDOM}}

\paragraph{Records}\index{records (in HOL)}
Record literals are written as a sequence of assignment to field-names
in between ASCII angle brackets, thus:
\begin{verbatim}
   <| fld1 := 3; fld2 := 5; fld3 := (F,[]) |>
\end{verbatim}
New record values can be constructed from old ones with the
\texttt{with} keyword.  For example
\begin{verbatim}
   rec with <| fld2 := 10; fld6 := T |>
\end{verbatim}
is a record value that is everywhere identical to \texttt{rec} except
that its fields \texttt{fld2} and \texttt{fld6} have different
values.

When updating records, in addition to the assignment
syntax~(\texttt{:=}), one can also use \texttt{updated_by}, which
allows a function to be applied to the old value of the field.  So,
\begin{verbatim}
   rec with <| fld2 updated_by SUC; fld6 := T |>
\end{verbatim}
is a record value everywhere the same as \texttt{rec}, except that its
\texttt{fld6} is true, and its \texttt{fld2} is one bigger.

\subsubsection{Definitions in HOL}\index{HOL definitions|(}
There are three main forms of definition used in HOL: definition of
new algebraic types, definition of functions specified equationally,
and inductive definition of relations.

\paragraph{Defining Types}
Algebraic types naturally correspond to the syntax of formal
languages.  They are defined in a style that resembles
\texttt{datatype} declarations in functional languages such as Haskell
or SML.  For example, the definition of the type for a small language
of arithmetic expressions might be:
\begin{alltt}
   ArithExp = Number of int
            | Variable of string
            | Plus of ArithExp # ArithExp
            | Times of ArithExp # ArithExp
            | FnCall of string # ArithExp list
\end{alltt}
In HOL's data type definitions, the string to the left of the
\texttt{=} (\texttt{ArithExp} here) is the name of the new type.
After the equals sign, there is then a list of different possible
forms for the values inhabiting the type.  In the example, we assert
that expressions come in five different forms.  Each form is
optionally accompanied by data (following the \texttt{of} keyword).
If the arithmetic expression is an addition, for example, then it
consists of (recursively) two arithmetic expressions representing the
left and right arguments (the \texttt{\#} symbol is the type operator
for Cartesian products).

As a result of a definition like the above, the new type is
established, and five new constants (known as the new type's
``constructors'') are defined, with types
\begin{alltt}
   Number   : int -> ArithExp
   Variable : string -> ArithExp
   Plus     : ArithExp # ArithExp -> ArithExp
   Times    : ArithExp # ArithExp -> ArithExp
   FnCall   : string # ArithExp list -> ArithExp
\end{alltt}
Thus, the new type \texttt{ArithExp} is inhabited by values such as
\texttt{Number~5}, \texttt{Variable~"i"}, and more complicatedly:
\begin{alltt}
   Plus (Number "3", FnCall ("sin", [Variable "pi"]))
\end{alltt}

\vspace{1ex}
\noindent Finally, in order to support the common, ``curried'' style of
functional programming, one can define multiple arguments to
constructors by separating them with the special symbol
\texttt{=>}. If one were to write
\begin{alltt}
   SimpExp = Number of int
           | Plus of SimpExp => SimpExp
\end{alltt}
the new type \texttt{SimpExp}'s second constructor \texttt{Plus} would
have type
\begin{alltt}
   SimpExp -> SimpExp -> SimpExp
\end{alltt}
So, rather than taking its two arguments as a pair (as in the first
\texttt{ArithExp} example above), the \texttt{Plus} constructor for
\texttt{SimpExp} takes its two arguments one after the other.

\paragraph{Defining Functions}
In HOL, definitions of functions look similar to function definitions
in functional programming languages, with features such as
pattern-matching and recursion common.  For example, the following is
the definition of a factorial function
\begin{alltt}
   (FACT 0 = 1) \(\land\)
   (FACT (SUC n) = SUC n * FACT n)
\end{alltt}
The individual equations are separated by conjunction symbols because
the text of the definition becomes the statement of the theorem
characterising the behaviour of the new constant.  (If the recursion
is not well-founded, or if there is some other error in the quoted
text, then HOL does not allow the definition to proceed, and no
theorem is produced.)

\paragraph{Defining Relations} Inductive relations allow the
definition of systems of rules, common in the definitions of
operational semantics.  For example, one might write a big-step rule
for applicative order reduction in the $\lambda$-calculus as
\[
\infer{\Gamma \vdash M\,N\;\Downarrow \;v}{\Gamma \vdash M \;\Downarrow\; (\lambda x. M_0) &
  \Gamma \vdash N \;\Downarrow\;v_0 & (x\mapsto v_0),\Gamma \vdash M_0 \;\Downarrow\; v}
\]
This should be read as stating that an application $M\,N$ reduces to a
value $v$ if $M$ reduces to an abstraction ($\lambda x. M_0$), if $N$
reduces to some value $v_0$, and if the body $M_0$ reduces to $v$,
while the bound variable $x$ is linked to $v_0$.

The same rule might be presented in HOL syntax as
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
     apeval G M (LAM x M0) \(\land\)
     apeval G N v0 \(\land\)
     apeval ((x,v0) :: G) M0 v
   \(\Rightarrow\)
     apeval G (APP M N) v
\end{alltt}
\end{minipage}
\end{center}
The use of the conjunction and implication symbols makes the
propositional structure of the rule explicit.  Also, the relation
being defined is always the first symbol (\texttt{apeval} here) of the
conclusion.

Note also how the \texttt{apeval} constant of this example is applied
to its three arguments in ``curried'' $\lambda$-calculus or
functional-programming style.  This is in contrast with ``standard''
mathematical style, where functions are typically applied to arguments
in parentheses separated by commas, as in $f(x,y,z)$.  Such tuples do
also appear in the model, but sequences of function or predicate
arguments are often just separated by whitespace, as above.

\index{HOL definitions|)}


\subsection{Understanding \cpp in Three Phases}

When we attempt to understand the meaning of a \cpp{} source file (or
``translation unit'' to use the standardese), this task is best broken
down into three phases.

When we begin, we have a sequence of parsed \emph{external
  declarations} (see the Standard's formal grammar in its Annex A:
Grammar Summary).  Throughout this semantics, we assume that this
sequence is well-formed syntactically, that some trusted compiler has
already checked the sources for syntactic errors of the sort compilers
can detect.  For example, this means that we assume that there are no
variables left undeclared, and that all the various expressions are
well-typed.  This is a not inconsiderable simplification of the basic
task, but it does seem fair to claim that such analysis is not as
interesting a problem.  This abstract syntax, as consumed and
manipulated by the semantic model, is described in
Section~\ref{sec:basic-types} below.

The first phase of understanding, or of ascribing meaning, is to do
what I refer to as ``name resolution''.  In this phase, bare names are
resolved into fully-qualified names wherever possible.  For example,
this phase turns a program such as
\begin{verbatim}
   int x;
   int f(int i) { return i + x; }
\end{verbatim}
into
\begin{verbatim}
   int ::x;
   int ::f(int i) { return i + ::x; }
\end{verbatim}
where the names declared in the top, global namespace (\texttt{x} and
\texttt{f}) have been replaced with unambiguous versions of their
names wherever they occur.  Note that the result is no longer valid
\cpp{} (it is illegal to use the explicit qualification in names being
defined), but the next phase of understanding does not expect valid
\cpp{} in any case.  In the presence of hierarchical namespaces, and
class namespaces inheriting from bases, Phase~1 is not entirely
trivial.  It is described in some detail in Section~\ref{sec:phase1}.

The second phase of the semantics is to deal with templates.  The
input to template resolution is a translation unit with most of its
names resolved, and where the translation unit consists of both
``ground'' (non-template) declarations or definitions, and template
declarations or definitions.  The ground definitions may refer to
various template classes or functions.  If so, the appropriate
template instantiations need to be made, producing fresh ground
declarations.  These new declarations need to first have their names
resolved (requiring a nested ``call'' to Phase~1), and may in turn
require more template instantiations.  In fact, template instantiation
may never terminate.  Templates are further described in
Section~\ref{sec:templates}.

The final phase of the semantics is execution, or ``dynamics''.  In
this phase, top-level declarations are executed, resulting in the
dynamic initialisation of variables, which can in turn result in the
execution of source-code.  The exact order of evaluation of external
declarations is allowed to vary
(see~\cite[\S3.6.2]{cpp-standard-iso14882}), and may or may not
precede the execution of a program's \texttt{main} function.  The
rules governing dynamic behaviour specify what is to occur when
execution does occur, but do not specify how various executions are
knitted together.  All of the model's dynamic rules are presented in
Section~\ref{sec:phase3}.

\section{\cpp's Basic Types}
\label{sec:basic-types}

The most fundamental types in the semantics are those expressing the
basic abstract syntax of \cpp{}.  The declaration of \cpp{} types is
(from \HOLfile{types})
\begin{verbatim}
   CPP_Type =
     Void |
     BChar (* "Basic char" *) |
     Bool |
     Unsigned of basic_integral_type |
     Signed of basic_integral_type |
     Class of CPP_ID  |
     Float |
     Double |
     LDouble |
     Ptr of CPP_Type |
     MPtr of CPP_ID => CPP_Type | (* member pointer *)
     Ref of CPP_Type |
     Array of CPP_Type => num |
     Function of CPP_Type => CPP_Type list |
     Const of CPP_Type |
     TypeID of CPP_ID
\end{verbatim}
This definition allows recursion: for example, a \cpp{} type can be a
pointer to another \cpp{} type (using the \texttt{Ptr}
constructor).  In this simple prefix notation, the type of an
``array of ten pointers to \texttt{int}'', is written
\begin{verbatim}
   Array (Ptr (Signed Int)) 10
\end{verbatim}
(\texttt{Int} is one of the four possible values inhabiting
\texttt{basic_integral_type}, along with \texttt{Char}, \texttt{Short}
and \texttt{Long}.)

Similarly, a function taking two \texttt{int}s and returning a
\texttt{char} is written
\begin{verbatim}
   Function BChar [Signed Int; Signed Int]
\end{verbatim}

\paragraph{Identifiers}
In the presence of templates, identifiers can take on forms such as
\begin{verbatim}
   List<int>::fldname
\end{verbatim}

This means that identifiers are a type in the model that must in turn
be mutually recursive with the type of types.  In the example above,
the type \texttt{int} appears within an identifier.  It is also clear
that identifiers occur within types, because identifiers are the basis
for naming and referring to class types.

Therefore, we must add the following to the above definition of \cpp{}
types:
\index{IDComp@\texttt{IDComp}}
\index{IDConstant@\texttt{IDConstant}}
\begin{verbatim}
   CPP_ID = IDConstant of bool => IDComp list => IDComp ;

   IDComp = IDTempCall of string => TemplateArg list
          | IDName of string
\end{verbatim}
In other words, values of identifier type are constructed by applying
the function \texttt{IDConstant} to three arguments: a boolean
indicating whether or not this is an ``absolute'' identifier
(represented in the concrete syntax by prefixing it with \texttt{::});
a list of ID components and one final ID component.

An ID component might either be a simple name, or can be a simple name
applied to multiple ``template arguments''.  There are three sorts of
template arguments: types, templates and values; giving
\begin{verbatim}
   TemplateArg = TType of CPP_Type
               | TTemp of CPP_ID
               | TVal of TemplateValueArg
\end{verbatim}
So, the type above would be represented as
\begin{verbatim}
   IDConstant F [IDTempCall "List" [TType (Signed Int)]]
                (IDName "fldname")
\end{verbatim}


\paragraph{Expressions and Statements}

Expressions are specified in exactly the same way as types, with
constructors such as \texttt{Assign} (assignment), \texttt{Deref} (the
\texttt{*} or pointer dereferencing operator) and \texttt{New}.  The
abstract syntax need not be a perfect match for the concrete syntax.
For example, there is an \texttt{ExpTypeID} operator (for
\texttt{typeid} applied to an expression argument), and
\texttt{TyTypeID} for when \texttt{typeid} is applied to a type.

The rules presented in Section~\ref{sec:phase3} cover the dynamic
behaviours various expression forms.  The HOL declaration is in the
file \HOLfile{expressions}.

Statements are similar again (see \HOLfile{statements}), with
constructors such as \texttt{CIf}, \texttt{Ret} and \texttt{Block}.
However, the type here is rather more complicated because statements
not only include expressions but must be mutually recursive with other
syntactic categories: variable and class declarations, ``class
entries'' (those things that can appear with a \texttt{class}
declaration), and initializers (those things that appear in variable
declarations that also explicitly initialise the variable).

\subsection{Bytes \& Memory}
\label{sec:bytes-memory-states}

After specifying abstract syntax for programs, one must continue by
describing the state that is manipulated by the action of those
programs.   In fact, each of the three phases manipulates slightly
different states, and each will be detailed in the relevant sections.
However, there are a few general observations possible.

\paragraph{Bytes} The fundamental type in the dynamic semantics is
that of the byte.  (See \HOLfile{memory} for more on these matters.)
Using HOL4's support for $n$-bit words, it is possible to define a
type called \texttt{byte}, which is a word containing
\texttt{CHAR_BIT} many bits, where \texttt{CHAR_BIT} is a natural
number under-specified to be at least 8, but possibly more.

It is then possible to define representation and valuation functions
between the HOL types of integer and byte.  These functions are
partial, meaning that they can either return \texttt{NONE} to indicate
failure, or $\texttt{SOME}(v)$ to indicate the successful return of
the value $v$.  These functions capture, again in a suitably
underspecified way, how bytes can be translated into values, and how
those same values can be converted back into bytes.  For example, we
know that for the unsigned \texttt{char} type, all values in the range
$0$ up to $2^{\texttt{CHAR_BIT}}-1$ must have corresponding bit
patterns.  For types other than \texttt{char}, the use of functions in
both directions is perhaps not quite under-specified enough: it
assumes that if an implementation can represent a value at all, then
it will always represent a value in the same way.  For example, this
reduces, though does not eliminate, the opportunities for signed
zeroes to occur.

Each primitive type is given a fixed size (in numbers of bytes).  This
is done in an underspecified way so that again, one can only conclude
that there are enough bytes in an \texttt{int} value to represent the
mandated range of values (from $-(2^{16} - 1)$ up to $2^{16} - 1$).

In the model to come, the function most used is
\begin{verbatim}
   INT_VAL : CPP_Type -> byte list -> int option
\end{verbatim}
which attempts to interpret the given list of bytes as a value of the
provided type, and returns its integer value, if it has one.  The
function might return \texttt{NONE} if the list of bytes is of the
wrong length, or if it is not a valid bit pattern for the type.  (The
latter might occur if the required type is a pointer value and the
hardware checks such values for validity before even allowing them
into address registers.)

\paragraph{Memory}
Memory is represented as a function from natural numbers to bytes.
The address 0 is reserved as the representation for the null pointer.
Strictly speaking, one might imagine that the map should be from some
machine word (an array of four bytes, say) to bytes.  However, even
with the domain of the map being $\mathbb{N}$, any given program will
only be able to address a finite amount of memory because it will only
be able to generate a finite number of addresses.  (All pointer types
have a fixed, finite number of bytes making up their representations.)

\subsection{Hierarchical Environments}
\label{sec:hierarchical-environments}

To reflect the hierarchical nesting of namespaces and classes, the
model uses a type of hierarchical environments, giving maps from
structured names into information about those names.  These maps are
instances of a type called \texttt{fmaptree} (see \HOLfile{fmaptree}).
This type has one constructor:
\begin{verbatim}
   FTNode : 'value -> ('key |-> ('key,'value)fmaptree) ->
            ('key,'value)fmaptree
\end{verbatim}
The \texttt{|->} type operator returns finite maps, so
\texttt{FTNode} takes a value, and a finite map from keys to more
\texttt{fmaptree}s, and returns a new \texttt{fmaptree}.  This type
rather resembles the trie data structure.  Like lists and other
``container'' types, the \texttt{fmaptree} is polymorphic, both in the
type of keys, and the type of values.

The operation to lookup up the sub-tree at a particular key list position
is \texttt{apply_path}:
\begin{alltt}
  (apply_path [] ft = SOME ft) \(\land\)
  (apply_path (h::t) ft = if h \(\in\) FDOM (map ft) then
                             apply_path t (map ft ' h)
                          else NONE)

\end{alltt}

The functions \texttt{item} and \texttt{map} are also heavily used,
and return the value, and sub-trees of an \texttt{FTNode}
respectively.
\begin{verbatim}
   item (FTNode i fm) = i

   map (FTNode i fm) = fm
\end{verbatim}

In the particular context of \cpp{}, there are two sorts of
environment (see \HOLfile{environments}).  The first maps from
namespace components into values of type \texttt{envinfo}.  An
\texttt{envinfo} is a record of three components, each of which are
finite-maps.
\begin{verbatim}
   envinfo = <|
     varmap   : string |-> addr # CPP_ID # CPP_ID list ;
     typemap  : IDComp |-> CPP_Type ;
     classenv : IDComp |-> class_env
   |>
\end{verbatim}
The \texttt{varmap} is a map from variable names to their l-value
information.\footnote{It should be clear that an address is necessary
  to specify an object's identity.  The additional identifier and
  identifier list are used to store the dynamic information about
  class types that is necessary to implement polymorphism.  For more
  on this, see Section~\ref{sec:multiple-inheritance} below.}  The
domain of this map can be strings because only functions can have
template-structured names, and these do not live in memory in the same
way as objects.  The \texttt{typemap} maps ID components to types,
giving static information both for objects and functions.  The
\texttt{classenv} field gives information about any classes that might
be declared at this level of the namespace hierarchy.

The \texttt{environment} type is then an abbreviation for a
\begin{verbatim}
   (string, envinfo) fmaptree
\end{verbatim}
At each point in the namespace tree, indexed by a path (or list) of
names, there is an \texttt{envinfo} value about the objects and
classes stored in that scope.

The \texttt{class_env} type is an abbreviation for another sort of
\texttt{fmaptree}
\begin{verbatim}
   (IDComp, class_envinfo) fmaptree
\end{verbatim}
In other words, a \texttt{class_env} is a structured map, where the
components can be full-blown \texttt{IDComp} values.  This is
necessary because classes can be constructed from template calls
(whereas namespaces are necessarily identified by just strings).

The information attached to each node of a \texttt{class_env} is the
following record type:
\begin{verbatim}
   class_envinfo = <|
      (* ironically, the location of the static variables is
         only available dynamically, as classes are
         initialised *)
      statvars : string |-> addr # CPP_ID # CPP_ID list ;
      info     : state_class_info ;
      refs     : string # addr |-> addr # CPP_ID # CPP_ID list
   |>
\end{verbatim}
The \texttt{statvars} field records the same information for a class's
static variables as the \texttt{envinfo} records for normal
variables.  The \texttt{refs} field records per-class information
about reference members.  Both of these fields are only used
dynamically (as static variables are declared, and as new classes are
constructed respectively).  Finally, the \texttt{info} field records
the static information associated with a class.



\section{Phase 1: Name Resolution}
\label{sec:phase1}

Name resolution must occur in a separate phase before dynamic
evaluation, and must rewrite declarations so that their name
dependencies are made explicit.  This is exemplified by the program in
Figure~\ref{fig:name-res-separate-phase}, where the name \texttt{x}
that occurs in the function \texttt{ns1::f} must be a reference to the
\texttt{x} that occurs in the outermost, global namespace.  A \naive{}
execution of the sequence of declarations in the program would put the
global \texttt{x} into its namespace, and then enter namespace
\texttt{ns1}, where it would first declare the function \texttt{f},
and then the second \texttt{x}.  A later call to \texttt{ns1::f} would
correctly open up the entirety of the namespace, and immediately mask
the global \texttt{x} with \texttt{ns1::x}, causing the evaluation of
the body to proceed erroneously.
\begin{figure}[htbp]
\begin{verbatim}
   int x = 3;
   namespace ns1 {
     int f(int n) { return n + x; }
     int x = 2;
   }
\end{verbatim}
  \caption[A Program Requiring Name Resolution]{A program
    demonstrating the need to have name resolution be a separate phase
    before dynamic evaluation.}
\label{fig:name-res-separate-phase}
\end{figure}

Even if one imagined a version of the dynamics that did perform name
resolution as it evaluated declarations, this semantics would still
need to transform the body of \texttt{ns1::f} to include the correct
reference to \texttt{::x}.  The rest of this section of the report
will describe the relation that turns the program in
Figure~\ref{fig:name-res-separate-phase} into
\begin{verbatim}
   int ::x = 3;
   int ::ns1::f(int n) { return n + ::x; }
   int ::ns1::x = 2;
\end{verbatim}

\bigskip\noindent The main relation in Phase~1 is called
\texttt{phase1}, and is defined in \HOLfile{name_resolution}.  In the
remainder of this section, I will discuss some of the more interesting
aspects of this phase of analysis.

\subsection{The Name Resolution State}
\label{sec:name-resol-state}

In order to track the current set of names that are in scope, Phase~1
uses two environments, as per
Section~\ref{sec:hierarchical-environments} above, to capture what is
known about the current nested scopes, as well as some extra fields to
describe the names that are \emph{visible}.  For example, in the
program of Figure~\ref{fig:name-res-separate-phase}, the global
\texttt{x} is visible when \texttt{::ns1::f} is defined, but there is
no \texttt{x} in the namespace \texttt{::ns1}, at least at that stage.

The HOL definition of the Phase~1 state is (see
\HOLfile{name_resolution}):
\begin{verbatim}
   P1state = <|
     current_nspath : string list ;
     dynclasses : string |-> bool # IDComp list #
                             TemplateArg list ;
     dynobjs : string |-> bool # IDComp list #
                          TemplateArg list # dynobj_type ;
     dynns : string |-> string list ;
     global : state ;
     accdecls : ext_decl list
   |>
\end{verbatim}
The three \texttt{dyn} fields record what names are visible in three
different categories: namespaces~(\texttt{dynns}),
classes~(\texttt{dynclasses}) and objects~(\texttt{dynobjs}).  Each
maps to information sufficient to provide an exact location for the
name.

In the case of namespace names, it is enough to provide a path from
the root, and such a path will just be of strings.  For objects and
classes, the path has to be of ID components because objects and
classes can be nested inside classes (and classes might be template
classes).  The boolean also records whether or not the name is local
or non-local.  The list of \texttt{TemplateArg} values records any
template parameters that the name may be associated with if it is a
template.  Finally, in the case of objects, it is also necessary to
record what sort of object the name is.  The options are given in the
type \texttt{dynobj_type}:
\begin{verbatim}
   dynobj_type =
      dStatMember | dMember | dVirtualMember | dNormalObj
\end{verbatim}
Note that in this context an ``object'' might actually be a function
(and it is functions that provide the interest); elsewhere
(particularly in the dynamics) functions are not considered objects
because they don't occupy allocated memory.

The \texttt{global} field of a \texttt{P1state} is a state from the
dynamic semantics.  In Phase~1 the vast majority of the information
stored in such a state is ignored; the state is part of the
\texttt{P1state} only for its two environments, which are accessed as
the fields \texttt{genv} (the global environment), and \texttt{env}
(the local environment).
\index{genv (state field)@\texttt{genv} (\texttt{state} field)}%
\index{env (state field)@\texttt{env} (\texttt{state} field)}%

Finally, the \texttt{accdecls} field records the accumulating
translated declarations.  It is this that provides the final output of
Phase~1.

\subsection{Template Names}
\label{sec:p1-template-names}

One significant issue is the resolution of names in templates.  When a
template definition is instantiated, it is important to specify how
the names occuring in the template are bound.  Typically, such names
might bind to global names that are in scope at the point of the
template's definition, or to member functions associated with the
template argument.

The rule is actually fairly straightforward, at least in principle:
function names are allowed to bind to template names when the
statically determined types of the function arguments refer to
template parameters.  Such names have to be left alone in Phase~1.

\subsection{Resolving Expressions}

The first interesting phase of name resolution comes when rewriting
expressions.  \index{phase1_expr@\texttt{phase1_expr}} This is done
with the function \texttt{phase1_expr}, defined in
\HOLfile{name_resolution}, and of type
\begin{verbatim}
   : frees_record -> P1state -> CExpr -> CExpr
\end{verbatim}
where the \texttt{frees_record} types records a set of template
arguments, which names must be treated specially.  (See
\HOLfile{frees} for more on the calculation of this notion of ``free
variable''.)

Most of the clauses of the function \texttt{phase1_expr} are
uninteresting recursions, \eg:
\begin{verbatim}
   phase1_expr avds ps (COr e1 e2) =
     COr (phase1_expr avds ps e1) (phase1_expr avds ps e2)
\end{verbatim}

The first interesting clause is the handling of function applications,
for which see Figure~\ref{fig:phase1expr-fnapp}.
\begin{figure}[htbp]
\begin{alltt}
   phase1_expr avoids ps (FnApp e elist) =
     let elist' = MAP (phase1_expr avoids ps) elist in
     let e' =
         if is_unqvar e then
           let fnm = dest_unqvar e in
           let atys =
              \(\varepsilon\)atys. listRel (expr_type ps.global RValue) elist'
                             atys
           in
             if \(\neg\)(DISJOINT
                     avoids
                     (FOLDL (\(\lambda\)a ty. a UNION tyfrees ty) \lbr\rbr atys))
             then
               e
             else if fnm \(\in\) FDOM ps.dynobjs then
               phase1_expr avoids ps e
             else
               let foldthis ps0 ty =
                   let nss =
                     FST (ass_nspaces_classes avoids ps0 ty) in
                   let nsl = SET_TO_LIST nss
                   in
                     FOLDL (\(\lambda\)ps00 ns. open_ftnode ns ps00) ps0 nsl
               in
               let ps' = FOLDL foldthis ps atys
               in
                 Var (idattach_locn
                        (ps'.dynobjs ' fnm)
                        (IDConstant F [] (IDName fnm)))
         else
           phase1_expr avoids ps e
     in
       FnApp e' elist'
\end{alltt}
\caption{Name Resolution in Function Applications}
\label{fig:phase1expr-fnapp}
\end{figure}
This is a complicated piece of code, though the structure is
relatively straightforward.  At the top level, the function calls
itself recursively to resolve the arguments of the function call,
generating the value \texttt{elist'}.  It is the calculation of the
resolved \texttt{e'} that introduces the complications.  The first
test checks if \texttt{e} is an unqualified variable.  If not, then
the recursion can proceed ``normally''.  If \texttt{e} is just a
simple variable however, then the code binds \texttt{fnm} to the name
of the variable, and \texttt{atys} to the types of the arguments.

The next test calculates the free type names of the argument types.
If this set overlaps with the names of any template arguments, then
the variable must be left alone, as \emph{per}
Section~\ref{sec:p1-template-names} above (it will be the subject of
future work if the containing template is instantiated).  Next it is
possible that the name is already in the \texttt{dynobjs} map, which
records information about the names that are necessarily in scope.  If
so, this binding for the name takes precedence, and a normal recursive
call can occur.  (This reflects~\cite[\S3.4.2,
paragraph~2a]{cpp-standard-iso14882}.)

The final part of this clause calculates the set of associated
namespaces and associated classes, in accordance with the language
of~\cite[\S3.4.2, paragraph~2]{cpp-standard-iso14882}, and then looks
for the given name in this new extended namespace.  (The function
\texttt{open_ftnode} is used to overlay an existing \texttt{P1state}
with the names of another namespace.)

\bigskip
\noindent
Another interesting case is dealing with variable names, assuming that
they have not already been caught by the function-application clause
just discussed.  The \texttt{Var} clause is presented in
Figure~\ref{fig:phase1expr:var}. \index{Var@\texttt{Var}}
\begin{figure}[htbp]
\begin{alltt}
   phase1_expr avoids ps (Var id) =
      case id of
         IDConstant T sfs sf ->
           if id_objtype ps.global id = dMember then
             let cnm = class_part id in
             let ps' = open_classnode avoids.tyfvs cnm ps
             in
               SVar (Deref This) (mk_dynobj_id ps' (IDtl id))
           else Var id
      || IDConstant F [] sf ->
           (let qid = idattach_locn (ps.dynobjs ' (sfld_string sf)) id
            in
              (case SND (SND (SND (ps.dynobjs ' (sfld_string sf)))) of
                  dVirtualMember -> SVar (Deref This) id
               || dMember -> SVar (Deref This) qid
               || dStatMember -> Var qid
               || dNormalObj -> Var qid))
      || IDConstant F (h::t) sf ->
           (let s = sfld_string h in
            let qid =
                if s \(\in\) FDOM ps.dynclasses then
                  idattach_locn (ps.dynclasses ' s) id
                else
                  IDConstant T (MAP IDName (ps.dynns ' s) ++ (h::t)) sf
            in
              if id_objtype ps.global qid = dMember then
                let cnm = class_part qid in
                let ps' = open_classnode avoids.tyfvs cnm ps
                in
                  SVar (Deref This) (mk_dynobj_id ps' (IDtl qid))
              else Var qid)
\end{alltt}
\caption{Name Resolution for Variables}
\label{fig:phase1expr:var}
\end{figure}
There are three cases depending on the form of the variable.  The
first is when the variable is an ``absolute'' name, with a leading
\texttt{::}.  This might still be a member reference, as in the
following
\begin{verbatim}
   class C {
     int x;
     int f() { return ::C::x; }
   };
\end{verbatim}
If this possibility is ruled out, then the name can be left
unchanged.  (If it's a static member, the name must be fine on its
own.)

The second case is when there is a single bare name, with no
qualification.  The qualified version of the name can be produced
immediately by consulting the \texttt{dynobjs} map, giving
\texttt{qid}.  Then it is necessary to determine what sort of name the
identifier is.  If it is a virtual member function, the name needs to
be left unqualified, but attached to a \texttt{this->}.  If it is a
normal member, then the qualified name needs to be used in the same
way.  Finally, if it is a static member, or non-class object, the
qualified name should be used as is.

The last case is when there is a qualified name, such as
\texttt{name1::name2}.  This is fiddly to resolve because the first
element of the qualification may refer to a namespace or a class.  In
either case, it is possible to resolve this (class names mask
namespace names), generating an unambiguous \texttt{qid}.  This then
needs to be treated just as in the first case, possibly generating a
member reference.

\subsection{Resolving Declarations: Establishing Phase 1 Names}
The code in \texttt{phase1_expr} uses the information that has been
stored in the Phase~1 states by earlier and higher-level traversals of
program syntax.  In particular, when a declaration is seen, this must
cause an adjustment of the information about names that is stored in
the Phase~1 state.

For example, when a new global variable is declared, the
\texttt{NewGVar} function is called to record this.  Its type is
\begin{verbatim}
   : CPP_Type -> IDComp -> P1state -> P1state
\end{verbatim}
and its definition appears in Figure~\ref{fig:newgvar-def}.
\begin{figure}[hbtp]
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
   NewGVar ty sfnm s =
     let sfnm' =
       IDConstant T (MAP IDName s.current_nspath) sfnm in
     let (targs,sfstr) = break_sfld sfnm in
     let ty' =
       rewrite_type
         (FOLDL (\(\lambda\)a ta. a UNION tafrees ta) \lbr\rbr targs)
         s ty
     in
       s with <|
         dynobjs :=
           s.dynobjs |+ (sfstr, (T,MAP IDName s.current_nspath,
                                 targs, dNormalObj)) ;
         global updated_by
           state_NewGVar ty s.current_nspath sfnm ;
         accdecls :=
           (s.accdecls ++ [Decl (VDec ty' sfnm')])
       |>
\end{alltt}
\end{minipage}
\end{center}
\caption{Defining a New Global Variable in Phase 1}
\label{fig:newgvar-def}
\end{figure}
The input to this procedure is a the type of the variable being
declared, its bare name (\texttt{sfnm} here), and the Phase~1 state
being updated.  The type is rewritten so that any of the names it
mentions are themselves resolved, and the state's \texttt{dynobjs}
field is updated to map the name to a full identifier, using the
current namespace path.  (The 4-tuple has \texttt{T} as its first
component because this is known to be a global variable; were we
defining a local name, this component would be \texttt{F} instead.)

\paragraph{Class Declarations} The most interesting behaviour at the
level of declarations comes with classes.  Here scopes are twisted in
order to allow member functions to refer to member names that have
actually been declared later in the class.  For example, in
\begin{verbatim}
   int x;
   class C {
     int f(int i) { return i + x; }
     int x;
   }
\end{verbatim}
the reference to \texttt{x} in the body of \texttt{C::f} is to
\texttt{C::x}, not to the global \texttt{x}.  This special
dispensation only extends as far as the bodies of member functions.
Sub-classes and their names are not so lucky; there the rule is that
the class declaration must come first.  If there is a conflict with an
external type-name, this is an error.  For example, the
following is an error:
\begin{verbatim}
   struct B { int x; };
   struct C {
     B b;
     struct B { int j; };
   };
\end{verbatim}
To make this correct, one should either explicitly qualify the type in
the declaration of member \texttt{b} (one could write \texttt{::B~b;}
to refer to the external class), or reorder so that the declaration of
the nested class came before the definition of \texttt{b} (in which
the field would be of the sub-class's type).

This analysis is illustrated in the definition of
\texttt{phase1_gclassdefn}, one clause of which is given in
Figure~\ref{fig:phase1-gclassdefn}.
\begin{figure}[htbp]
\begin{alltt}
   phase1_gclassdefn avds cnm (SOME ci) ps =
     let ancs' = MAP (\(\lambda\)(id,b,p). (resolve_classid ps id, b, p))
                     ci.ancestors in
     let fullnm =
           case cnm of
              IDConstant b [] sf ->
                 IDConstant b (MAP IDName ps.current_nspath) sf
           || IDConstant b sfs sf -> resolve_classid ps cnm in
     let ps0 = ps with global updated_by
                 new_class fullnm
                           (SOME (<| ancestors := ancs' ;
                                     fields := [] |>, \lbr\rbr)) in
     let ps1 = open_path avds.tyfvs T (id_sfs fullnm) ps0 in
     let ps2 = FOLDL (\(\lambda\)s cebp.
                        extract_class_names avds s
                           (T, id_sfs fullnm) cebp)
                     ps1
                     ci.fields in
     let ps3 = open_path avds.tyfvs T (id_sfs fullnm) ps2 in
     let flds' =
         FOLDL (\(\lambda\)celist (ce,b,p).
                  let ce' = phase1_gcentry avds ps3 cnm ce
                  in
                    (celist ++ [(ce',b,p)]))
               []
               ci.fields
     in
       ps3 with <|
         dynobjs := ps0.dynobjs ;
         dynclasses := ps0.dynclasses ;
         accdecls :=
           (ps.accdecls ++
            [Decl (VStrDec fullnm
                     (SOME <| ancestors := ancs' ;
                              fields := flds' |>))])
       |>
\end{alltt}
\caption{Name Resolution for a Global Class Declaration}
\label{fig:phase1-gclassdefn}
\end{figure}
The first pass over the fields appears in the binding for value
\texttt{ps2}.  The function called there, \texttt{extract_class_names}
passes over the fields of the class-info value (\texttt{ci}), and adds
the names it sees there to the state \texttt{ps1}.  The resolved
fields are then calculated in the last \texttt{let} binding (to
\texttt{flds'}).  Note that the state returned from the function adds
the resolved declaration to its accumulating list of declarations
(\texttt{accdecls}), but otherwise resets its dynamic state to that
which held immediately after the declaration of the class
(\texttt{ps0}).

\paragraph{Function Definitions} The final aspect of name resolutions
worth illustating comes with the constant
\texttt{phase1_fndefn},\index{phase1_fndefn@\texttt{phase1_fndefn}}
which handles resolution for top-level function definitions.  This is
another large definition, presented in Figure~\ref{fig:phase1-fndefn}.
\begin{figure}[htbp]
\begin{alltt}
   phase1_fndefn avds retty fnm pms body ps =
     let retty' = rewrite_type avds ps retty in
     let pms' =
       MAP (\(\lambda\)(nm,ty). (nm, rewrite_type avds ps ty)) pms in
     let funty = Function retty' (MAP SND pms') in
     let (fnm',declared_ps, body_ps) =
       case fnm of (* if the name is qualified, then there must be an
                      existing declaration, so we don't need to alter
                      anything in the state *)
          IDConstant T [] sf -> ARB (* must be an error, see 8.3 p1 *)
       || IDConstant T (sf1::sfs) sf2 ->
             (fnm, ps, open_path avds.tyfvs T (sf1::sfs) ps)
       || IDConstant F [] sf ->
             (IDConstant T (MAP IDName ps.current_nspath) sf,
              NewGVar funty sf ps,
              NewGVar funty sf ps)
       || IDConstant F (sf1::sfs) sf2 ->
             let fnm' = resolve_classid ps fnm in
             let (b,sfs,sf) = dest_id fnm'
             in
               (fnm', ps, open_path avds.tyfvs b sfs ps)
     in
     let ps' =
       FOLDL (\(\lambda\)ps (n,ty).
                  newlocal ps (IDName n) ty) body_ps pms' in
     let body' = phase1_stmt avds ps' body
     in
       declared_ps with
         accdecls := (declared_ps.accdecls ++
                      [FnDefn retty' fnm' pms' body'])
\end{alltt}
\caption{Name Resolution for a Global Function Definition}
\label{fig:phase1-fndefn}
\end{figure}
The big case-split on the form of the function name (\texttt{fnm})
binds two different Phase~1 states.  The \texttt{declared_ps} is what
is returned; and may reflect the fact that a new function is being
defined.  (When the name is qualified in some way, then the function
has already been declared (usually in a class).)

The \texttt{body_ps} is the name information that needs to be used
when the body of the function is analysed.  For example, consider the
following:
\begin{verbatim}
   namespace ns {
     int x;
     class C { int f(); int i; };
   }
   int ns::C::f() { return x + i; }
\end{verbatim}
When one comes to analyse the function \texttt{f}, both the global
variable \texttt{ns::x}, and the member variable \texttt{C::i} are in
scope.  This adjustment of scopes is done by the calls to
\texttt{open_path}.

\section{Phase 2: Templates}
\label{sec:templates}
\index{templates|(}

In this section, I describe how the semantics models templates.  I
have been inspired by Siek and Taha~\cite{DBLP:conf/ecoop/SiekT06},
though as I shall discuss, the dynamics of their model is too
simplistic for the full language of templates, in particular handling
template parameters that are themselves references to templates
(``higher order templates'' if you will).\footnote{Siek and Taha do
  model \texttt{typedef} declarations within classes, which I do not.}

One might imagine that it be possible to treat templates at
``run-time'', as if one had written a one-pass \cpp{} interpreter.
However, the example in Figure~\ref{fig:templates-not-interpretable}
demonstrates that such a goal is impossible, or at least that one
would have to write a two pass interpreter at the very least.  Any
reference to the figure's \texttt{List} template, perhaps within a
function that was called at a great stack depth, causes the need to
statically initialise the global \texttt{node\_count} before the
program even begins.  A \naive{} interpreter that attempts to execute
the program source as it sees it, will come unstuck.

As the interpreter sees the template declarations above, it does
nothing.  Then it performs its global declarations, and jumps into
main.  At this point it has already failed to do the right thing.
Instead, the putative interpreter would have to scan the whole program
for template applications so that it can generate the appropriate
global variable initialisations.  This is no better than explicitly
pre-compiling templates, so I have adopted an explicit two-phase
compilation approach.

\begin{figure}
\begin{verbatim}
  template <class T> class List {
    T item;
    List *next;
    static int node_count;
  };

  template<class T> int List<T>::node_count = 0;

  int main(void)
  {
    List<int> mylist;
    ...
  }
\end{verbatim}
  \caption[A Difficult Program for Template Interpretation]{A program
    demonstrating the difficulty of interpreting templates.}
\label{fig:templates-not-interpretable}
\end{figure}

We need to specify the possible sorts of arguments that can be passed
to templates.  The Standard is quite explicit
here~\cite[\S14.3~para~1]{cpp-standard-iso14882}, there are three
sorts of arguments: types, templates, and ``non-type, non-template''
arguments (meaning references to objects with linkage, or numbers).
Thus:
\begin{verbatim}
   TemplateArg = TType of CPP_Type
               | TTemp of CPP_ID
               | TVal of TemplateValueArg
\end{verbatim}
Finally, there are four different sorts of non-type, non-template
arguments~\cite[\S14.3.2~para~1]{cpp-standard-iso14882}:
\begin{verbatim}
   TemplateValueArg =
       TNum of int
     | TObj of CPP_ID
         (* id is of suitable global (one that has
            linkage etc). *)
     | TMPtr of CPP_ID => CPP_Type
     | TVAVar of string (* => CPP_Type *)
         (* can have a value (of the given type)
            substituted for this *)
\end{verbatim}
This presentation is slightly simplified because the standard also
allows arithmetic on these arguments, where this is appropriate
(between \texttt{TNum} and \texttt{TVAVar} parameters).

\subsection{Instantiation and Matching}

(This seection describes formalisation done in
\HOLfile{instantiation}.)

\medskip
\noindent Types and identifiers can be \emph{instantiated}: mappings
from variable names to values are applied over the structure of the
value (type or identifier), and occurrences of variable names are
replaced by the appropriate element from the range of the function.
Because there are three sorts of variables (corresponding to the three
different sorts of template argument), an instantiation is actually a
triple of functions (one for each sort of variable).

In Siek and Taha~\cite{DBLP:conf/ecoop/SiekT06}, instantiation is a
very elegant operation.  In a more faithful model of more of \cpp,
more complexities intrude.  In addition to the need for three
mappings, the model must also accept that instantiation can result in
an invalid result.  Instantiation must become partial, which is
modelled by making the types of the various instantiation functions be
of the form
\[
\texttt{inst<}\tau\texttt{>} : \mathit{substitution} \to \tau
\to \tau\;\textsf{option}
\]
The partiality arises at the lowest level, as in the following
example:
\begin{verbatim}
   template<class T> void f<T>(int x) { T::staticfield = x; }
   void g() { f<int>(3); }
\end{verbatim}
This must be an error because it is not sensible to write
\texttt{int::staticfield}.  (Other type substitutions may also cause
this to be an error, but this error can be detected as the
substitution is done, without any need to lookup information about the
argument.)

The partiality of instantiation does not prevent us from defining a
partial order over types, such that $\tau_1 \leq \tau_2$ when $\tau_2$
is a more specialised/instantiated version of $\tau_1$.  As in Siek
and Taha~\cite{DBLP:conf/ecoop/SiekT06}, we can prove reflexivity,
transitivity, and antisymmetry (up to renaming of free variables).
(These are sanity results, requiring substantial proof.)

Given the partial order, it is straightforward to find the best match
amongst a set of template definitions for a given template call.

\subsection{Program Instantiation}

Siek and Taha have an elegant model for program instantiation.  A
program is a sequence of definitions (of classes, and of static member
functions).  A definition may cause an existing template to be
instantiated because of a reference to that template within the
definition.  When a member function definition is encountered, if its
body includes a reference to other functions, these functions may need
to be instantiated.

For example, when analysing the program in Figure~\ref{fig:taha-prog},
the Siek and Taha's model will see the reference to
\texttt{Foo<T*>::f()} in the definition of \texttt{Bar<T>::g()} and
instantiate the definition of \texttt{Foo} (it knows that it does not
already have an instantiation for a type of the form \texttt{Foo<T*>}).
This instantiation will result in a template definition (one with free
variables), which may or may not be required in the rest of the
program.
\begin{figure}
\begin{verbatim}
   template <class T> class Foo { static int f(); };
   template <class T> int Foo<T>::f() { return 3; }

   template <class T> class Bar { static int g(); };
   template <class T> int Bar<T>::g() { return Foo<T*>::f(); }
\end{verbatim}
  \caption[A Template Program]{In Siek and Taha's model, the
    definition of class \texttt{Foo<T>} will get instantiated to
    provide a definition of class \texttt{Foo<T*>} when a reference to
    that type is seen inside the definition of \texttt{Bar<T>::g}.}
\label{fig:taha-prog}
\end{figure}

This model breaks down in the presence of template parameters that are
templates because it becomes impossible to determine the dependencies
of a template definition.  In the program in
Figure~\ref{fig:taha-problem}, it is impossible to tell what
definition should be instantiated when processing the definition of
\texttt{Baz<A>::g}.  In the presence of template parameters, Siek and
Taha's model is too eager.

\begin{figure}
\begin{verbatim}
   template <class T> struct Foo { static int f(); };
   template <class T> int Foo<T>::f() { return 3; }

   template <class T> struct Bar { static int f(); };
   template <class T> int Bar<T>::f() { return 4; }

   template <template <class> class A> struct Baz {
     static int g();
   };
   template <template <class> class A>
   int Baz<A>::g() {
     return A<int>::f();
   }

   int main() { return Baz<Foo>::g(); }
\end{verbatim}
  \caption[A Template Program that Breaks Siek and Taha's Model]{Siek
    and Taha's model's early instantiation breaks down when it sees
    the definition of \texttt{Baz<A>::g}, and the call to
    \texttt{A<int>} in particular.  At this point, it can not tell
    which template is being instantiated in the body.  By way of
    contrast, my model doesn't instantiate anything until it sees the
    definition of \texttt{main}.  (This program is available as
    \texttt{notes/siek-taha-tempvar.cpp})}
\label{fig:taha-problem}
\end{figure}

My model only performs instantiations when there is a ground instance
to drive the instantiation.  Otherwise, it is similar to what is
presented in Siek and Taha.  In particular, it is crucial to avoid
instantiating member functions unless they are called for.

The model in \HOLfile{templates} script is based around a working
state of two components: a Phase~1 state, and a sequence of ground
declarations.  In addition, the template relations take a sequence of
template declarations, the ``patterns''.  These patterns do not change
as template instantiation is performed, whereas the other components
do.  Thus, the general forms of the relations' definition is
\begin{verbatim}
   template_relation pats (ps0,grds0) (ps,grds) = ...
\end{verbatim}

Template instantiation only begins when all of the program's
declarations have been analysed in Phase~1.  This means that the
process begins with a complete Phase~1 state, and with all of the
translation unit's definitions ``to hand''.  This is only real
difference between the model here and Siek \& Taha's.  Their core
relation is presented in their Figure~6, and consists of 4 rules,
including one that checks when instantiation can finish.  It is their
last rule, \textsc{(C-Fun)} that represents a problem: when their
system encounters a member function definition, it analyses it there
and then.

In contrast, my model only performs Phase~1 analysis on such
functions.  All template work is deferred until the end of Phase~1.
Further, template work requires that all class definitions have member
function definitions stripped from them and turned into separate
top-level definitions.  This is not a difficult operation to perform.
At this point, my model repeatedly performs the equivalent of Siek and
Taha's rule \textsc{(C-InstFun)}.

The top-level definition (from \HOLfile{templates}) is
\begin{verbatim}
   template_analysis pats =
     TC ((template_phase2_destructors pats RUNION
          template_phase2_constructors pats RUNION
          template_phase2_statmems pats RUNION
          template_phase2_fns pats) O
         TC (template_phase1 pats))
\end{verbatim}
where \texttt{TC} is transitive closure, \texttt{RUNION} is relation
union, and \texttt{O} is relation composition.

The first phase is \texttt{template_phase1}, which is instantiates any
needed template classes:
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
   template_phase1 pats (ps0, grds0) (ps, grds) =
     \(\exists\)id id' sub ci0.
       id \(\in\) used_ttypes pats grds0 \(\land\)
       id \(\not\in\) declared_types grds0 \(\land\)
       (\(\forall\)sub_id. sub_id is_sub_tid id \(\Rightarrow\)
                 sub_id IN declared_types grds0) \(\land\)
       best_class_match pats id sub (id', ci0) \(\land\)
       phase1 ([P1Decl
                  (Decl
                     (VStrDec id
                        (cinfo_inst sub (THE ci0))))], ps0)
              ([], ps) \(\land\)
       (grds = grds0 ++ [LAST ps.accdecls])
\end{alltt}
\end{minipage}
\end{center}
This rule first looks for a type name \texttt{id} that is both
referred to in the ground input declarations (\texttt{grds0}), and
which is not declared there.  It then checks that all identifiers that
are a proper prefix of \texttt{id} \emph{are} declared.\footnote{Thus,
  a reference to something like \texttt{C<int>::D<char>} will result
  in the instantiation of \texttt{C<int>} first.} Then, the relation
\texttt{best_class_match} scans the template declarations, and returns
the best (most specific) match.  In fact, it returns both the
instantiation required to turn the template ID (\texttt{id'}) into the
desired ID (\texttt{id}) and the template class declaration, which is
\texttt{ci0}.

The penultimate conjunct of the definition instantiates the
class-info, and performs a Phase~1 analysis of it.  The resulting
class declaration can be appended to the list of ground declarations.

The second phase of template analysis looks to instantiate member
functions (including constructors and destructors),  as well static
member objects.  The pattern is similar for each constant.  The following is
the rule for member functions.
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
   template_phase2_fns pats (ps0, grds0) (ps, grds) =
     \(\exists\)id id' sub retty pms bod.
       id \(\in\) used_tfns pats grds0 \(\land\)
       id \(\not\in\) defined_fns grds0 \(\land\)
       (\(\forall\)sub_id. sub_id is_sub_tid id \(\Rightarrow\)
                 sub_id \(\in\) declared_types grds0) \(\land\)
       best_function_match pats id sub
                           (id', (retty, pms, bod)) \(\land\)
       phase1 ([P1Decl
                  (FnDefn
                     (THE (type_inst sub retty))
                     id
                     (MAP (\(\lambda\)(n,ty).
                             (n,THE (type_inst sub ty)))
                          pms)
                     (THE (stmt_inst sub bod)))], ps0)
              ([], ps) \(\land\)
       (grds = grds0 ++ [LAST ps.accdecls])
\end{alltt}
\end{minipage}
\end{center}
The basic pattern of this rule is similar to that of
\texttt{template_phase1}.  First, an identifier \texttt{id} is found
that is both referred to among the ground declarations, and which is
not ground itself.  If a matching function can be found, then this is
instantiated, and passed to the Phase~1 analysis to have its names
resolved.  It is at this point that names we avoided in
Figure~\ref{fig:phase1expr-fnapp}~(page~\pageref{fig:phase1expr-fnapp}),
will get their chance to find resolution in appropriate namespaces,
because arguments that had been templates will now be concrete, ground
types.

Note that this rule also handles template instantiation for function
templates that are not associated with a class, though it is an
incomplete picture because the \texttt{best_function_match} relation
does not consider other ground functions, and so doesn't deal with
overloading resolution.
\index{overloading}

The definition of \texttt{best_function_match} appears in
Figure~\ref{fig:best-function-match}.  A lot of the ``heavy lifting''
in this definition of the behaviour of templates comes from the
operations of matching and instantiation.  This is the strength of
Siek and Taha's approach.  In this definition, the best match is one
that finds a \texttt{sub} that does indeed instantiate the pattern
\texttt{id'} to the desired \texttt{id} (instantiating only the
variables that are identified as template parameters).  The second
half of the definition requires that the match be ``best'' by
requiring that all other contenders be instantiable to it.
\begin{figure}[htbp]
\begin{alltt}
   best_function_match Temps id sub (id', (retty,pms,bod)) =
     (\(\exists\)targs.
         (cppID_inst sub id' = SOME id) \(\land\)
         MEM (TemplateDef targs (FnDefn retty id' pms bod))
             Temps \(\land\)
         sub only_changes targsfrees targs) \(\land\)
     \(\forall\)id2 retty2 pms2 bod2 sub2 targs.
         MEM (TemplateDef targs (FnDefn retty2 id2 pms2 bod2))
             Temps \(\land\)
         sub2 only_changes targsfrees targs \(\land\)
         (cppID_inst sub2 id2 = SOME id) \(\Rightarrow\)
         \(\exists\)sub'. (cppID_inst sub' id2 = SOME id') \(\land\)
                sub' only_changes targsfrees targs
\end{alltt}
\caption{Finding the Best Function Instantiation}
\label{fig:best-function-match}
\end{figure}

\index{templates|)}

\section{Phase 3: Dynamics}
\label{sec:phase3}

Much of the core semantics in this section is based on the C semantics
presented in my PhD thesis~\cite{Norrish98}.  In particular, details
of the way in which side effects are created and applied remain the
same, as does the use of an evaluation context, and the way in
unspecified order of evaluation is handled.

\subsection{Dynamic States}
\label{sec:dynamic-states}

The dynamic semantics updates values of the type \texttt{state} (see
\HOLfile{states}), given in full in Figure~\ref{fig:state-type}.  The
first four components of the state are sets of addresses.  The
\texttt{allocmap} and \texttt{initmap} sets are from my C
model~\cite{Norrish98}, and record which addresses have been allocated
and initialised, respectively.  The new field \texttt{hallocmap} is
necessary to allow memory to be allocated on the heap, and for its
life-span to persist beyond the end of the current block.  The second
new field, \texttt{constmap} records which memory has been allocated
with the \texttt{const} \emph{cv}-qualifier.  (Updating such memory
causes undefined behaviour.)

\begin{figure}[htbp]
\footnotesize
\begin{verbatim}
   state = <|
     allocmap : addr -> bool ;  (* the set of stack-allocated addresses *)
     hallocmap: addr -> bool ;  (* the set of heap-allocated addresses *)
     constmap : addr -> bool ;  (* the set of read-only addresses *)
     initmap  : addr -> bool ;  (* the set of initialised addresses *)

     fnmap    : CPP_ID |-> fn_info ;
                (* map from function 'names' to type information about
                   the given functions *)
     fnencode : CPP_ID |-> byte list ;
                (* map encoding function 'name' as a byte sequence
                   so that its address can be stored in memory *)
     fndecode : byte list |-> CPP_ID ;
                (* map inverting fnencode *)

     genv: environment ; (* non-local environment *)
     env : environment ; (* local version of the above *)

     locmap   : addr -> byte ;
                (* memory.  Domain might also be ( void * ) words *)

     stack    : (environment # CExpr option # (addr->bool)) list ;
                (* stack of environment, this and allocation info.
                   Updated as blocks are entered and left *)

     thisvalue: CExpr option ;
                (* the value (i.e., this will always be an ECompVal
                   with a pointer value) of the this expression *)

     blockclasses : constructed list list ;
     exprclasses  : construction_locn list list
       (* the stack of objects that need to have destructors
          called.  First field is for automatic objects that have
          block-delimited lifetimes.  Second is for temporary
          objects that need to be destroyed at the end of the
          full enclosing expression *)
     ;

     current_exns : CExpr list
                    (* stack of exceptions that might be subjected
                       to a bare throw *)
   |>
\end{verbatim}
\caption[The HOL Type of Dynamic State]{The HOL type of dynamic state.
  There are two environment values, \texttt{genv}, and \texttt{env}.
  The former is for non-local, persistent identifiers, the latter for
  local identifiers.  Because there is no such thing as a local
  namespace, there will only be a top-level node in the \texttt{env}
  field (which may, however point to an arbitrarily deep
  \texttt{class_env}).}
\label{fig:state-type}
\end{figure}

\subsection{The Dynamic Relation}

\newcommand{\mng}{\texttt{mng}}

The fundamental relation in the dynamics semantics is \mng{} (or
``meaning''), which is a binary relation on states and abstract syntax
forms.  For reasons to do with the prevention of function call
interleaving (explained below in Section~\ref{sec:small-step-stmts}),
this one relation is used for both expression and statement forms.
(One might otherwise imagine two mutually recursive relations: one for
statements and the other for expressions.)

Thus the type of \mng{} is
\begin{alltt}
   : (state # ExtE) -> (state # ExtE) -> bool
\end{alltt}
making it a binary relation on pairs of states and \emph{extended
  expressions}.  An extended expression is either
\begin{itemize}
\item a syntactic expression coupled with a side effect information
  record (containing the three fields, \texttt{update\_map},
  \texttt{ref\_map} and \texttt{pending\_ses}, ($R$, $\Upsilon$ and
  $\Pi$ in the terminology of my thesis)); or
\item a statement coupled with a continuation, which latter is a
  function that takes a value and returns an expression.  This latter
  is used to recreate the expression in which the function call
  that generated the statement occurred.  Also, all expressions within
  statements (such as those that appear as guards in loops and
  \texttt{if}-statements), are actually extended expressions.
\end{itemize}

In \HOLfile{statements}, the declaration of extended expression
(\texttt{ExtE}) is thus mutually recursive with the type of
statements:
\index{ExtE@\texttt{ExtE}}
\index{EX@\texttt{EX}}
\index{ST@\texttt{ST}}
\begin{verbatim}
   ExtE = EX of CExpr => se_info
        | ST of CStmt => conttype
\end{verbatim}

Most of the time reduction occurs between expressions and expressions,
or between statements and statements, allowing one to imagine that one
has the $\rightarrow_e$ and $\rightarrow_s$ from the C semantics.
For example, when evaluating expressions, rules in the dynamics have
conclusions of the form
\begin{alltt}
   mng (s0, EX e0 se0) (s, EX e se)
\end{alltt}
where \texttt{s0} and \texttt{s} are the initial and final states;
\texttt{e0} and \texttt{e} are the initial and final expression forms;
and \texttt{se0} and \texttt{se} are the initial and final ``side
effect records''.

Similarly, when evaluating statements, conclusions are typically of
the form
\begin{alltt}
   mng (s0, ST st0 c) (s, ST st c)
\end{alltt}
where \texttt{st0} and \texttt{st} are the initial and final statement
forms.  Note that the continuation (\texttt{c} above) never changes
within statement evaluation, meaning that statement rules will always
actually repeat the given continuation from initial to final tuple.

\subsection{Special Syntactic Forms}
\label{sec:spec-synt-forms}

In the abstract syntax types representing both expressions and
statements, I have added special forms that only arise as a result of
evaluation and could never be seen in an input program.  The most
important of these are the forms for representing values and l-values
within the expression type.

\index{ECompVal@\texttt{ECompVal}|textbf}
The \texttt{ECompVal} constructor has type
\begin{alltt}
   : byte list -> CPP_Type -> CExpr
\end{alltt}
and represents values as sequences of bytes, coupled with their type.

\index{LVal@\texttt{LVal}|textbf}
The \texttt{LVal} constructor is used to represent l-values, and has
type
\begin{alltt}
   : addr -> CPP_Type -> CPP_ID list
\end{alltt}
Thus, an l-value is represented by a combination of its base address
and its type, along with the list of identifiers that allow us to
represent the dynamic types of basic object orientation; see
Section~\ref{sec:basic-oo} below.

In addition, there is an analogue to \texttt{LVal} for functions,
called \texttt{FVal}.  This represents the identity of a function, and
has type:
\begin{alltt}
   : CPP_ID -> CPP_Type -> CExpr option -> CExpr
\end{alltt}
A function is identified by its name, its type, and if a (non-static)
member function, the expression denoting the class object for which it
is to be called.

\index{UndefinedExpr@\texttt{UndefinedExpr}}
Finally, there is the special value \texttt{UndefinedExpr} used to
represent the occurrence of undefined behaviour within an expression.

\subsection{Simple Expression Rules}
\label{sec:simple-expr-rules}

\paragraph{Literals} We begin with two rules for literals.  We don't
have any rules for other literal forms, such as floating point
constants, though it is clear what they would look like.
\index{Cnum@\texttt{Cnum}}%
\index{rule (dynamic)!number-literal@\texttt{number-literal}}%
\begin{alltt}
(* RULE-ID: number-literal *)
     (REP_INT (Signed Int) n = SOME bl)
   \(\Rightarrow\)
     mng (s, EX (Cnum n) se)
         (s, EX (ECompVal bl (Signed Int)) se)
\end{alltt}

The only difference with character constants is that the underlying
number is pushed into a different sized space:
\index{Cchar@\texttt{Cchar}}%
\index{rule (dynamic)!char-literal@\texttt{char-literal}}
\begin{alltt}
(* RULE-ID: char-literal *)
     (REP_INT BChar n = SOME bl)
   \(\Rightarrow\)
     mng (s, EX (Cchar n) se) (s, EX (ECompVal bl BChar) se)
\end{alltt}

\index{This@\texttt{This}} Though not really a literal, the special
\cpp{} expression form \texttt{this} also has a simple rule:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!this@\texttt{this}}
\begin{alltt}
(* RULE-ID: this *)
     T
   \(\Rightarrow\)
     mng (s, EX This se) (s, EX (THE s.thisvalue) se)
\end{alltt}
\end{minipage}
\end{center}


\paragraph{Variables} Looking up object variables becomes a little
complicated in the presence of references and object orientation.
\index{Var@\texttt{Var}}%
\index{rule (dynamic)!var-to-lvalue@\texttt{var-to-lvalue}}%
\begin{alltt}
(* RULE-ID: var-to-lvalue *)
     (lookup_type s vname = SOME ty0) \(\land\)
     object_type ty0 \(\land\)
     (lookup_addr s vname = SOME (a,cnm,p)) \(\land\)
     (ty = if class_type ty0 then Class cnm else ty0)
   \(\Rightarrow\)
     mng (s, EX (Var vname) se) (s, EX (LVal a ty p) se)
\end{alltt}
\index{lookup_type@\texttt{lookup_type}}%
The call to \texttt{lookup_type} determines the variable's static
type, which will have been set in the appropriate part of the state
when the variable was declared.  The second premise checks to see that
the variable is of object type.  If so, the variable will have an
address.  Accompanying the address is information (\texttt{cnm} and
\texttt{p}) that gives dynamic type information if the object is of
class type.

It may not be clear how a variable may come to have a dynamic type
that is separate from its static type.  In fact, this is only possible
in the presence of references, which are treated as aliases for real
variables.  Thus, in a function such as
\begin{verbatim}
   int f(C &c) { return c.memfn(); }
\end{verbatim}
the variable \texttt{c} is initialised to ``point at'' some existing
variable, and the address maps are set up so that \texttt{c} is indeed
a perfect alias for some existing l-value.  But, the argument may in
fact have been a derived class of \texttt{C}, and so \texttt{c}'s
dynamic type won't be the same as its static type.

Variables can also denote functions:
\index{FVal@\texttt{FVal}}%
\index{Var@\texttt{Var}}%
\index{rule (dynamic)!var-to-fvalue@\texttt{var-to-fvalue}}
\begin{alltt}
(* RULE-ID: var-to-fvalue *)
     (lookup_type s vname = SOME ty) \(\land\)
     function_type ty \(\land\)
     vname \(\in\) FDOM s.fnencode
   \(\Rightarrow\)
     mng (s, EX (Var vname) se) (s, EX (FVal vname ty NONE) se)
\end{alltt}


\paragraph{Contextual Evaluation}
\index{valid_econtext@\texttt{valid_econtext}}
Just as in the C semantics, most nested evaluation of expressions is
mediated through one rule: \label{rule:econtext-expr}
\index{rule (dynamic)!econtext-expr@\texttt{econtext-expr}}
\begin{alltt}
(* RULE-ID: econtext-expr *)
     mng (s0, EX e0 se0) (s, EX e se) \(\land\)
     valid_econtext f
   \(\Rightarrow\)
     mng (s0, EX (f e0) se0) (s, EX (f e) se)
\end{alltt}
Here, \texttt{f} is a function of type \texttt{:CExpr->CExpr},
but restricted by the predicate \texttt{valid_econtext}.  This
predicate restricts where evaluation can occur.  For example, a
function satisfying \texttt{valid_econtext} would be
\[
\lambda e.\;\;\texttt{CAnd}\;e\;e_2
\]
for all possible values $e_2$.  Such a function allows reduction to
occur to the left of the \texttt{CAnd} constructor (\ie,
\texttt{\&\&}).  The corresponding function with its ``hole'' on the
right of the \texttt{CAnd} is not a valid context function.

\index{UndefinedExpr@\texttt{UndefinedExpr}}
If an undefined behaviour occurs, this is reflected by having the
expression that caused it become the special \texttt{UndefinedExpr}
value.  This value can rise to the top of any expression:
\index{rule (dynamic)!econtext-undefinedness@\texttt{econtext-undefinedness}}%
\begin{alltt}
(* RULE-ID: econtext-undefinedness *)
     valid_econtext f
   \(\Rightarrow\)
     mng (s, EX (f UndefinedExpr) se) (s, EX UndefinedExpr se)
\end{alltt}

The notion of where a function l-value decays into a pointer to a
function is also controlled by a context:
\index{valid_fvcontext@\texttt{valid_fvcontext}}%
\index{rule (dynamic)!fcontext@\texttt{fcontext}}
\begin{alltt}
(* RULE-ID: fcontext *)
     fnid \(\in\) FDOM s.fnencode \(\land\)
     (s.fnencode ' fnid = bytes) \(\land\)
     valid_fvcontext f
   \(\Rightarrow\)
     mng (s, EX (f (FVal fnid ty NONE)) se)
         (s, EX (f (ECompVal bytes (Ptr ty))) se)
\end{alltt}
The definition of \texttt{valid_fvcontext} is
\begin{alltt}
   valid_fvcontext f =
      valid_econtext f \(\land\)
      \(\forall\)args. \(\neg\)(f = \(\lambda\)f'. FnApp f' args)
\end{alltt}
stating that a function l-value can decay as in the rule above, as
long as it is not at the head of a function application.

\index{valid_lvcontext@\texttt{valid_lvcontext}}%
\index{lval2rval@\texttt{lval2rval}}%
Finally, there is the rule allowing normal l-values to decay into
their r-value forms (the ``l-value to r-value conversion''):
\index{rule (dynamic)!lvcontext@\texttt{lvcontext}}%
\begin{alltt}
(* RULE-ID: lvcontext *)
     valid_lvcontext f \(\land\)
     lval2rval (s0,e0,se0) (s,e,se)
   \(\Rightarrow\)
     mng (s0, EX (f e0) se0) (s, EX (f e) se)
\end{alltt}
The \texttt{lval2rval} relation can result in an
\texttt{UndefinedExpr} if the l-value causes a reference to a value
that has already been updated within the same phase of execution, as
might happen in the expression \texttt{i++ + i} for example.
Otherwise, if the l-value denotes an object not of class type, the
l-value turns into a list of bytes (an \texttt{ECompVal}), ready for
further manipulations to occur.

\paragraph{Operators} The rules governing the behaviour of the
standard operators are as in the original C semantics.  The rules for
the standard computational binary operators (arithmetic and shift
operators) are presented in Figure~\ref{fig:capbinary-rules}, and
depend on an auxiliary relation \texttt{binop_meaning}, which is
defined in \HOLfile{operators}.  Being a relation, it allows for
nondeterminism and failure.

\index{overloading}
Were the model to cope with operator overloading correctly, these
rules would remain unchanged.  Operator overloading would be resolved
in Phases~1 and~2, allowing uses of overloaded operators to be
rewritten to the function calls that they really are.
\begin{figure}[htbp]
\index{CApBinary@\texttt{CApBinary}}%
\index{rule (dynamic)!binop-fails@\texttt{binop-fails}}%
\index{rule (dynamic)!binop-computes@\texttt{binop-computes}}%
\begin{alltt}
(* RULE-ID: binop-fails *)
     (\(\forall\)res restype. \(\neg\)binop_meaning s f \(\!\)v1 (strip_const type1)
                                       v2 (strip_const type2)
                                       res restype)
   \(\Rightarrow\)
     mng (s, EX (CApBinary f (ECompVal v1 type1)
                             (ECompVal v2 type2)) se0)
         (s, EX UndefinedExpr se0)
\end{alltt}

\begin{alltt}
(* RULE-ID: binop-computes *)
     binop_meaning s f v1 (strip_const type1)
                       v2 (strip_const type2)
                       res restype
   \(\Rightarrow\)
     mng (s, EX (CApBinary f (ECompVal v1 type1)
                             (ECompVal v2 type2)) se)
         (s, EX (ECompVal res restype) se)
\end{alltt}
\caption{Rules for the Standard Binary Operators}
\label{fig:capbinary-rules}
\end{figure}

There are analogous rules for the standard unary operators (arithmetic
and logical negation, unary plus, and bit-wise complement), presented
in Figure~\ref{fig:capunary-rules}.
\begin{figure}[htbp]
\index{CApUnary@\texttt{CApUnary}}%
\index{rule (dynamic)!unop-computes@\texttt{unop-computes}}%
\index{rule (dynamic)!unop-fails@\texttt{unop-fails}}%
\begin{alltt}
(* RULE-ID: unop-computes *)
     unop_meaning f ival (strip_const t) result rt
   \(\Rightarrow\)
     mng (s, EX (CApUnary f (ECompVal ival t)) se)
         (s, EX (ECompVal result rt) se)
\end{alltt}

\begin{alltt}
(* RULE-ID: unop-fails *)
     (\(\forall\)res rt. \(\neg\)unop_meaning f ival (strip_const t) res rt)
   \(\Rightarrow\)
     mng (s0, EX (CApUnary f (ECompVal ival t)) se0)
         (s0, EX UndefinedExpr se0)
\end{alltt}
\caption{Rules for the Standard Unary Operators}
\label{fig:capunary-rules}
\end{figure}

\paragraph{Sequential Operators}
The logical operators \texttt{\&\&} and \texttt{||}, the ternary
conditional operator \texttt{?:}, and the comma operator all evaluate
their arguments in a prescribed order, and must exhaust the pending
side effects that may have accumulated in a state before they can move
from one argument to the next, if indeed they move on at all.   For
example, the rule where logical-and returns false is
\index{rule (dynamic)!and-false@\texttt{and-false}}%
\begin{alltt}
(* RULE-ID: and-false *)
     is_zero t v
   \(\Rightarrow\)
     mng (s, EX (CAnd (ECompVal v t) sub2) se)
         (s, EX (ECompVal (signed_int 0) Bool) se)
\end{alltt}
When the first argument is true (non-zero), the truth value of the
second argument is the result.  The conversion of the second argument
to a truth value is achieved by negating twice:
\index{rule (dynamic)!and-true@\texttt{and-true}}%
\begin{alltt}
(* RULE-ID: and-true *)
     ~is_zero t v \(\land\)
     is_null_se se
   \(\Rightarrow\)
     mng (s, EX (CAnd (ECompVal v t) sub2) se)
         (s, EX (CApUnary CNot (CApUnary CNot sub2)) base_se)
\end{alltt}
\index{is_null_se@\texttt{is_null_se}|textbf}%
The \texttt{is_null_se} predicate tests whether or not a side effect
record is empty of pending side effects.
\index{base_se@\texttt{base_se}|textbf}%
The \texttt{base_se} value is the empty side effect record; it is the
appropriate starting point for a new phase of execution after a
sequence point has been reached.

\medskip
\noindent
\index{CommaSep@\texttt{CommaSep}}%
The comma operator (\texttt{CommaSep} here) always evaluates both of
its arguments.  As with the other operators, evaluation of the first
argument is handled by the contextual evaluation rule; we need only
provide a rule for when the left-hand expression has been fully
evaluated.
\index{rule (dynamic)!comma-progresses@\texttt{comma-progresses}}%
\begin{alltt}
(* RULE-ID: comma-progresses *)
     final_value (EX e1 se)
   \(\Rightarrow\)
     mng (s0, EX (CommaSep e1 e2) se)
         (s0, EX (RValreq e2) base_se)
\end{alltt}
\index{RValreq@\texttt{RValreq}}%
The special \texttt{RValreq} form is used to force l-values to
evaluate to r-values if possible.  (See~\cite[\S3.3.3]{Norrish98} for
why this form is necessary.)
\index{final_value@\texttt{final_value}|textbf}%
The \texttt{final_value} predicate (from \HOLfile{statements}) checks
an extended expression to confirm that it represents a completely
evaluated form.  Its definition is
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
   (final_value (EX e se) =
      is_null_se se \(\land\)
      ((\(\exists\)v t. e = ECompVal v t) \(\lor\)
       (\(\exists\)a t p. e = LVal a t p))) \(\land\)

   (final_value (ST s c) = F)
\end{alltt}
\end{minipage}
\end{center}

\paragraph{Pointer Operations}
The two significant pointer operations are dereferencing and
address-taking (the \texttt{*} and \texttt{\&} operators
respectively).  \cpp{} adds two class-related variants of these
operations to the existing pair, which come across from C practically
unchanged.  Thus the rule for taking an address:
\index{Addr@\texttt{Addr}}%
\index{rule (dynamic)!addr-lvalue@\texttt{addr-lvalue}}
\begin{alltt}
(* RULE-ID: addr-lvalue *)
(* See 5.3.1 p2-5 - taking the address of an lvalue *)
     (SOME result = ptr_encode s a t pth)
   \(\Rightarrow\)
     mng (s, EX (Addr (LVal a t pth)) se)
         (s, EX (ECompVal result
                          (Ptr (static_type (t,pth)))) se)

\end{alltt}
\index{LVal@\texttt{LVal}}%
The function
\texttt{static_type}\index{static_type@\texttt{static_type}} computes
the static type for a l-value given access to the type and path of
identifiers.  (For non-class values, the static type is simply the
second argument to \texttt{LVal}.)

There must be two rules for dereferencing a normal pointer; it may or
may not point to a valid object.  In fact, there must also be a third
rule because of the possibility that the pointer value being
dereferenced is actually a pointer to a function. These rules are presented in
Figure~\ref{fig:deref-rules}.
\begin{figure}[htbp]
\index{rule (dynamic)!deref-objptr@\texttt{deref-objptr}}%
\index{rule (dynamic)!deref-objptr-fails@\texttt{deref-objptr-fails}}%
\index{rule (dynamic)!deref-fnptr@\texttt{deref-fnptr}}%
\index{Deref@\texttt{Deref}}%
\begin{alltt}
(* RULE-ID: deref-objptr *)
(* 5.3.1 p1 - pointer to an object type *)
     object_type t \(\land\)
     (SOME mval = ptr_encode s addr t' pth) \(\land\)
     (static_type (t',pth) = t)
   \(\Rightarrow\)
     mng (s, EX (Deref (ECompVal mval (Ptr t))) se)
         (s, EX (LVal addr t' pth) se)


(* RULE-ID: deref-objptr-fails *)
     object_type t \(\land\)
     ((\(\forall\)addr t' p. \(\neg\)(SOME mval = ptr_encode s addr t' p)) \(\lor\)
      (\(\exists\)t' p. SOME mval = ptr_encode s 0 t' p))
   \(\Rightarrow\)
     mng (s, EX (Deref (ECompVal mval (Ptr t))) se)
         (s, EX UndefinedExpr se)


(* RULE-ID: deref-fnptr *)
(* 5.3.1 p1 - pointer to a function type *)
     v \(\in\) FDOM s.fndecode
   \(\Rightarrow\)
     mng (s, EX (Deref
                  (ECompVal v
                            (Ptr (Function retty argtys))))
                se)
         (s, EX (FVal (s.fndecode ' v)
                      (Function retty argtys)
                      NONE) se)
\end{alltt}
\caption{Rules for ``C-style'' Dereferencing of Pointers}
\label{fig:deref-rules}
\end{figure}

\medskip
\noindent More interesting from a \cpp{} perspective are the rules for
taking the address of class-members (and then using those pointers to
members to access members).  The concrete syntax for this is
rather ugly:
\begin{verbatim}
   struct C { int x; int y; };
   int C::* cintptr = &C::x; // or &C::y
\end{verbatim}
\index{MemAddr@\texttt{MemAddr}}%
In the abstract syntax, the address taking operation is written
\texttt{MemAddr}, of type
\begin{verbatim}
   : CPP_ID -> IDComp -> CExpr
\end{verbatim}
where the first argument is the name of the class, and the second is
the name of the field.

If the member whose address is being taken is actually a static
member, then a normal pointer is generated, as can be seen from the
type attached to the \texttt{ECompVal} in the conclusion of the rule.
(There is a similar rule for taking the address of a static member
function.)
\begin{center}
\index{rule (dynamic)!mem-addr-static-nonfn@\texttt{mem-addr-static-nonfn}}%
\begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: mem-addr-static-nonfn *)
(* 5.3.1 p2 *)
     object_type ty \(\land\)
     MEM (FldDecl fldname ty, T, prot)
         (cinfo s cname).fields \(\land\)
     (lookup_addr s (mk_member cname fldname) =
        SOME (addr, pth)) \(\land\)
     (SOME ptrval = ptr_encode s addr ty (SND pth))
   \(\Rightarrow\)
     mng (s, EX (MemAddr cname fldname) se)
         (s, EX (ECompVal ptrval (Ptr ty)) se)
\end{alltt}
\end{minipage}
\end{center}
\index{cinfo@\texttt{cinfo}}
The function \texttt{cinfo} takes a state and a class-name and returns
the information about that class in the form of a record, one of whose
fields is called \texttt{fields}, being a list of all the declarations
occurring within the class.

\bigskip\noindent
The more interesting case occurs when the member is not static.
\index{rule (dynamic)!mem-addr-nonstatic@\texttt{mem-addr-nonstatic}}%
\begin{alltt}
(* RULE-ID: mem-addr-nonstatic *)
     (encode_offset cnm fldname = SOME bl) \(\land\)
     ((\(\exists\)prot. MEM (FldDecl fldname ty, F, prot)
                  (cinfo s cnm).fields) \(\lor\)
      (\(\exists\)prot v rt args bod.
          MEM (CFnDefn v rt fldname args bod, F, prot)
              (cinfo s cnm).fields \(\land\)
          (ty = Function rt (MAP SND args))))
   \(\Rightarrow\)
     mng (s, EX (MemAddr cnm fldname) se)
         (s, EX (ECompVal bl (MPtr cnm ty)) se)
\end{alltt}
Functions and data members are not declared in quite the same way
within a class (because the functions may be accompanied by their
implementations), which explains the disjunctive hypothesis above.
The function \texttt{encode_offset} takes a class and field-name and
returns the encoding of this offset as a list of bytes.  It is this
that will be written into memory if the offset is stored in a
variable.

\bigskip\noindent
Once one has a pointer-to-member value, one can dereference it, as
long as one also had a class object to hand.  Unlike normal C-style
dereferencing, dereferencing a pointer-to-member is a binary
operator.  The concrete C++ syntax looks like:
\begin{verbatim}
   int f(int C::* cintptr, C c)
   {
     return c.*cintptr;
   }
\end{verbatim}
There is also a \texttt{->*} operator for when one has a pointer to a
class (by analogy with the \texttt{->} operator for field
dereferencing).  In the abstract syntax, the one operator is called
\texttt{OffsetDeref}.\index{OffsetDeref@\texttt{OffsetDeref}}

The rule is complicated by the fact that if the pointer to a member is
to a virtual function, then the result must be a reference to a
virtual function in the class on which the dereference is
performed.
\index{rule (dynamic)!offset-deref@\texttt{offset-deref}}%
\begin{alltt}
(* RULE-ID: offset-deref *)
     (encode_offset cnm2 fldname = SOME bl) \(\land\)
     (fld = if function_type fldty then
              let (r,a) = dest_function_type fldty
              in
                if is_virtual s cnm2 fldname r a then
                  IDConstant F [] fldname
                else
                  mk_member cnm2 fldname
            else
              mk_member cnm2 fldname)
   \(\Rightarrow\)
     mng (s, EX (OffsetDeref
                     (LVal a (Class cnm1) p)
                     (ECompVal bl (MPtr cnm2 fldty)))
                se)
         (s, EX (SVar (LVal a (Class cnm1) p) fld)
                se)
\end{alltt}
The invariant in the model is that if a reference is made to a virtual
function, then it must occur as the right-hand argument of a
field-selection as a bare name (hence the
\texttt{IDConstant~F~[]}\dots above), and conversely that if a
reference is not to a virtual function, then the field dereference
must be to a completely qualified identifier.\footnote{Note the
  contrast with C: in \cpp, one can write \texttt{c.::B::fld}, which
  is unambiguous, if ugly, about which \texttt{fld} member is meant.}

It is possible to have null member pointers
(see~\cite[\S4.11]{cpp-standard-iso14882}).  We specify
\texttt{encode_offset} in such a way that the null member pointer
constant is not in its range, and add the rule
\index{rule (dynamic)!offset-deref-fails@\texttt{offset-deref-fails}}%
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: offset-deref-fails *)
     T
   \(\Rightarrow\)
     mng (s, EX (OffsetDeref
                   (LVal a (Class cnm1) p)
                   (ECompVal null_member_ptr (MPtr cnm2 fldty)))
                se)
         (s, EX UndefinedExpr se)
\end{alltt}
\end{minipage}
\end{center}
It is undefined behaviour to apply the null member pointer to any
class.

\paragraph{Assignment}
The rules for assignment do not need to change from their presentation
in C.  Nonetheless, this semantics adopts Clive
Feather's\index{Feather, Clive} proposal~\cite{Feather2000} for
handling the infamous language in the standard:
\begin{quotation}
\itshape
    Between the previous and next sequence point an  object
    shall  have  its  stored  value modified at most once by the
    evaluation of an expression.  Furthermore, the  prior  value
    shall  be  accessed  only  to  determine  the  value  to  be
    stored.
\end{quotation}
Rather than count references made on the RHS of an assignment, as in
my thesis~\cite{Norrish98}, the model now is that references can occur
before updates, but not the other way round.  This makes the rules for
assignment considerably simpler, at the cost of requiring an analysis
of all possible execution paths to see if any of them result in an
update before a reference.

\index{Assign@\texttt{Assign}}%
The rule for a completed assignment expression is presented in
Figure~\ref{fig:assign-completes}.
\begin{figure}[htbp]
\begin{center}
\index{rule (dynamic)!assign-completes@\texttt{assign-completes}}%
\begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: assign-completes *)
    \(\neg\)class_type lhs_t \(\land\)
    (nonclass_conversion s (v0,t0) (v,lhs_t) \(\land\) (* 5.17 p3 *)
     (se = add_se (a, v) se0) \(\land\) (resv = ECompVal v lhs_t)
                          \(\lor\)
     (\(\forall\)v. \(\neg\)nonclass_conversion s (v0, t0) (v, lhs_t)) \(\land\)
     (resv = UndefinedExpr) \(\land\)
     (se = se0))
   \(\Rightarrow\)
     mng (s, EX (Assign NONE (LVal a lhs_t [])
                             (ECompVal v0 t0)) se0)
         (s, EX resv se)
\end{alltt}
\end{minipage}
\end{center}
\caption{Rule for the Completion of an Assignment Expression}
\label{fig:assign-completes}
\end{figure}
The \texttt{NONE} value that is the first argument ot \texttt{Assign}
is where a binary operator can be installed, implementing the
\texttt{op=} syntax (\texttt{+=}, \texttt{>>=} etc.).  The rule that
deals with this is
\index{CApBinary@\texttt{CApBinary}}%
\index{rule (dynamic)!assign-op-assign@\texttt{assign-op-assign}}
\begin{alltt}
(* RULE-ID: assign-op-assign *)
     T
   \(\Rightarrow\)
     mng (s0, EX (Assign (SOME f) (LVal n t p) e) se0)
         (s0, EX (Assign NONE
                         (LVal n t p)
                         (CApBinary f (LVal n t p) e)) se0)

\end{alltt}
(Note that the hypothesis true (\texttt{T}) means there are no
preconditions on this transition occurring.)



\subsection{Statements in a Small-step Style}
\label{sec:small-step-stmts}

One might imagine that stating the statement part of a dynamic
semantics in a small-step style should be easy.  (My
thesis~\cite[\S7.1]{Norrish98} explains why the way I formulated
statements in a big-step style was a mistake.) The literature contains
many examples of how to express constructs such as \texttt{while} and
\texttt{if} in a small-step style.  However, in C and \cpp{} this is
not as straightforward as one might think because of the need to
prevent function bodies from interleaving.

Imagine a program such as that in Figure~\ref{fig:two-functions}, and
how one might evaluate the return-expression in \texttt{main}.  If one
simply expanded the bodies of the called functions into the expression
as the functions were ready to be called, one would be permitting the
simultaneous evaluation of the bodies of \texttt{f} and \texttt{g}.
But the \cpp{} standard explicitly forbids this (\S1.8~fn8), and the C
standard also hints that it is forbidden.
\begin{figure}[htbp]
\begin{verbatim}
   int global;
   int f(int x) { return global * 2 + x; }
   int g(int y) { while (y > 0) { global += 2; y--; } }

   int main(void) {
     global = 10;
     return f(6) + g(10);
   }
\end{verbatim}
\caption{Where Functions Must Not Interleave}
\label{fig:two-functions}
\end{figure}

One has to arrange the semantics so that expression evaluation can
continue non-deterministically until a function call is encountered
and the function call is made (after arguments have been evaluated).
At this point, all further evolution of the program must occur within
the function body, no matter how deeply nested the function call may
have been within an enclosing expression.  (This problem does not
occur if statement evaluation is big-step because the hypothesis in
the expression rule for a function call would be a statement rule that
required the complete evaluation of the function body.)

\index{FnApp@\texttt{FnApp}} At the base level, a function call turns
an \texttt{EX} piece of syntax into an extended expression tagged with
\texttt{ST}.  The rule \ruleid{global-function-call} of
Figure~\ref{fig:global-function-call} governs (normal) function calls:
\begin{figure}[hbtp]
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!global-function-call@\texttt{global-function-call}}%
\begin{alltt}
(* RULE-ID: global-function-call *)
     find_best_fnmatch s0 fnid (MAP valuetype args)
                       rtype params body \(\land\)
     (pdecls = MAP (\(\lambda\)((n,ty),a).
                       VDecInit ty (Base n)
                                   (CopyInit (EX a base_se)))
                   (ZIP (params, args)))
   \(\Rightarrow\)
     mng (s0, EX (FnApp_sqpt (FVal fnid ftype NONE) args) se)
         (s0 with <| stack updated_by
                       (CONS (s0.env, s0.thisvalue,
                              s0.allocmap));
                     thisvalue := NONE;
                     blockclasses updated_by stackenv_newscope ;
                     exprclasses updated_by stackenv_newscope ;
                     env := empty_env |>,
          ST (Block T pdecls [body]) (return_cont se rtype))
\end{alltt}
\end{minipage}
\end{center}
\caption{Making a Call to a Global (\ie, Non-member) Function}
\label{fig:global-function-call}
\end{figure}

\index{return_cont@\texttt{return_cont}}%
(For the details behind \texttt{return_cont}, and the \texttt{RVC}
function that appears in the next rule, see
Section~\ref{sec:refs-returned-from-fns}.  For the operations applied
to \texttt{s0}, setting up the new function's scope, see
Section~\ref{sec:statements-blocks}.)  At this point, the standard
rule for evaluating an expression within a context
(\ruleid{expr-econtext}, p\pageref{rule:econtext-expr}) can not fire,
because its hypothesis is of the form
\[
\texttt{mng (s0, EX e0 se0) (s, EX e se)}
\]
Instead, the new rule
\label{rule:econtext-stmt}
\begin{alltt}
(* RULE-ID: econtext-stmt *)
     mng (s0, EX e se0) (s, ST stmt c) \(\land\)
     valid_econtext f
   \(\Rightarrow\)
     mng (s0, EX (f e) se0) (s, ST stmt (cont_comp f c))
\end{alltt}
can fire, turning the enclosing expression into a statement form, with
an ever more elaborate continuation.   The r\^ole of the continuation
is to do no more than record where the function-call was, so that when
the statement form finishes execution, its result can be slotted back
into the appropriate expression.

These rules have specified what happens when an expression evaluation
switches to a statement evaluation.  In the opposite direction, when a
function call is about to return, one of the rules is
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!return-rvalue@\texttt{return-rvalue}}
\label{rule:return-rvalue}
\begin{alltt}
(* RULE-ID: return-rvalue *)
     is_null_se se0
   \(\Rightarrow\)
     mng (s, ST (Ret (EX (ECompVal v t) se0)) (RVC c se))
         (s, EX (c (ECompVal v t)) se)
\end{alltt}
\end{minipage}
\end{center}
In this situation, the \texttt{return} statement has completely
evaluated its argument into a value, and there are no remaining side
effects to be evaluated.  This means that the value can be put back
into the containing expression tree, and expression evaluation can
continue.  This is reflected by the switch from \texttt{ST} to
\texttt{EX}, and the application of the continuation \texttt{c} to the
value.

Note how the argument to the return statement is itself an extended
expression.  This means that the argument will be tagged with
\texttt{EX} initially, but may later evolve to be a statement and
continuation (tagged with \texttt{ST}) if the return-expression
includes a function call.  This means that the rule for evaluation of
the argument of return is
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!return-eval-under@\texttt{return-eval-under}}
\begin{alltt}
(* RULE-ID: return-eval-under *)
     mng (s1, exte0) (s2, exte)
   \(\Rightarrow\)
     mng (s1, ST (Ret exte0) c) (s2, ST (Ret exte) c)
\end{alltt}
\end{minipage}
\end{center}
where \texttt{exte0} and \texttt{exte} may be statements or
expressions.

\paragraph{Statement Evaluation Strategy}
The basic idea behind all of the rules for statements are that they
should be evaluated until they yield a ``final'' form.  As is
explained further in Section~\ref{sec:refs-returned-from-fns} below,
such an evaluation has to be done in the context of the continuation
that is accompanying the statement.  In essence, a final form is both
one that can not be further evaluated, and also something that can be
returned to a higher level as some sort of result.  The definition of
\texttt{final_stmt} is from \HOLfile{statements}:
\index{final_stmt@\texttt{final_stmt}|textbf}%
\index{final_value@\texttt{final_value}}%
\begin{alltt}
  (final_stmt EmptyStmt c = T) \(\land\)
  (final_stmt Break c = T) \(\land\)
  (final_stmt Cont c = T) \(\land\)
  (final_stmt (Ret e) c =
     case c of
        LVC f se0 -> (\(\exists\)a t p se. (e = EX (LVal a t p) se) \(\land\)
                                 is_null_se se)
     || RVC f se0 -> final_value e) \(\land\)
  (final_stmt (Throw exn) c = \(\exists\)e. (exn = SOME e) \(\land\)
                                  final_value e) \(\land\)
  (final_stmt _ c = F)
\end{alltt}
\index{Throw@\texttt{Throw}}%
\index{EmptyStmt@\texttt{EmptyStmt}}%
\index{Ret@\texttt{Ret}}%
The \texttt{Throw} form implements exceptions (for which, see
Section~\ref{sec:exceptions}); most statements will evaluate to either
an \texttt{EmptyStmt}, or a \texttt{Ret}.

\subsubsection{Simple Statements}
\label{sec:simple-statements}

The rules for the simplest statement forms, expression statements
(using the \texttt{Standalone}
``constructor''\index{Standalone@\texttt{Standalone}}) and
if~statements are given in Figure~\ref{fig:simple-stmts}.  While an
expression statement explicitly terminates (yielding an
\texttt{EmptyStmt}), the if statement just evolves into one of its two
branches.
\begin{figure}[htbp]
\index{rule (dynamic)!standalone-evaluates@\texttt{standalone-evaluates}}%
\index{rule (dynamic)!standalone-finishes@\texttt{standalone-finishes}}%
\index{rule (dynamic)!if-eval-guard@\texttt{if-eval-guard}}%
\index{rule (dynamic)!if-true@\texttt{if-true}}%
\index{rule (dynamic)!if-false@\texttt{if-false}}%
\index{CIf@\texttt{CIf}}
\begin{alltt}
(* RULE-ID: standalone-evaluates *)
     mng (s1, exte) (s2, exte')
   \(\Rightarrow\)
     mng (s1, ST (Standalone exte) c)
         (s2, ST (Standalone exte') c)


(* RULE-ID: standalone-finishes *)
     is_null_se se \(\land\)
     final_value e
   \(\Rightarrow\)
     mng (s, ST (Standalone e) c) (s, ST EmptyStmt c)


(* RULE-ID: if-eval-guard *)
     mng (s0, RVR guard) (s, RVR guard')
   \(\Rightarrow\)
     mng (s0, ST (CIf guard t e) c)
         (s, ST (CIf guard' t e) c)


(* RULE-ID: if-true *)
     scalar_type t \(\land\)
     is_null_se se \(\land\)
     \(\neg\)is_zero t v
   \(\Rightarrow\)
     mng (s, ST (CIf (EX (ECompVal v t) se) thenstmt elsestmt) c)
         (s, ST thenstmt c)


(* RULE-ID: if-false *)
     scalar_type t \(\land\)
     is_null_se se \(\land\)
     is_zero t v
   \(\Rightarrow\)
     mng (s, ST (CIf (EX (ECompVal v t) se) thenstmt elsestmt) c)
         (s, ST elsestmt c)
\end{alltt}
\caption{Statement Rules for Expression and If Statements}
\label{fig:simple-stmts}
\end{figure}

\index{loops}%
\index{CLoop}%
\paragraph{Loops} The loop forms in \cpp{} are modelled just as they
were in my thesis~\cite[\S3.4.5]{Norrish98}, as syntactic sugar for
forms involving one loop and different arrangements of the
\texttt{Trap}, \texttt{continue} and \texttt{break} primitives.
This allows just one, unconditional rule for all loops:
\begin{center}
  \begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: loop *)
     T
   \(\Rightarrow\)
     mng (s, ST (CLoop guard bdy) c)
         (s, ST (CIf guard (Block F [] [bdy; CLoop guard bdy])
                           EmptyStmt) c)
\end{alltt}
  \end{minipage}
\end{center}

\paragraph{Traps, and Loop Interruptions}
\index{Trap@\texttt{Trap}}%
\index{Break@\texttt{Break}}%
\index{Cont@\texttt{Cont}}%
Again, following my thesis, the rules for traps are straightforward,
though relatively plentiful because of the different possible
combinations of \texttt{continue} (written \texttt{Cont}) and
\texttt{break} (written \texttt{Break}).  The simplest rules for these
forms are presented in Figure~\ref{fig:traps}.  The rule for the way
in which \texttt{break}, \texttt{continue}, \texttt{return} and
exceptions all cause flow of control to alter within a block is
presented in Section~\ref{sec:statements-blocks} below.

\begin{figure}[htbp]
\index{rule (dynamic)!trap-stmt-evaluation@\texttt{trap-stmt-evaluation}}%
\index{rule (dynamic)!trap-break-catches@\texttt{trap-break-catches}}%
\index{rule (dynamic)!trap-continue-catches@\texttt{trap-continue-catches}}%
\index{rule (dynamic)!trap-continue-pass-break@\texttt{trap-continue-pass-break}}%
\index{rule (dynamic)!trap-break-pass-continue@\texttt{trap-break-pass-continue}}%
\index{rule (dynamic)!trap-emptystmt-passes@\texttt{trap-emptystmt-passes}}%
\index{rule (dynamic)!trap-ret-passes@\texttt{trap-ret-passes}}%
\begin{alltt}
(* RULE-ID: trap-stmt-evaluation *)
     mng (s0, ST st c) (s, ST st' c)
   \(\Rightarrow\)
     mng (s0, ST (Trap tt st) c) (s, ST (Trap tt st') c)

(* RULE-ID: trap-break-catches *)
     T
   \(\Rightarrow\)
     mng (s, ST (Trap BreakTrap Break) c) (s, ST EmptyStmt c)

(* RULE-ID: trap-continue-catches *)
     T
   \(\Rightarrow\)
     mng (s0, ST (Trap ContTrap Cont) c) (s0, ST EmptyStmt c)

(* RULE-ID: trap-continue-passes-break *)
     T
   \(\Rightarrow\)
     mng (s, ST (Trap ContTrap Break) c) (s, ST Break c)

(* RULE-ID: trap-break-passes-continue *)
     T
   \(\Rightarrow\)
     mng (s, ST (Trap BreakTrap Cont) c) (s, ST Cont c)

(* RULE-ID: trap-emptystmt-passes *)
     T
   \(\Rightarrow\)
     mng (s0, ST (Trap tt EmptyStmt) c) (s0, ST EmptyStmt c)

(* RULE-ID: trap-ret-passes *)
     final_value e
   \(\Rightarrow\)
     mng (s, ST (Trap tt (Ret e)) c) (s, ST (Ret e) c)
\end{alltt}
  \caption{Dynamic Rules for Loop Interruptions and Traps}
  \label{fig:traps}
\end{figure}

\paragraph{Declarations in Guards}
\cpp{} allows variables to be declared in the guard positions of loop
forms and if statements.  This is a syntactic nicety that we can assume
has been compiled away.  For example, something like
\begin{verbatim}
   if (int i = e) { ... }
\end{verbatim}
can be rewritten into
\begin{verbatim}
   { int i = e; if (i) { ... } }
\end{verbatim}
I take a similar attitude to \cpp's relaxation of C's rule that
declarations and statements can intermingle.  Such an intermingling
can be rewritten to successive nested blocks, all of which respect the
basic C rule that a block is a sequence of declarations followed by a
sequence of statements.

\subsubsection{Statements in Blocks}
\label{sec:statements-blocks}

\index{Block@\texttt{Block}}
The compound statement is the basic syntactic structure expressing
scope at the statement level.  Its manifestation in this model is as
the constant \texttt{Block}, with type
\begin{verbatim}
   : bool -> var_decl list -> CStmt list -> CStmt
\end{verbatim}
The initial boolean field is used to record whether or not a block has
been entered.  It starts as false (\texttt{F}).  The rule for entering
a block is
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-entry@\texttt{block-entry}}
\begin{alltt}
(* RULE-ID: block-entry *)
     T
   \(\Rightarrow\)
     mng (s, ST (Block F vds sts) c)
         (s with <| stack updated_by
                      (CONS (s.env, s.thisvalue, s.allocmap));
                    blockclasses updated_by
                      stackenv_newscope ;
                    exprclasses updated_by
                      stackenv_newscope |>,
          ST (Block T vds sts) c)
\end{alltt}
\end{minipage}
\end{center}
\index{stack (state field)@\texttt{stack} (\texttt{state} field)}%
\index{env (state field)@\texttt{env} (\texttt{state} field)}%
The \texttt{blockclasses} and \texttt{exprclasses} fields are to do
with pending destructor calls, and are further explained in
Section~\ref{sec:exceptions}.  The field \texttt{stack} is a stack of
local environments, coupled with a stack of values for the
\texttt{this} pointer.  When a block is entered, the old value for
the environment needs to be stored so that it can be restored on block
exit.  Recall that the field \texttt{env} stores all of the
information about \emph{local} entities.  Information on non-local
entities is all recorded in the \texttt{genv} field.

After a block is entered, its variable declarations must be executed.
This is handled by the rule \ruleid{block-declmng}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-declmng@\texttt{block-declmng}}
\begin{alltt}
(* RULE-ID: block-declmng *)
     declmng mng (d0, s0) (ds, s)
   \(\Rightarrow\)
     mng (s0, ST (Block T (d0 :: vds) sts) c)
         (s, ST (Block T (ds ++ vds) sts) c)
\end{alltt}
\end{minipage}
\end{center}
\index{declmng relation@\texttt{declmng} relation}%
The auxiliary \texttt{declmng} (which takes \texttt{mng} as a
parameter, allowing it to recurse back to it) has type
\begin{verbatim}
   : ((state # ExtE) -> (state # ExtE) -> bool) ->
     (var_decl # state) -> (var_decl list # state) -> bool
\end{verbatim}
The ``return'' of a list of new variable declarations allows
termination to be indicated (by returning the empty list), and also
allows complicated object constructions, which involve multiple calls
to initialise sub-objects, done through special forms of variable
declaration.  There is more on the simple forms of \texttt{declmng} in
Section~\ref{sec:simple-declarations} below.

When the declaration list is exhausted, execution of a block's body of
statements can proceed.  The congruence rule for a block is
\ruleid{block-stmt-evaluate}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-stmt-evaluate@\texttt{block-stmt-evaluate}}%
\begin{alltt}
(* RULE-ID: block-stmt-evaluate *)
     mng (s0, ST st c) (s, ST st' c)
   \(\Rightarrow\)
     mng (s0, ST (Block T [] (st :: sts)) c)
         (s, ST (Block T [] (st' :: sts)) c)
\end{alltt}
\end{minipage}
\end{center}
Note the form of \texttt{Block} required: it must have no further
variable declarations to evaluate, and must have been entered (has its
boolean flag set to~\texttt{T}).

\index{EmptyStmt@\texttt{EmptyStmt}}
If the first statement inside a \texttt{Block} is, or becomes, an
\texttt{EmptyStmt}, and there are more statements beyond it to
evaluate, then the \texttt{EmptyStmt} can be discarded:
\begin{center}
  \begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: block-emptystmt *)
     \(\neg\)(sts = [])
   \(\Rightarrow\)
     mng (s, ST (Block T [] (EmptyStmt::sts)) c)
         (s, ST (Block T [] sts) c)
\end{alltt}
\end{minipage}
\end{center}

Alternatively, if the head statement is an exception or interruption
form, and it is followed by other statements, then it causes all
following statements to disappear:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-interrupted@\texttt{block-interrupted}}
\begin{alltt}
(* RULE-ID: block-interrupted *)
     final_stmt exstmt c \(\land\)
     \(\neg\)(exstmt = EmptyStmt) \(\land\)
     \(\neg\)(sts = [])
   \(\Rightarrow\)
     mng (s, ST (Block T [] (exstmt::sts)) c)
         (s, ST (Block T [] [exstmt]) c)
\end{alltt}
\end{minipage}
\end{center}

Then, when a final statement is the only thing remaining in a block,
the block itself can exit, clearing its local stack frame in the
environment, and propagating the final statement upwards.  This gives
us \ruleid{block-exit}, in Figure~\ref{fig:block-exit}.
\begin{figure}
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-exit@\texttt{block-exit}}
\begin{alltt}
(* RULE-ID: block-exit *)
     (s.stack = (env,this,amap) :: stk') \(\land\)
     final_stmt st c \(\land\)
     (s.blockclasses = []::bcs) \(\land\)
     (s.exprclasses = []::ecs)
   \(\Rightarrow\)
     mng (s, ST (Block T [] [st]) c)
         (s with <| stack := stk';
                    allocmap := amap;
                    env := env;
                    thisvalue := this;
                    blockclasses := bcs;
                    exprclasses := ecs |>,
          ST st c)
\end{alltt}
\end{minipage}
\end{center}
\caption{Exiting a block}
\label{fig:block-exit}
\end{figure}
\index{blockclasses (state field)@\texttt{blockclasses} (\texttt{state} field)}%
By requiring that the \texttt{blockclasses} and \texttt{exprclasses}
components of the state be empty at their heads, we require that all
local objects have had their destructors called (for more on this, see
Section~\ref{sec:object-lifetimes}).  If this condition is met, the
various stacks can be popped, and the final statement lifted up a
level.  In this way, a return statement deep within multiple blocks
can eventually make its way to the top level, where its value can be
passed to the continuation through rules \ruleid{return-rvalue}
(page~\pageref{rule:return-rvalue}) or \ruleid{return-lvalue}
(page~\pageref{rule:return-lvalue}).

\index{ST@\texttt{ST}} \index{EX@\texttt{EX}} Such a return can not
happen prematurely: the two \texttt{return} rules both have
\texttt{EX} tags in their ``result'' arguments, and the rule
\ruleid{block-stmt-evaluate}, as well as all the other rules calling
for statement evaluation recursively, requires its recursive call to
be an \texttt{ST}-to-\texttt{ST} evaluation.

\subsubsection{Simple Declarations}
\label{sec:simple-declarations}

This section discusses simple declaration forms, which are treated in
a way that is similar to the treatment in my thesis.  Declarations
involving class types are typically not simple, and are discussed in
Sections~\ref{sec:basic-oo} (basic object orientiation)
and~\ref{sec:object-lifetimes} (object lifetimes). There are two
simple forms of declaration: a bare declaration of a variable, such as
\begin{verbatim}
   int x;
\end{verbatim}
or a declaration coupled with an initialisation
\begin{verbatim}
   int x = 3;
\end{verbatim}
\index{VDec@\texttt{VDec}} \index{VDecInit@\texttt{VDecInit}} These
two different forms are represented with the constructors
\texttt{VDec} and \texttt{VDecInit} respectively, both constructing
values in the \texttt{var_decl} type.

\index{declmng relation@\texttt{declmng} relation}%
As already mentioned, the \cpp{} mechanisation uses an auxiliary
relation \texttt{declmng} to do most variable declaration work.  This
relation is defined in \HOLfile{declaration_dynamics}.  Its simplest
rule is
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-vdec-nonclass@\texttt{decl-vdec-nonclass}}%
\begin{alltt}
(* RULE-ID: decl-vdec-nonclass *)
     vdeclare s0 ty name s \(\land\)
     object_type ty \(\land\)
     \(\neg\)class_type (strip_array ty)
   \(\Rightarrow\)
     declmng mng (VDec ty name, s0) ([], s)
\end{alltt}
  \end{minipage}
\end{center}
\index{vdeclare@\texttt{vdeclare}}
This rule states that if one is declaring a variable of non-class type
(and which is not an array of a class type), then it suffices to
allocate space for it through the \texttt{vdeclare} relation, storing
its address in the appropriate part of the state's environment, and
also recording the type.  The empty list in the second argument to
\texttt{declmng} signals that no further work needs to be done for
this declaration.

When a variable is to be initialised, this can occur as a direct
initialisation:
\begin{verbatim}
   int x(3);
\end{verbatim}
or as a copy-initialiation:
\begin{verbatim}
   inx x = 3;
\end{verbatim}
\index{DirectInit0@\texttt{DirectInit0}}%
For non-classes this syntactic difference makes no difference in
behaviour.  The first rule is for the direct initialisation
(\texttt{DirectInit0} form), where the transition is immediately to a
copy-initialisation:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-init-start-eval-dnonclass@\texttt{decl-init-start-eval-dnonclass}}
\begin{alltt}
(* RULE-ID: decl-vdecinit-start-evaluate-direct-nonclass *)
     ~class_type ty \(\land\)
     vdeclare s0 ty name s \(\land\)
     (SOME (a,pth) = lookup_addr s name) \(\land\)
     (loc = if ref_type ty then RefPlace NONE name
            else ObjPlace a)
   \(\Rightarrow\)
     declmng mng
             (VDecInit ty name (DirectInit0 [arg]), s0)
             ([VDecInitA ty loc (CopyInit (EX arg base_se))], s)
\end{alltt}
\end{minipage}
\end{center}
\index{VDecInitA@\texttt{VDecInitA}}%
\index{vdeclare@\texttt{vdeclare}}%
The transition is to the \texttt{VDecInitA} form, which records where
the initialisation is to be performed.  The \texttt{vdeclare} relation
is used, as before, to allocate space for the new object, and
subsequent steps in the evaluation of the declaration will fill this
space in.  (In the case of a reference, \texttt{vdeclare} will not
allocate any space, but will record a type for the new name.)

\index{CopyInit@\texttt{CopyInit}}%
The rule for the \texttt{CopyInit} form is similar: there is a
transition to the \texttt{VDecInitA} form and a call to
\texttt{vdeclare}. (As it happens this rule can be applied for the
declaration and initialisation of class objects too.)
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-init-start-eval-copy@\texttt{decl-init-start-eval-copy}}%
\begin{alltt}
(* RULE-ID: decl-init-start-eval-copy *)
     vdeclare s0 ty name s \(\land\)
     (SOME (a,pth) = lookup_addr s name) \(\land\)
     (loc = if ref_type ty then RefPlace NONE name
            else ObjPlace a)
   \(\Rightarrow\)
     declmng mng
             (VDecInit ty name (CopyInit arg), s0)
             ([VDecInitA ty loc (CopyInit arg)], s)
\end{alltt}
\end{minipage}
\end{center}

Once a \texttt{VDecInitA} form has been achieved, the initialising
expression can be evaluated.
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-vdecinit-evaluation@\texttt{decl-vdecinit-evaluation}}%
\begin{alltt}
(* RULE-ID: decl-vdecinit-evaluation *)
     mng (s0, exte) (s, exte') \(\land\)
     ((f = CopyInit) \(\lor\) (f = DirectInit))
   \(\Rightarrow\)
     declmng mng (VDecInitA ty loc (f exte), s0)
                 ([VDecInitA ty loc (f exte')], s)
\end{alltt}
\end{minipage}
\end{center}
Note that the initialisor form \texttt{f} can only be a
\texttt{DirectInit} when initialising classes.  All non-class objects
will be a \texttt{CopyInit} form by this point.

When initialising a non-reference, expressions that yield l-values
must be allowed to undergo the ``l-value to r-value'' conversion:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-vdecinit-lval2rval@\texttt{decl-vdecinit-lval2rval}}%
\begin{alltt}
(* RULE-ID: decl-vdecinit-lval2rval *)
     lval2rval (s0,e0,se0) (s,e,se) \(\land\)
     \(\neg\)ref_type ty \(\land\)
     ((f = CopyInit) \(\lor\) (f = DirectInit))
   \(\Rightarrow\)
     declmng mng (VDecInitA ty loc (f (EX e0 se0)), s0)
                 ([VDecInitA ty loc (f (EX e se))], s)
\end{alltt}
\end{minipage}
\end{center}

\paragraph{Finishing an Initialisation}
When a non-class, non-reference initialisation is ready, the rule
\ruleid{decl-vdecinit-finish} of Figure~\ref{fig:decl-vdecinit-finish}
will apply.  The value of the initialising expression is first
converted to be of the appropriate type, and the resulting value
(\texttt{v'}, a list of bytes), is copied into memory using the
\texttt{val2mem}\index{val2mem@\texttt{val2mem}} relation.  Note that
the state's \texttt{initmap} is also initialised in the
process.  The fact that the location attached to the
\texttt{VDecInitA} constructor is an \texttt{ObjPlace} ensures that
the variable being initialised is not a reference.%
\index{initmap (state field)@\texttt{initmap} (\texttt{state} field)}%
\begin{figure}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-vdecinit-finish@\texttt{decl-vdecinit-finish}}%
\index{nonclass_conversion@\texttt{nonclass_conversion}}%
\begin{alltt}
(* RULE-ID: decl-vdecinit-finish *)
     nonclass_conversion s0 (v,ty) (v',dty) \(\land\)
     is_null_se se \(\land\)
     ~class_type dty \(\land\)
     (s = val2mem (s0 with initmap updated_by (UNION) rs) a v') \(\land\)
     (rs = range_set a (LENGTH v')) \(\land\)
     ((f = CopyInit) \(\lor\) (f = DirectInit))
   \(\Rightarrow\)
     declmng mng (VDecInitA dty
                            (ObjPlace a)
                            (f (EX (ECompVal v ty) se)), s0)
                 ([], s)
\end{alltt}
\end{minipage}
\caption[Finishing Initialisation of a Non-class, Non-reference
  Variable]{Completing the Initialisation of a Non-class, Non-reference
  Variable}
\label{fig:decl-vdecinit-finish}
\end{figure}

\subsection{Exceptions}
\label{sec:exceptions}
\newcommand{\ethrow}{\texttt{EThrow}}

Exceptions are modelled in a way similar to the treatment of
\texttt{return}, \texttt{break} and \texttt{continue}.  One difference
is that exceptions propagate further: the \texttt{return} ``value''
only propagates up as far as a function call (within an expression).
In contrast, an exception will continue to propagate up through the
call-stack until it hits a suitable handler.

\index{EThrow@\texttt{EThrow}} \index{Throw@\texttt{Throw}} This much
allows a preliminary sketch of the behaviour.  The \texttt{throw} form
is actually an expression (\texttt{EThrow}), but we set things up so
that there is a statement-level version of \texttt{throw} as well
(\texttt{Throw}), and it will be this that propagates through
statement syntax.  The rule \ruleid{expression-throw-some} describes
the behaviour when \texttt{EThrow} has an argument:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!expression-throw-some@\texttt{expression-throw-some}}%
\begin{alltt}
(* RULE-ID: expression-throw-some *)
     T
   \(\Rightarrow\)
     mng (s, EX (EThrow (SOME e)) se)
         (s, ST (Throw (SOME (EX e se))) c)
\end{alltt}
\end{minipage}
\end{center}
The variable \texttt{c} represents the continuation that would
normally convert the result of the statement into a value to be
inserted into a containing expression tree.  Because thrown
values can't ever turn into values until they initialise a handler,
this $c$ can be anything at all.

At the statement level, the \texttt{Throw} form takes an extended
expression as an argument.  This evaluates its argument as one might
expect (rule \ruleid{throw-expr-evaluation})
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: throw-expr-evaluation *)
     mng (s0, RVR e0) (s, RVR e)
   \(\Rightarrow\)
     mng (s0, ST (Throw (SOME e0)) c) (s, ST (Throw (SOME e)) c)
\end{alltt}
\end{minipage}
\end{center}

When a \texttt{throw}'s expression has been completely evaluated, we
have something that can then propagate upwards through the abstract
syntax of statements.

We already have a rule specifying how \texttt{throw}-statements traverse
\texttt{Block} values: \ruleid{block-interrupted}, repeated here:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-interrupted@\texttt{block-interrupted}}
\begin{alltt}
(* RULE-ID: block-interrupted *)
     final_stmt exstmt c \(\land\)
     \(\neg\)(exstmt = EmptyStmt) \(\land\)
     \(\neg\)(sts = [])
   \(\Rightarrow\)
     mng (s, ST (Block T [] (exstmt::sts)) c)
         (s, ST (Block T [] [exstmt]) c)
\end{alltt}
\end{minipage}
\end{center}
The predicate \texttt{final_stmt} is true of \texttt{throw} and
\texttt{return} statements with fully evaluated arguments, as well as
of \texttt{break}, \texttt{continue} and the \textsf{EmptyStmt} form.
The latter doesn't cause an interruption, so is excluded by the second
hypothesis to the rule.  The final hypothesis ensures that there isn't
an infinite loop on this rule.  The same predicate is used in the rule
for exiting a block (\ruleid{block-exit}, page~\pageref{fig:block-exit}).

There is also rule \ruleid{trap-exn-passes} for exception statements
escaping the \texttt{Trap} form (which is used for handling
\texttt{continue} and \texttt{break}):
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!trap-exn-passes@\texttt{trap-exn-passes}}%
\begin{alltt}
(* RULE-ID: trap-exn-passes *)
     exception_stmt exn
   \(\Rightarrow\)
     mng (s, ST (Trap tt exn) c) (s, ST exn c)
\end{alltt}
\end{minipage}
\end{center}

\medskip
Because exceptions arise from expressions, the statement level rules
need to acknowledge this possibility.  Thus, this rule for
\texttt{if} (\ruleid{if-exception}):
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!if-exception@\texttt{if-exception}}%
\index{CIf@\texttt{CIf}}%
\begin{alltt}
(* RULE-ID: if-exception *)
     is_exnval guard
   \(\Rightarrow\)
     mng (s, ST (CIf guard thenstmt elsestmt) c)
         (s, mk_exn guard c)
\end{alltt}
\end{minipage}
\end{center}
where the definition of \texttt{is_exnval} is (from
\HOLfile{statements})\index{is_exnval@\texttt{is_exnval}}
\begin{alltt}
   (is_exnval (ST (Throw (SOME e)) c) = final_value e) \(\land\)
   (is_exnval _ = F)
\end{alltt}
The function \texttt{mk_exn} takes an exception value and
replaces its continuation information with something appropriate for
the level of the containing statement: \index{mk_exn@\texttt{mk_exn}}
\begin{verbatim}
   mk_exn (ST (Throw (SOME e)) c0) c = ST (Throw (SOME e)) c
\end{verbatim}

Of course, exceptions can arise in all the other expressions that
appear within statement forms, so there are similar rules for the
standalone expression and \texttt{return} forms, as well as for the
statement-level \texttt{throw} form itself.  (The rule
\ruleid{expression-throw-some} turns an \texttt{EThrow} into a
\texttt{Throw} statement immediately, without evaluating the argument.
When the argument \emph{is} evaluated, it may itself cause an
exception.)

Because exceptions can arise in variable declarations, there is also a
rule for handling these.  This is \ruleid{block-declmng-exception}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-declmng-exception@\texttt{block-declmng-exception}}%
\begin{alltt}
(* RULE-ID: block-declmng-exception *)
     ((f = CopyInit) \(\lor\) (f = DirectInit)) \(\land\)
     declmng mng (d0, s0) ([VDecInitA ty loc (f e)], s) \(\land\)
     is_exnval e \(\land\)
     (e = ST (Throw (SOME ex)) c')
   \(\Rightarrow\)
     mng (s0, ST (Block T (d0 :: vds) sts) c)
         (s, ST (Block T [] [Throw (SOME ex)]) c)
\end{alltt}
\end{minipage}
\end{center}
Again, note how the continuation initially associated with the
exception (\texttt{c'}) is ignored.


\subsubsection{Handling Exceptions}

Handling exceptions is done with the \texttt{try-catch} form, which is a
sequence of handlers associated with a statement that might raise an
exception.  In the concrete syntax, programmers write something like
\newcommand{\suplus}{\ensuremath{^+}}
\newcommand{\sustar}{\ensuremath{^*}}
\begin{alltt}
   try \{
     \emph{statement}\sustar
   \}
   \emph{handler}\suplus
\end{alltt}
where a \emph{handler} is of the form
\begin{alltt}
   catch (\emph{guard}) \{ \emph{statement}\sustar \}
\end{alltt}
and a \emph{guard} can be ``\texttt{...}'' (\ie, three full-stops), a
type, or a standard parameter declaration (associating a type with a
name).

At the abstract syntax level, this is captured by the following HOL
declarations (in \texttt{statementsScript}):
\begin{alltt}
   exn_pdecl = (string option # CPP_Type) option

   stmt = ...
        | Catch of CStmt => (exn_pdecl # CStmt) list
\end{alltt}

\bigskip
\noindent
Statements can evaluate as usual under a \texttt{Catch}
\ruleid{catch-stmt-evaluation}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!catch-stmt-evaluation@\texttt{catch-stmt-evaluation}}%
\index{Catch@\texttt{Catch}}%
\begin{alltt}
(* RULE-ID: catch-stmt-evaluation *)
     mng (s0, ST st c) (s, ST st' c)
   ==>
     mng (s0, ST (Catch st hnds) c) (s, ST (Catch st' hnds) c)
\end{alltt}
\end{minipage}
\end{center}
Non-exception statements pass through \texttt{Catch} statements,
ignoring the handlers \ruleid{catch-normal-stmt-passes}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!catch-normal-stmt-passes@\texttt{catch-normal-stmt-passes}}%
\begin{alltt}
(* RULE-ID: catch-normal-stmt-passes *)
     final_stmt st c \(\land\)
     \(\neg\)exception_stmt st
   \(\Rightarrow\)
     mng (s0, ST (Catch st hnds) c) (s0, ST st c)
\end{alltt}
\end{minipage}
\end{center}

There are three rules governing how handlers interact with thrown
exceptions.  The first describes the behaviour when the handler
parameter is given as ``\texttt{...}'' \ruleid{catch-all}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!catch-all@\texttt{catch-all}}%
\begin{alltt}
(* RULE-ID: catch-all *)
     (exn = SOME (EX e base_se))
   \(\Rightarrow\)
     mng (s0, ST (Catch (Throw exn) ((NONE, hnd_body) :: rest)) c)
         (s0 with current_exns updated_by (CONS e),
          ST (Block F [] [hnd_body; ClearExn]) c)
\end{alltt}
\end{minipage}
\end{center}
\index{current_exns (state field)@\texttt{current_exns} (\texttt{state} field)}%
\index{ClearExn@\texttt{ClearExn}}%
This rule introduces two new features, the \textsf{current\_exns}
field of the program state, and the \textsf{ClearExn} statement-form.
Both are present to support the ability of programs to use
\texttt{throw} without an argument to re-throw the ``current
exception''.  This is covered below in Section~\ref{sec:throw-none}.

Otherwise, the behaviour is clear: if the top handler has
``\texttt{...}'' as its parameter, then this handler is entered (and
the other handlers are discarded).

When the top handler has an explicitly-typed parameter, the handler is
only entered if the type of the thrown value matches:
\ruleid{catch-specific-type-matches} in
Figure~\ref{fig:catch-specific-type-matches}.
\begin{figure}[htbp]
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!catch-specific-type-matches@\texttt{catch-specific-type-matches}}%
\begin{alltt}
(* RULE-ID: catch-specific-type-matches *)
     (exn = SOME (EX e base_se)) \(\land\)
     exception_parameter_match s0 pty (value_type e) \(\land\)
     (pname = case pnameopt of SOME s -> Base s
                            || NONE -> (Base " no name "))
   \(\Rightarrow\)
     mng (s0, ST (Catch
                   (Throw exn)
                   ((SOME(pnameopt, pty), hnd_body) :: rest))
                 c)
         (s0 with current_exns updated_by (CONS e),
          ST (Block F [VDecInit pty pname
                                    (CopyInit (EX e base_se))]
                      [hnd_body; ClearExn]) c)
\end{alltt}
\end{minipage}
\end{center}
\caption{Catching a Typed Exception}
\label{fig:catch-specific-type-matches}
\end{figure}

The string \texttt{" no name "} is chosen arbitrarily as the name of
the invisible temporary if the handler has just a type as its
parameter and no associated name.  This name is chosen so as to not
mask any existing names in scope (no legal \cpp{} program can have
variable names that include spaces).

If the declared type \texttt{pty} matches the type of the exception
value, then the exception value copy-initialises the parameter, and
the handler body is executed.  The constant
\texttt{exception_parameter_match} checks the match, embodying the
rules in~\cite[\S15.3, paragraph 3]{cpp-standard-iso14882}.  If there
is no match, then the remaining handlers have to be tried
\ruleid{catch-specific-type-nomatch}:
\begin{center}
  \begin{minipage}{\textwidth}
\index{rule (dynamic)!catch-specific-type-nomatch@\texttt{catch-specific-type-nomatch}}%
\begin{alltt}
(* RULE-ID: catch-specific-type-nomatch *)
     (exn = SOME (EX e base_se)) \(\land\)
     \(\neg\)exception_parameter_match s0 pty (value_type e)
   \(\Rightarrow\)
     mng (s0, ST (Catch
                    (Throw exn)
                    ((SOME(pnameopt, pty), hnd_body) :: rest))
                 c)
         (s0, ST (Catch (Throw exn) rest) c)
\end{alltt}
  \end{minipage}
\end{center}
If no handlers, remain, the exception propagates further
\ruleid{catch-stmt-empty-hnds} (generalised to allow any statements to
pass through):
\begin{center}
  \begin{minipage}{\textwidth}
\index{rule (dynamic)!catch-stmt-empty-hnds@\texttt{catch-stmt-empty-hnds}}%
\begin{alltt}
(* RULE-ID: catch-stmt-empty-hnds *)
     T
   \(\Rightarrow\)
     mng (s0, ST (Catch st []) c) (s0, ST st c)
\end{alltt}
  \end{minipage}
\end{center}

\subsubsection{Using \texttt{throw} with No Argument}
\label{sec:throw-none}

If flow of control is within an exception handler, or within a
function body that has been called from such, then it is permissible
to use the expression \texttt{throw} without any arguments to cause
the current exception to be rethrown.  This requires the model to
track what the current handled exception is.  More, the standard
requires the state to track the notion of ``most recently caught''
exception~\cite[\S15.1, paragraph 7]{cpp-standard-iso14882}), which
requires the state to track a stack of exceptions that have been
caught.

The expression version \ethrow{} is converted to the statement form as
soon as it is encountered \ruleid{expression-throw-none}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!expression-throw-none@\texttt{expression-throw-none}}%
\begin{alltt}
(* RULE-ID: expression-throw-none *)
     T
   \(\Rightarrow\)
     mng (s, EX (EThrow NONE) se) (s, ST (Throw NONE) c)
\end{alltt}
\end{minipage}
\end{center}
(The choice of $c$ is again irrelevant.)

There are then two rules for the statement form \texttt{Throw~NONE}.
If there is a current exception, all is well
\ruleid{bare-throw-succeeds}:
\begin{center}
  \begin{minipage}{\textwidth}
\index{rule (dynamic)!bare-throw-succeeds@\texttt{bare-throw-succeeds}}%
\index{current_exns (state field)@\texttt{current_exns} (\texttt{state} field)}%
\begin{alltt}
(* RULE-ID: bare-throw-succeeds *)
     (s0.current_exns = e::es)
   \(\Rightarrow\)
     mng (s0, ST (Throw NONE) c)
         (s0 with current_exns := es,
          ST (Throw (SOME (EX e base_se))) c)
\end{alltt}
\end{minipage}
\end{center}
Otherwise, the program must call the \texttt{::std::terminate} function
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!bare-throw-fails@\texttt{bare-throw-fails}}%
\begin{alltt}
(* RULE-ID: bare-throw-fails *)
     (s0.current_exns = [])
   \(\Rightarrow\)
     mng (s0, ST (Throw NONE) ct)
         (s0, ST (Standalone (EX callterminate base_se)) ct)
\end{alltt}
\end{minipage}
\end{center}
where the special expression \texttt{callterminate} is defined to be
\begin{verbatim}
   FnApp (Var (IDConstant T [IDName "std"]
                          (IDName "terminate")))
         []
\end{verbatim}

\index{ClearExn@\texttt{ClearExn}}%
Above, the rules for handlers also use a statement-form
\texttt{ClearExn}.  This special value has the following rule
\ruleid{clear-exn}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!clear-exn@\texttt{clear-exn}}
\begin{alltt}
(* RULE-ID: clear-exn *)
     (s0.current_exns = e::es)
   \(\Rightarrow\)
     mng (s0, ST ClearExn c)
         (s0 with current_exns := es, ST EmptyStmt c)
\end{alltt}
\end{minipage}
\end{center}
This ensures that when a handler finishes the most recently caught
exception is no longer recorded as such.  If a handler rethrows the
current exception, or throws a fresh exception of its own, and this
exception escapes the handler, then the flow of control will never
reach the \textsf{ClearExn}, and this rule will not fire.

\subsubsection{Exception Specifications}

The standard's \S15.4 specifies a method whereby functions can specify
which exception types they will produce.  If an unexpected exception
value occurs, this results in a call to \texttt{std::unexpected}.
This is not modelled in the dynamic semantics as it can be emulated
with a compile-time rewriting of the program.  If a function
\texttt{f} is specified to only raise exceptions X and Y, then it can
be rewritten to be
\begin{center}
\begin{minipage}{\textwidth}
\begin{verbatim}
   f(args)
   {
     try {
       body
     }
     catch (X) { throw; }
     catch (Y) { throw; }
     catch (...) { std::unexpected(); }
   }
\end{verbatim}
\end{minipage}
\end{center}

\subsubsection{Exceptions and Object Lifetimes}

Exceptions complicate the story about the construction and destruction
of objects.  When a constructor runs it will typically cause a
sequence of sub-objects to also be constructed. If at any stage, an
exception is raised during this process, then those objects that have
been constructed need to have their destructors called, but naturally,
those that haven't yet been constructed shouldn't have destructors
called.

Consider for example
\begin{alltt}
  Class::Class(objty p1) : b1(3), b2(\(e\)) \{ \(\mathit{body}\) \}
\end{alltt}
There are three objects that have their constructors called as a
result of a call to this constructor.  One is the parameter
\texttt{p1}, and the other are the base classes (or data-members)
\texttt{b1} and \texttt{b2}.  When this constructor is called,
\texttt{p1} is always eventually destroyed, but (sub-)objects
\texttt{b1} and \texttt{b2} should live on, unless $\mathit{body}$ or
$e$ cause an exception to be raised.

To get this situation to work in the model, the state's
\texttt{blockclasses} field has to record two sorts of object
construction (which are to be unwound later), sub-object creation and
normal object creation.  When a block exits normally, sub-object
destructors are not called, but instead delayed so that they can be
recorded as having the same lifetime as the enclosing object.  For
more on this, see Section~\ref{sec:object-lifetimes}.

\subsection{Basic Object-Orientation}
\label{sec:basic-oo}

The inspiration for this part of the semantics is the article by
Wasserrab~\emph{et al}~\cite{wasserrab-nst-OOPSLA06}, which provides a
detailed model for multiple inheritance in a simple \cpp-like
language.

\subsubsection{Class Declarations}
\label{sec:class-declaration}
A class declaration is similar to the original C model's declaration
of a \texttt{struct} type.  A class declaration takes two parameters,
the name of the class, and an optional ``class-info''
argument.\footnote{The information argument is optional to allow the
  situation where a forward declaration of a class occurs.}  The
class-info, if present, is a list of fields, coupled with a list of
ancestors.  The latter allows inheritance from zero or many ancestors.
Each ancestor is coupled with a boolean flag indicating whether or not
it is a \texttt{virtual} ancestor.  As the model ignores protection
issues, there is no scope for indicating protection status for
ancestors.

The fields are of two sorts, declarations of members (whether of
``data'' fields or member functions), and nested classes.  Member
declarations are accompanied by a flag indicating whether or not they
are static, and a protection indicator (i.e., \texttt{public},
\texttt{protected}, or \texttt{private}).  Again, protection
information is entirely ignored: any field access is assumed to have
been OK-ed earlier by the compiler.

Member function definitions give the function's name, return-type,
parameter list (types and names), function body, and a flag indicating
whether or not it is virtual.  (Of course, even in the absence of an
explicit declaration that a member function is virtual, it may be so
because of an ancestor's prior declaration.)

When a class declaration is encountered , its member functions are
entered into the state's function map.  The same function map is used
for normal (non-class) functions, but the structured nature of \cpp{}
identifiers allows the model to distinguish both sorts of function.

\subsubsection{Class Values and Member Functions}
\label{sec:class-values}
Classes can not be converted into r-values like other values.  This is
because of the problems that arise with multiple inheritance.  In
particular, with multiple inheritance in place, it is no longer true
that one can extract the byte sequence for a given l-value by starting
at the base address and taking as many bytes from memory as the size
of the type.  In particular, virtual base classes may be at completely
different places in memory, not necessarily even contiguous with the
rest of the object.  (This is demonstrated for the \texttt{g++}
compiler by the little program in
\texttt{notes/mult-inheritance-layout.cpp}.)

Absence of support for r-values means that, in this model, one can not
assign classes, pass them as parameters, or return them from
functions.  However, because references are supported (see
Section~\ref{sec:reftypes}) much idiomatic \cpp{} is still covered by
the model.

\index{LVal@\texttt{LVal}!and dynamic types}
%
The presence of classes means that the model's presentation of
l-values changes from the way it was in the original C model.  In
particular, an l-value that is statically typed as a base class needs
to know dynamically that it is really of a derived type.  This
information is traditionally recorded in \texttt{vtable} fields.
Following Wasserrab~\emph{et al}, my model instead records an
additional path accompanying every l-value.  This path is a list of
strings, listing the path through the ancestry-tree that leads from
the most-derived class to the static class type.  Moreover, the type
that accompanies every l-value (recall that the \texttt{LVal}
constructor takes three arguments, an address, a type and a list of
identifiers), will have as the type, the \emph{dynamic} type
of the l-value.

\index{member functions!virtual}
Consider, for example, the code in Figure~\ref{fig:oo-example}.  The
body of function \texttt{g} constructs the l-value \texttt{*b} when it
calls \texttt{f}.  As in the C model, this l-value will be associated
with some address, and the static type, which is \texttt{Class~B}.
The actual l-value will be of the form
\begin{alltt}
   LVal a (Class D2) [D2,D1,B]
\end{alltt}
The last element of the paths in l-values is always the static class
of the value.

In Figure~\ref{fig:oo-example}, the expression of interest is
\texttt{b->f()}, which is syntactic sugar for \texttt{((*b).f)()}.
(Note how the member selection is syntactically subordinate to the
function application.)  The \ruleid{virtual-fn-member-select}
rule (see Figure~\ref{fig:virtual-fn-member-select}) governs the
evaluation of \texttt{(*b).f} once the left-hand-side (\texttt{*b})
has evaluated to an l-value.\footnote{Even when the model allows for
  class r-values, they will be given a memory location (and thus, a
  life-time).  This will enable them to also be l-values.  In essence,
  it is not possible to create an object of any sort without giving it
  a location.  Contrast numbers, which can be ``created'', and not
  given a memory location, simply by writing them down.}

\begin{figure}[hbtp]
\begin{verbatim}
   class B {
     public: virtual int f() { return 3; }
   };

   class D1 : public B {
     public: int f() { return 4; }
   };

   class D2 : public D1 { };

   int g(class B *b) { return b->f(); }

   int main()
   {
     D2 d;
     return g(&d);
   }
\end{verbatim}
  \caption[\cpp{} Code Demonstrating OO-Polymorphism]{\cpp{} code
    demonstrating OO-polymorphism.  The program will return 4. Though
    it appears as if \texttt{B}'s function \texttt{f} is called, the
    version of \texttt{f} called will actually be that attached to
    \texttt{D1}.}
\label{fig:oo-example}
\end{figure}

\begin{figure}[hbtp]
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!virtual-fn-member-select@\texttt{virtual-fn-member-select}}%
\begin{alltt}
(* RULE-ID: virtual-fn-member-select *)
     (s,\lbr\rbr) |- LAST Cs has least method
                 (IDName fld) -:
                 (static_retty,F,args0,body0) via
                 Ds \(\land\)
     (s,\lbr\rbr) |- (C,Cs ^ Ds) selects
                 (IDName fld) -:
                 (dyn_retty,F,args,body) via
                 Cs'
   \(\Rightarrow\)
     mng (s, EX (SVar (LVal a (Class C) Cs)
                      (IDConstant F [] (IDName fld))) se)
         (s, EX (FVal (mk_member (LAST Cs') (IDName fld))
                      (Function dyn_retty (MAP SND args))
                      (SOME (LVal a (Class C) Cs'))) se)

\end{alltt}
\end{minipage}
\end{center}
\caption{The Rule for Virtual Member Function Dispatch}
\label{fig:virtual-fn-member-select}
\end{figure}

\index{vtables}
In our model, the l-value's address will be the same as the address of
its most-derived class.  In other words, the \texttt{a} of the rule
will be the same as the address of the object \texttt{d}.  This is not
what happens in typical compilers, which will actually make the
pointer to the \texttt{B} sub-class point at the address of that
sub-object's fields in the wider object's memory layout.  Then, the
fact that the most-derived class is a \texttt{D2} is implicitly
recorded in the \texttt{vtable}, which will contain a pointer to
\texttt{D1::f}.

In the rule, the variable \texttt{C} containing the name of the static
class will be \texttt{D2}, and \texttt{Cs}, the path variable, will be
\texttt{[D2,D1,B]}.  The \texttt{fld} variable will be \texttt{f}.
Then, the first hypothesis will check the class hierarchy to determine
where an \texttt{f} can be found, starting at the static type, i.e.,
at \texttt{B}.  This will reveal that, with respect to \texttt{B}
there is an \texttt{f} at path \texttt{[B]}.  This will be the value
for \texttt{Ds}.  The same check determines four pieces of information
about the function: its static return type (in the variable
\texttt{static_retty}, that it is not static (virtual functions can
not be static), and what its arguments and body are (\texttt{args0},
and \texttt{Body0}).

The second hypothesis calculates which function must be called given
the class's dynamic type.  This is complicated because of the need to
handle multiple inheritance (the definition of
``\texttt{selects-via}'' is discussed below in
Section~\ref{sec:multiple-inheritance}), but in this case, the path
\texttt{Cs'} will be found to be \texttt{[D2,D1]}, and the information
\texttt{(dyn_retty,F,args,body)} found will be that for the function
\texttt{D1::f}.

\index{mk_member@\texttt{mk_member}}
The result of the rule in this circumstance is that the expression
\texttt{b->f} turns into a reference to the function \texttt{D1::f}
(this is the call to \texttt{mk_member}), coupled with with the fact
that the function call is being made on an object whose dynamic type
is \texttt{D2}, and whose static type is \texttt{D1} (as is
appropriate for the body of the function).

Note that the function in this rule is known to be virtual by virtue
of the fact that the fieldname is unqualified: it is of the form
\[
\texttt{IDConstant~F~[]~(IDName~fld)}
\]
Name resolution will ensure that non-virtual members all have
qualified names.

\paragraph{Other Sorts of Member Function}

There are two other sorts of member functions in \cpp{}: static
member functions, and normal functions.  Each sort has its own rule
in the semantics.
\index{member functions!static}
First, the rule for static member functions:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!static-fn-member-select@\texttt{static-fn-member-select}}%
\begin{alltt}
(* RULE-ID: static-fn-member-select *)
     (s,\lbr\rbr) |- path (LAST Cs) to class_part fldid via Ds \(\land\)
     (s,\lbr\rbr) |- LAST Ds has least method
                  (IDtl fldid) -: (retty,T,ps,body)
                  via [LAST Ds] \(\land\)
     (ftype = Function retty (MAP SND ps)) \(\land\)
     is_qualified fldid
   \(\Rightarrow\)
     mng (s, EX (SVar (LVal a (Class cnm) Cs) fldid) se)
         (s, EX (FVal fldid ftype NONE) se)
\end{alltt}
\end{minipage}
\end{center}
\index{is_qualified@\texttt{is_qualified}}%
The third hypothesis (\texttt{is_qualified}) checks that the field
name has multiple components to it.  This qualification will be
introduced by name resolution if not already provided by the user.
Name resolution will also ensure that the name given to the field is
qualified with the name of the class where the field actually
resides.

\index{class_part@\texttt{class_part}}%
Strictly, in this rule, the first hypothesis is redundant because of
this pre-processing: we know that the field will occur in the class
that is at the end of the path \texttt{Ds}, and that this final
element will be equal to the class-part of the identifier.  The second
hypothesis reinforces this: the deduced path from \texttt{LAST~Ds}
(which equals \texttt{class_part~fldid}) to the host class for the
given field is the singleton \texttt{[LAST~Ds]}.  Because the member
is static (witness the \texttt{T} as argument 2 of the 4-tuple
returned by \texttt{least-method}), the final function value does not
include a class component.

\index{member functions!non-static}
The rule for normal, non-static  member functions is given in
Figure~\ref{fig:nstatic-fn-member-select}.
\begin{figure}
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!nstatic-fn-member-select@\texttt{nstatic-fn-member-select}}%
\begin{alltt}
(* RULE-ID: nstatic-fn-member-select *)
     (s,\lbr\rbr) |- path (LAST Cs) to class_part fldid via Ds \(\land\)
     (s,\lbr\rbr) |- LAST Ds has least method
                  (IDtl fldid) -: (retty,F,ps,body)
                  via [LAST Ds] \(\land\)
     (ftype = Function retty (MAP SND ps)) \(\land\)
     is_qualified fldid
   \(\Rightarrow\)
     mng (s, EX (SVar (LVal a (Class cnm) Cs) fldid) se)
         (s, EX (FVal fldid ftype
                      (SOME (LVal a (Class cnm) (Cs ^ Ds))))
                se)
\end{alltt}
\end{minipage}
\end{center}
\caption{Selecting a Non-static Member Function}
\label{fig:nstatic-fn-member-select}
\end{figure}
This is very similar to the rule for static functions, but this time
the identity of the class for which the function is being called is
important, and recorded in the third argument to \texttt{FVal}.  The
dynamic type of the object stays the same, but the static type is
adjusted to reflect the class where the function being called is
defined.

\paragraph{Calling a Member Function}
Once the name of the function to be called has been found, the step of
actually entering the body of the function can be taken.  This is
described in rule \ruleid{member-function-call}, presented in
Figure~\ref{fig:member-function-call}.
\begin{figure}[htbp]
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!member-function-call@\texttt{member-function-call}}%
\begin{alltt}
(* RULE-ID: member-function-call *)
     find_best_fnmatch s0 fnid (MAP valuetype args)
                       rtype params body \(\land\)
     (pdecls = MAP (\(\lambda\)((n,ty),a). VDecInit ty
                                     (Base n)
                                     (CopyInit (EX a base_se)))
                   (ZIP (params, args))) \(\land\)
     (SOME this = ptr_encode s0 a (Class cname) p)
   \(\Rightarrow\)
     mng (s0, EX (FnApp_sqpt (FVal fnid ftype
                                   (SOME (LVal a (Class cname) p)))
                             args) se0)
         (s0 with <| stack updated_by
                       (CONS (s0.env, s0.thisvalue, s0.allocmap));
                     thisvalue :=
                       SOME (ECompVal this (Ptr (Class cname)));
                     blockclasses updated_by stackenv_newscope ;
                     exprclasses updated_by stackenv_newscope ;
                     env := empty_env
                  |>,
          ST (Block T pdecls [body]) (return_cont se0 rtype))
\end{alltt}
\end{minipage}
\end{center}
\caption{Making a Member Function Call}
\label{fig:member-function-call}
\end{figure}
This rule is basically the same as that for normal function calls (see
\ruleid{global-function-call} in
Figure~\ref{fig:global-function-call}), except that the value of the
\texttt{this} pointer has to be established.\index{This@\texttt{This}}

\paragraph{Field Selection}
Field selection is also based on the notion of being able to find the
most-derived declaration of the given field in the ancestor hierarchy.
There is no need to worry about adjusting \texttt{this} pointers, or
performing analyses with dynamic types as field selections are always
done with respect to a class's static type.  However, there is an
additional complexity, stemming from the need to give addresses to
selected fields, so that they can become well-formed l-values.  In
turn, this relies on knowing how a class is laid out in memory.

The standard \emph{does} require that fields belonging to a particular
class type be laid out in the order in which they appear.\footnote{The
  order is actually required to hold as long as they have the members
  have the same access-specifiers, but the model doesn't handle
  accessibility.}  But there is no specification of how base
sub-objects are laid out.  (Recall, moreover, that in the presence of
a virtual base-class, an object that is not most-derived may be split
over distinct parts of memory.)

The rule for finding the offset of a non-static data member is given
in Figure~\ref{fig:nstatic-data-field-select}.
\begin{figure}
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!nstatic-data-field-select@\texttt{nstatic-data-field-select}}%
\begin{alltt}
(* RULE-ID: nstatic-data-field-select *)
     (s,\lbr\rbr) |- path (LAST p) to cnm2 via p' \(\land\)
     (s,\lbr\rbr) |- LAST p' has least
                 (IDtl fldid) -: (ty, F)  (* F = non-static *)
                 via [LAST p'] \(\land\)
     object_type ty \(\land\)
     (mdp = (cnm1 = cnm2) \(\land\) (p = [cnm1])) \(\land\)
     is_qualified fldid \(\land\)
     (class_part fldid = cnm2) \(\land\)
     (SOME offn = lookup_offset s mdp fldid)
   \(\Rightarrow\)
     mng (s, EX (SVar (LVal a (Class cnm1) p) fldid) se)
         (s, EX (LVal
                  (a + subobj_offset s (cnm1, p ^ p') + offn)
                  ty
                  (SND (default_path ty))) se)
\end{alltt}
\end{minipage}
\end{center}
\caption{Calculating the Offset of a Non-static Data Member}
\label{fig:nstatic-data-field-select}
\end{figure}
Recall that static analysis done by Phase~1 will have turned all data
field references into fully-qualified identifiers.  That means the
dynamics already knows exactly which sub-class holds the desired
field.  In the rule, that sub-class is \texttt{cnm2}.  The first
hypothesis confirms that there is indeed a path from the static type
of the l-value to that sub-class (which might be itself, of course).
The second hypothesis then both extracts the type of the field and
confirms that it is not static.

The rule also determines whether or not the sub-class is actually the
most-derived class, and records this in the boolean variable
\texttt{mdp}.  This is done so that the underspecified calculation in
\texttt{lookup_offset} can return a different value for field offsets
depending on whether or not a class is most-derived.  (It seems very
unlikely that an implementation would do this; most would put any
virtual bases at the end of their internal layout, meaning that all
other offset calculations could proceed undisturbed.)

The variable \texttt{offn} is the offset of the field within its host
class.  The function \texttt{subobj_offset} is used to calculate the
offset of the sub-class within the larger containing (dynamic) class,
allowing a final offset to be calculated.  Finally, the second
component of \texttt{default_path~ty} function returns the singleton
list consisting of the class name if \texttt{ty} is a class type, and
the empty list otherwise.


\index{vtables}%
\paragraph{What of vtables?}
The use of paths \emph{\`a la} Wasserrab~\emph{et al.} does away with
the need for vtables.  On the other hand, we wouldn't want to specify
the model in such a way as to preclude this perfectly reasonable
implementation strategy.  In particular, vtables will be catered for
just as in the standard, by maintaining that it is only in POD
(``plain old data'') types where one can rely on the address of the
first field being the same as the address of the containing
\texttt{struct}.  The calculation of sizes must also be
under-specified to allow for the presence of extra, user-invisible
data at the start of a class.

\subsubsection{Casting and Other Type Conversions}
We have already seen one use of implicit conversion from one type of
value to another, in the rule \ruleid{assign-completes}
(Figure~\ref{fig:assign-completes},
page~\pageref{fig:assign-completes}), where the relation
\texttt{nonclass_conversion} is used to this end.  This relation
governs the way in which various values are allowed to be silently
converted from one type to another.  Its definition is from the file
\HOLfile{declaration_dynamics}, and is repeated in
Figure~\ref{fig:nonclass-conversion}.
\begin{figure}
\index{nonclass_conversion@\texttt{nonclass_conversion}}
\begin{alltt}
  nonclass_conversion s (v1,ty1) (v2,ty2) =
    let ty1 = strip_const ty1
    and ty2 = strip_const ty2
    in
      (integral_type ty1 \(\land\) integral_type ty2 \(\lor\)
       \(\exists\)ty0. (ty1 = Ptr ty0) \(\land\) (ty2 = Ptr Void)) \(\land\)
      (\(\exists\)i. (INT_VAL ty1 v1 = SOME i) \(\land\)
           (SOME v2 = REP_INT ty2 i))
              (* includes null pointer conversion *)
         \(\lor\)
      (strip_ptr_const ty1 = strip_ptr_const ty2) \(\land\) (v1 = v2)
         \(\lor\)
      (\(\exists\)c1 c2 addr pth1 pth2.  (* this is an upcast *)
          (ty1 = Ptr (Class (LAST pth1))) \(\land\) (ty2 = Ptr (Class c2)) \(\land\)
          (SOME v1 = ptr_encode s addr (Class c1) pth1) \(\land\)
          (s,\lbr\rbr) |- c2 casts pth1 into pth2 \(\land\)
          (SOME v2 = ptr_encode s addr (Class c1) pth2))
         \(\lor\)
      (\(\exists\)ty0 base derived p fld.
          (ty1 = MPtr base ty0) \(\land\) (ty2 = MPtr derived ty0) \(\land\)
          (s,\lbr\rbr) |- path derived to base unique \(\land\)
          (derived, p) \(\in\) rsubobjs (s,\lbr\rbr) \(\land\)
             (* rsubobjs ensures base is not virtual *)
          (LAST p = base) \(\land\)
          (v2 = v1) \(\land\)
          ((SOME v1 = encode_offset base fld) \(\lor\)
           (v1 = null_member_ptr)))
         \(\lor\)
      (\(\exists\)ty0 c. (* null pointer conversion for pointers to member *)
          (ty1 = Signed Int) \(\land\) (SOME v1 = REP_INT (Signed Int) 0) \(\land\)
          (ty2 = MPtr c ty0) \(\land\) (v2 = null_member_ptr))
\end{alltt}
\caption[The \texttt{nonclass_conversion} Relation]{The
  \texttt{nonclass_conversion} relation for implicit type conversions.
  Based on the standard's \S4.}
\label{fig:nonclass-conversion}
\end{figure}

\index{dynamic_cast@\texttt{dynamic_cast}}
The most important of \cpp{}'s explicit casts is the
\texttt{dynamic_cast} operation which allows for run-time checked
manoeuvering around a class hierarchy.  First up-casts to unambiguous bases
are permitted (this is the rule for references; there are parallel
rules for the dynamic casting of pointers):
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!dyncast-derived-base-ref@\texttt{dyncast-derived-base-ref}}%
\begin{alltt}
(* RULE-ID: dyncast-derived-base-ref *)
(* assume that base is accessible (checked by compiler) *)
     (strip_const dty = Class dcnm) \(\land\)
     (s,\lbr\rbr) |- path (LAST p) to dcnm unique \(\land\) (* static check *)
     (s,\lbr\rbr) |- path (LAST p) to dcnm via p'
   \(\Rightarrow\)
     mng (s, EX (DynCast (Ref dty) (LVal a (Class scnm) p)) se)
         (s, EX (LVal a (Class scnm) (p ^ p')) se)
\end{alltt}
\end{minipage}
\end{center}
The second hypothesis is strictly redundant in the dynamics; along
with the base's accessibility, this will be checked before the
dynamics gets a chance to execute.  The third hypothesis is where the
extended path from the dynamic type up to the new base is
constructed.

In the other direction (back down a class hierarchy), dynamic casts
can fail, and require the source type to be polymorphic (\ie, the
source class should have at least one virtual function).  The rule
governing this behaviour appears in
Figure~\ref{fig:dyncast-base-other-ref}.
\begin{figure}[htbp]
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!dyncast-base-other-ref@\texttt{dyncast-base-other-ref}}%
\begin{alltt}
(* RULE-ID: dyncast-base-other-ref *)
     (strip_const dty = Class dcnm) \(\land\)
     (src_dynty = Class scnm) \(\land\)
     polymorphic s (LAST p) \(\land\)
     (s,\lbr\rbr) |- path scnm to dcnm via p' \(\land\)
     (result =
      if (s,\lbr\rbr) |- path scnm to dcnm unique then
        (* should also check accessible, though I think this
           could be done statically *)
        LVal a src_dynty p'
      else
        EThrow (SOME (New (Class bad_cast_name) NONE)))
   \(\Rightarrow\)
     mng (s, EX (DynCast (Ref dty) (LVal a src_dynty p)) se)
         (s, EX result se)
\end{alltt}
\end{minipage}
\end{center}
\caption{Performing a Polymorphic \texttt{dynamic_cast}}
\label{fig:dyncast-base-other-ref}
\end{figure}
Note how the dynamic type of the l-value does not change: it remains
as \texttt{src_dynty}.  Instead the accompanying path value adjusts:
shifting from a path that leads up as far as \texttt{LAST~p} (the
original static type), to one that leads to the class \texttt{dcnm}.
In this way, a \texttt{dynamic_cast} can move the static type from one
branch of the ancestry tree to another; in one step, one can do more
than just make a down-cast.

\index{bad_cast exception@\texttt{bad_cast} exception}
When there isn't a class of the desired type available, a reference
cast causes a \texttt{bad_cast} exception to be thrown.  The
accompanying rule for dynamic-casting of pointer values has the
pointer converted to a null pointer if the destination type is unreachable.


\subsection{Reference Types}
\label{sec:reftypes}

Reference types pose problems in the contexts where they are
distinctive:
\begin{itemize}
\item passed as parameters to functions;
\item returned from functions;
\item when they are initialised.
\end{itemize}

Otherwise, it is obvious how the existing semantics should treat
references: they are l-values.  References are only created from
l-values, and in the reverse direction, l-values can turn into
r-values as required.  They will do the right things when of
\texttt{class} types because they will have the Wasserrab style paths
attached.  In other words, a reference to a base class may actually be
an l-value referring to a derived class.

The remaining sub-sections explain what happens in the three
interesting situations.

\paragraph{Omissions}
\begin{itemize}
\item The semantics does not handle references to functions.
  Supporting these will require more rules in the dynamic semantics,
  but these rules will be directly analogous to the rules presented
  below: wherever an \clvalue{} constructor (which is for l-values of
  object type) appears, there will need to also be a rule for
  \cfvalue{}, which is for function values.
\item The semantics doesn't handle initialisation of \texttt{const}
  references from r-values.
\end{itemize}


\subsubsection{References as Parameters}

When a formal parameter is of reference type, the actual parameter
needs to stay an l-value rather than reduce to an r-value.  When the
called function's environment is being established in its local stack
frame, the binding for the formal name can be directly to the actual
l-value's address and type.  In other words, nothing is allocated in
memory to represent the reference.  This is not very likely in an
actual environment, which will probably have an address in memory
somewhere.  (The only way to detect this (and this would require the
use of undefined behaviour) would be know where local variables were
allocated, and to scan this area byte-by-byte, presumably starting at
the address of some other, non-reference, local parameter.)

This requires a change to the existing semantics, to remove function
arguments from the l-value context (as defined by
\texttt{valid_lvcontext}.\index{valid_lvcontext@\texttt{valid_lvcontext}}
In order to allow some function arguments to decay into r-values, a
new rule is introduced:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!fnapp-lval2rval@\texttt{fnapp-lval2rval}}%
\begin{alltt}
(* RULE-ID: fnapp-lval2rval *)
     lval2rval (s0,e0,se0) (s,e,se) \(\land\)
     fn_expects_rval s0
       (case s0.thisvalue of
           SOME (ECompVal bytes (Ptr ty)) -> SOME ty
        || _ -> NONE)
       f
       (LENGTH pfx)
   \(\Rightarrow\)
     mng (s0, EX (FnApp f (pfx ++ (e0 :: sfx))) se0)
         (s, EX (FnApp f (pfx ++ (e :: sfx))) se)
\end{alltt}
\end{minipage}
\end{center}
The variables \texttt{pfx} and \texttt{sfx} are lists of expressions
corresponding to the other actual parameters being passed to the
function $f$.  The predicate \texttt{fn_expects_rval} examines the
type of \texttt{f} to determine whether or not the argument at the
given position (\texttt{LENGTH~pfx} here) is required to be an l-value.

The rule that determines that a function application's sequence point
has been reached (\ruleid{function-call-sqpt}) must also change.
Previously, this rule checked that the function and all of the
arguments had been fully evaluated, and being ``fully evaluated''
meant ``had been evaluated to a value (consisting of a list of
bytes)''.  The new rule checks that every parameter is either a
byte-list value (when the function doesn't expect a reference type),
or an l-value:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!function-call-sqpt@\texttt{function-call-sqpt}}%
\begin{alltt}
(* RULE-ID: function-call-sqpt *)
     (fty = Function retty argtys) \(\land\)
     EVERYi (\(\lambda\)i e. if ref_type (EL i argtys) then
                     \(\exists\)a t p. e = LVal a t p
                   else \(\exists\)v t. e = ECompVal v t)
            params \(\land\)
     is_null_se se
   \(\Rightarrow\)
     mng (s, EX (FnApp (FVal fnid fty eopt) params) se)
         (s, EX (FnApp_sqpt (FVal fnid fty eopt) params)
                base_se)
\end{alltt}
\end{minipage}
\end{center}
The \texttt{EVERYi} function (from \HOLfile{utils}) is of type
\begin{verbatim}
   : (num -> 'a -> bool) -> 'a list -> bool
\end{verbatim}
and checks whether or not every element of a list satisfies the given
predicate, but where the predicate is also given access to the
element's index in the list.

\subsubsection{References Returned from Functions}
\label{sec:refs-returned-from-fns}

In order to return a reference from a function, the model must not
force the ``l-value to rvalue'' conversion that would normally turn
l-value expressions in \texttt{return} statements into r-values.  But
it must also allow that conversion to occur when appropriate.  This in
turn requires the model to be able to recognise when a function is due
to return a reference as opposed to a normal value.  The model
achieves this by encoding this expectation in the continuation that
accompanies every statement evaluation.

\index{return_cont@\texttt{return_cont}}%
The rules for function calls (see, for example
\ruleid{global-function-call} in Figure~\ref{fig:global-function-call}
(page~\pageref{fig:global-function-call})) construct the continuation
with a call to \texttt{return_cont}.  The continuation type is defined
in \HOLfile{statements}:
\begin{verbatim}
  conttype = RVC of (CExpr -> CExpr) => se_info
           | LVC of (CExpr -> CExpr) => se_info
\end{verbatim}
meaning that a continuation stores both the side effect record that is
to accompany the re-established expression, and a function which will
construct it when given the result of the function call.

The definition of \texttt{return_cont} is
\begin{verbatim}
  return_cont se ty = if ref_type ty then LVC I se
                      else RVC I se
\end{verbatim}
where \texttt{I} is the identity combinator (the function equal to
$(\lambda x.\;x)$).

In the continuations, the ``tags'', \texttt{RVC} and \texttt{LVC},
allow other rules to determine what is expected.  To return to the
example of the ``l-value to r-value'' conversion, this is done by the
following rule:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!return-lval2rval@\texttt{return-lval2rval}}%
\index{lval2rval@\texttt{lval2rval}}%
\begin{alltt}
(* RULE-ID: return-lval2rval *)
     lval2rval (s0,e,se0) (s,e,se)
   \(\Rightarrow\)
     mng (s0, ST (Ret (EX e0 se0)) (RVC c ret_se))
         (s, ST (Ret (EX e se)) (RVC c ret_se))
\end{alltt}
\end{minipage}
\end{center}
The continuation that accompanies every statement is the second
argument of the \texttt{ST} tag. Also note that the first argument of
a \ckey{return} might itself be another statement.  If the original
expression contained a function call, the body of the called function,
a statement, would eventually become the top of the expression.  In
this rule, the use of the inner \texttt{EX} tag precludes this
possibility.

There are two rules allowing a \ckey{return} statement to pass its
expression-value to the continuation.  The rule for returning normal
values is \ruleid{return-rvalue} (we saw this rule earlier, in
Section~\ref{sec:small-step-stmts}):
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!return-rvalue@\texttt{return-rvalue}}%
\begin{alltt}
(* RULE-ID: return-rvalue *)
     is_null_se se0
   \(\Rightarrow\)
     mng (s, ST (Ret (EX (ECompVal v t) se0)) (RVC c se))
         (s, EX (c (ECompVal v t)) se)

\end{alltt}
\end{minipage}
\end{center}

\smallskip\noindent
The rule for returning a reference \ruleid{return-lvalue} is similar:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!return-lvalue@\texttt{return-lvalue}}%
\label{rule:return-lvalue}
\begin{alltt}
(* RULE-ID: return-lvalue *)
     is_null_se se0
   \(\Rightarrow\)
     mng (s, ST (Ret (EX (LVal a t p) se0)) (LVC c se))
         (s, EX (c (LVal a t p)) se)

\end{alltt}
\end{minipage}
\end{center}

\subsubsection{Declaring References}

When a reference is declared, it must also be initialised, and the
initialising expression must be an l-value.  But normal
initialisations need to be able to turn l-values into r-values so
there is an ``lvalue-to-rvalue'' rule for variable declarations that
are accompanied by initialisations (this rule earlier appeared in
Section~\ref{sec:simple-declarations}):
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-vdecinit-lval2rval@\texttt{decl-vdecinit-lval2rval}}%
\begin{alltt}
(* RULE-ID: decl-vdecinit-lval2rval *)
     lval2rval (s0,e0,se0) (s,e,se) \(\land\)
     \(\neg\)ref_type ty \(\land\)
     ((f = CopyInit) \(\lor\) (f = DirectInit))
   \(\Rightarrow\)
     declmng mng (VDecInitA ty loc (f (EX e0 se0)), s0)
                 ([VDecInitA ty loc (f (EX e se))], s)
\end{alltt}
  \end{minipage}
\end{center}

A variable declaration of reference type is ready to ``fire'' when its
initialising expression has reduced to an l-value, and when there are
no remaining side effects in the side effect record.  At this point,
the variable address map in the state is updated to point at the
l-value's address, and the type map is also updated to make the type
of the name the same as the type of the l-value.
This step is controlled by the rule \ruleid{decl-vdecinit-finish-ref},
for which see Figure~\ref{fig:decl-vdecinit-finish-ref}.
\begin{figure}[hbtp]
\begin{center}
  \begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-vdecinit-finish-ref@\texttt{decl-vdecinit-finish-ref}}%
\begin{alltt}
(* RULE-ID: decl-vdecinit-finish-ref *)
(* if isSome, aopt is the address of a containing class *)
     is_null_se se \(\land\)
     ((f = CopyInit) \(\lor\) (f = DirectInit)) \(\land\)
     (if class_type ty1 then
        (s0,\lbr\rbr) |- dest_class ty1 casts p into p'
      else (p' = p)) \(\land\)
     (s = new_addr_binding refnm aopt (a,dest_class ty2,p') s0)
   \(\Rightarrow\)
     declmng mng
             (VDecInitA (Ref ty1)
                        (RefPlace aopt refnm)
                        (f (EX (LVal a ty2 p) se)), s0)
             ([], s)
\end{alltt}
  \end{minipage}
\end{center}
\caption{How References are Initialised}
\label{fig:decl-vdecinit-finish-ref}
\end{figure}




\subsection{Polymorphism \& Multiple Inheritance}
\label{sec:multiple-inheritance}
\index{multiple inheritance|(}

As already suggested, multiple inheritance has been modelled by
following the approach described in Wasserrab~\emph{et
  al}~\cite{wasserrab-nst-OOPSLA06}.  Most of the dynamic rules have
already been presented, so that the modelling of multiple inheritance
is best understood by considering the auxiliaries supporting those
rules.  Most of these auxiliaries are defined in
\HOLfile{class_info}.

\newcommand{\fld}{\texttt{fld}}
\newcommand{\Cs}{\texttt{Cs}}

At the top level, the rule for calculating the function that will be
called dynamically is \ruleid{function-member-select}, which appears
in Figure~\ref{fig:virtual-fn-member-select}, on
page~\pageref{fig:virtual-fn-member-select}.  This rule describes how
the call to method \fld{} is resolved for an object located at address
\texttt{a}, with dynamic type \texttt{C}, and where the static type of
the object is the last element of the list \Cs.  The list \Cs{} is
also a path through the class hierarchy, starting at the dynamic type
and ending at the current static type.  (Note that an object's dynamic
type is determined on object creation, and persists for an object's
entire life-time.  In contrast, an object's static type is the type
ascribed to it by a particular piece of code.  Different pieces of
code may well ``see'' the same object as having different types.  In
this sense, an object's dynamic type is unchanging, but it will have a
variety of static types across the text of a program.  Confusing, but
true!)

The first premise (``has-least-method'') examines the static type of
the object for which the method will be called, \texttt{LAST~\Cs}.
Starting at that point in the hierarchy it looks upwards (\ie, towards
base classes) for the nearest base class that provides an
implementation of the desired method.  This base-class might be
\texttt{LAST~\Cs} itself, in which case the path found (\texttt{Ds})
will be the singleton consisting of just \texttt{LAST~Cs}.  There must
also be a unique closest ancestor providing the desired method.  If
this isn't the case, then there will have been a compile-time error,
as the call will be statically ambiguous.

The second premise (``selects-via'') then determines the dynamic
location of the desired method.  There are two cases.  The simple case
(reiterating the discussion in Section~\ref{sec:class-values}) is when
there is a unique best method for the dynamic type, \texttt{C}.
Imagine, for example, that there is a four-element singly-linked
inheritance graph, from base \texttt{B0} down to most-derived
\texttt{B3}, with implementations of the method \fld{} at \texttt{B0}
and \texttt{B2}.  If the object is actually of type \texttt{B3}, but
is statically seen as type \texttt{B1}, then \texttt{C} is
\texttt{B3}, and $\Cs$ will be \texttt{[B3,B2,B1]}.  The first premise
(``has-least-method'') determines that, starting at \texttt{B1} (the
static type) there is an implementation of $\fld$ at path \texttt{[B1,
  B0]}.  This will be the instantiation of the rule's variable
\texttt{Ds}.

\index{selects-via relation}
The simple case for ``selects-via'' checks whether or not there is
also a least method for the dynamic type (ignoring, for the moment,
the path giving the static type).  Thus (from \HOLfile{class_info})
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: selects-simple *)
     s |- C has least method mname -: minfo via Cs'
   \(\Rightarrow\)
     s |- (C,Cs) selects mname -: minfo via Cs'
\end{alltt}
\end{minipage}
\end{center}
In the simple example, we will thus conclude that
\begin{verbatim}
   s |- (B3, [B3,B2,B1,B0]) selects fld -: info via [B3,B2]
\end{verbatim}
so that the call will be to the implementation of $\fld$ in
\texttt{B2}, and the \texttt{this} pointer will be adjusted so that
the type and path information associated with its value will be
\texttt{(B3,[B3,B2]}, \ie, a dynamic type of \texttt{B3} (as always)
and a static type of \texttt{B2}.

The same rule applies in a much more complicatd seeming situation,
where multiple inheritance and shared base objects come into play.
Consider the program in Figure~\ref{fig:diamond-cpp}.
\begin{figure}[hbtp]
\begin{verbatim}
#include <iostream>

class B {
public:
  virtual int f() { std::cout << "B's f\n"; return 3; }
  virtual ~B() { }
};

class C1 : virtual public B {
};

class C2 : virtual public B {
public:
  virtual int f() { std::cout << "C2's f\n"; return 4; }
};

class D : public C1, public C2 {
};

int dosomething(C1 &cref)
{
  return cref.f();
}

int main()
{
  D d;
  return dosomething(d);
}
\end{verbatim}
  \caption[Multiple Inheritance with Shared Base Objects]{Multiple
    inheritance with shared base objects.  (This program is in the
    \texttt{notes} directory with name
    \texttt{diamond-multinherit.cpp}.)}
\label{fig:diamond-cpp}
\end{figure}
When the call to \texttt{cref.f()} is made, the type and path
associated with the reference will be \texttt{(D,[D,C1])}.
Statically, the reference is a \texttt{C1} value, but dynamically,
it's really of class \texttt{D}. The first premise in rule
\ruleid{function-member-select} finds that there is a path
($\texttt{Ds}$ in the rule) which is appropriate for \texttt{f}.  This
path is \texttt{[B]}.  The fact that the path does not include the
derived object's name, and is just a bare reference to a class
indicates that it is a path to a shared base.  When such a path is the
second argument of path concatenation
%
\index{^ (path concatenation)@\texttt{\^{}} (path concatenation)}%
%
(the \texttt{\^{}} operator in the second premise), the result is just
the second argument, so that the second hypothesis in the rule becomes
\begin{verbatim}
   s |- (D,[B]) selects f -: info via Cs'
\end{verbatim}

The first, simple, rule for ``selects-via'' resolves this.  Ignoring
the path \texttt{[B]}, the simple rule checks whether or not there is
a unique least path to an \texttt{f} from \texttt{D}.  There is such a
path, and it is \texttt{[D,C2]}.  So, the call to \texttt{cref.f()}
ends up being a call to the \texttt{f} in class \texttt{C2}, in an
``unrelated'' part of the object hierarchy.
\[
\rule{0.2\textwidth}{.1mm}
\]

For those situations where there is not a unique path from the dynamic
type to a best selection, there is another more complicated rule
defining ``selects-via''.  In Figure~\ref{fig:lopsided-v}, the
inheritance hierarchy looks like
\[
\psset{rowsep=3ex,nodesep=2mm,colsep=2em}
\begin{psmatrix}
\texttt{\psframebox{B}} \\
\texttt{Left1}\\
\texttt{\psframebox{Left2}} & & \texttt{\psframebox{Right}}\\
& \texttt{D}
\end{psmatrix}
\ncline{1,1}{2,1}
\ncline{2,1}{3,1}
\ncline{3,1}{4,2}
\ncline{3,3}{4,2}
\]
where the boxed class names are those that implement the function
\texttt{f}.  The question is which \texttt{f} will be called when the
dynamic type is \texttt{D}, and when the static type is
\texttt{Left1}.  There is no unique, least implementation of
\texttt{f} visible from the dynamic type (\texttt{D}), so the simple
rule does not apply.  Instead, the notion of \emph{overrider} is
introduced via the rule
\index{selects-via relation}
\index{member functions!overriders}
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: selects-with-overrider *)
     (\(\forall\)minfo Cs'.
       \(\neg\)(s |- C has least method mname -: minfo via Cs')) \(\land\)
     s |- (C,Cs) has overrider mname -: minfo via Cs'
   \(\Rightarrow\)
     s |- (C,Cs) selects mname -: minfo via Cs'
\end{alltt}
\end{minipage}
\end{center}
where the static type of the value again plays a role.  In this case,
the \texttt{f} that gets called is that in \texttt{Left2}.  For
further details on exactly how this is defined, see either
\HOLfile{class_info}, or
Wasserab~\emph{et~al}~\cite{wasserrab-nst-OOPSLA06}.

\begin{figure}[hbtp]
\begin{verbatim}
#include <iostream>

class B {
public:
  virtual void f() { std::cout << "B's f\n"; }
  virtual ~B() { }
};

class Left1 : public B { };

class Left2 : public Left1 {
public:
  virtual void f() { std::cout << "Left2's f\n";  }
};

class Right {
public:
  virtual void f() { std::cout << "Right's f\n"; }
  virtual ~Right() { }
};

class D : public Left2, public Right { };

void dosomething(Left1 &l1ref) { l1ref.f(); }

int main()
{
  D d;
  // d.f();  would be statically ambiguous
  dosomething(d);
  return 0;
}
\end{verbatim}
  \caption[A Lop-sided `V' Inheritance Hierarchy]{A lop-sided `V'
    inheritance hierarchy.  Available as
    \texttt{notes/lopsided-v.cpp}.}
\label{fig:lopsided-v}
\end{figure}
\index{multiple inheritance|)}
\subsection{Object Lifetimes}
\label{sec:object-lifetimes}

\paragraph{Constructors}
Handling constructors has easily wrought the greatest change to the
simple C model.  The basic approach taken has been to encode as much
as possible with ``evolving syntax''.  Just as \texttt{while} can be
modelled by having
\[
\texttt{while}\;\texttt{(}G\texttt{)}\;\mathit{body}
\] become \[
\texttt{if}\;\texttt{(}G\texttt{)}\;\texttt{\{}\mathit{body}\texttt{;}\;\texttt{while}\;\texttt{(}G\texttt{)}\;\mathit{body} \texttt{\}}
\]
so too do calls to \cpp{} constructors create new programs ``in
place''.  The advantage of this approach is that there is less need
for relatively complicated state to be recorded in yet more fields in
the big record type \texttt{state} (see Figure~\ref{fig:state-type} on
page~\pageref{fig:state-type}).  Instead, programs can unfold into
more elaborate forms directly.  The disadvantage of this approach is
that the original syntax may not support enough forms, requiring new
special syntax to be created, or for existing forms to be extended
with new parameters.

\index{Block@\texttt{Block}}
The existing handling of block-statements is an example of this latter
disadvantage.  In particular, the abstract syntax has a constructor
\texttt{Block} with type
\begin{verbatim}
   : bool -> decl list -> stmt list
\end{verbatim}
where the boolean flag indicates whether or not the block has been
entered yet.  In this way, the abstract syntax has values in it that
can't be written down in the concrete syntax.  (Simiarly, the original
thesis model for C included the \texttt{RVR} constructor and the
$\hat{f}$ intermediate form for function calls.)

Constructors are intimately tied up with declarations and
initialization.  In the simple C world, a variable comes into being in
two stages.  First space in memory is allocated for the variable
(whether on the stack or heap), and the variable name is associated
with that space for the span of the variable's life.  Then there is an
optional initialization phase, when the piece of memory associated
with the variable space is filled in with some value.

The \cpp{} model is similar.  All new objects (but not references)
must be associated with some new space.  Then they may or may not be
initialised.  Additionally, in \cpp{}, an object that is only
declared, and which does not appear to be initialised, will actually
have its default constructor called.

The abstract syntax supporting this is all defined in
\HOLfile{statements}:

\begin{center}
\begin{tabular}{lll}
Constructor & Argument Types & Description\\
\hline
\texttt{VDec} & $\mathit{name},\mathit{type}$ & no initialization\\
\texttt{VDecInit} &
$\mathit{name},\mathit{type},\mathit{initializer}$ &
initialization (unallocated) \\
\texttt{VDecInitA} &
$\mathit{varlocation},\mathit{type},\mathit{initializer}$ &
initialization (space allocated)
\end{tabular}
\end{center}

For example, when a class is declared with no explicit initialization
of any sort, meaning that the default constructor will be called, the
syntax moves through all three stages.  The abstract syntax
corresponding to something like
\begin{verbatim}
{
   classname c;
   ...
}
\end{verbatim}
will be \texttt{VDec "c" classname}.  Because this is a class type,
rule \ruleid{decl-vdec-class} will fire (and can do so immediately),
and the declaration will become \texttt{VDecInit "c" classname init},
where the form of \texttt{init} will encode the fact that a direct
initialization is being performed, and that there are no arguments.
Then the rule \ruleid{decl-vdecinit-start-evaluate-direct-class}
fires.  Side conditions of this rule cause space to be allocated (at
address \texttt{a}), the state's maps from names to addresses be
updated, and for the construction of the class to be recorded so that
it can be destroyed later.

The syntax also evolves to become
\begin{verbatim}
   VDecInitA classname (ObjPlace a) init'
\end{verbatim}
where the new initializer records that a function call to a
constructor is about to happen, and where that construction will
happen (\ie, \texttt{init'} includes a reference to \texttt{a}).

There are three forms of initializer.  The first two are
\texttt{DirectInit0} and \texttt{DirectInit} and correspond to direct
initialization~\cite[\S 8.5 paragraph 12]{cpp-standard-iso14882}.  The
\texttt{DirectInit0} constructor takes as arguments a list of
expressions.  In this way, concrete syntax such as
\begin{verbatim}
{
  Classname c(x,&y,z+1);
}
\end{verbatim}
is directly modelled.  (When the rule \ruleid{decl-vdec-class} fires,
the newly created \texttt{DirectInit0} constructor takes an empty list
of arguments.)

The \texttt{DirectInit} constructor takes one argument, an ``extended
expression'', which will initially be an expression constructed by an
application of the special constructor
\texttt{ConstructorFVal}\index{ConstructorFVal@\texttt{ConstructorFVal}}
to the same argument list.  This form needs to be an extended
expression so that the body of the constructor (a statement) can be
entered.

The other form of initializer is constructed by the function
\texttt{CopyInit}.  This corresponds to the syntax
\begin{verbatim}
{
  type varname = expression;
  ...
}
\end{verbatim}
which is a
copy-initialization~\cite[\emph{ibid}]{cpp-standard-iso14882}.  When
the type of the new object is not a class, there is no difference
between copy-initialization and direct-initialization, reflected in
the rule \ruleid{decl-vdecinit-start-evaluate-direct-nonclass}, which
moves from a \texttt{DirectInit0} to a \texttt{CopyInit} initializer.

When a \texttt{CopyInit} initializer completes its evaluation,
yielding a value, that value be copied across into the space earlier
allocated for the object.  For non-class types this is done with the
same \texttt{val2mem} helper function that is used to apply side
effects.  For class types, this copying must be performed by a call to
the copy constructor.

\paragraph{Constructor Calls}
The expression form corresponding to a constructor call uses the
expression form for function applications, but with a special form in
the place of the function value.  This allows the normal evaluation of
function applications (with the unspecified order of evaluation of
arguments, for example).  The function value position is filled by a
new abstract syntactic form
\texttt{ConstructorFVal}.\index{ConstructorFVal@\texttt{ConstructorFVal}}
This takes three parameters:
\begin{itemize}
\item a boolean indicating whether or not the constructor is being
  called for a most-derived object or not;
\item the address of the space which the constructor is to operate
  over; and
\item the name of the class that is being constructed
\end{itemize}
So, if a declaration is made of the form
\begin{verbatim}
{
   class v(x);
}
\end{verbatim}
then, once sufficient space is allocated for the new object \texttt{v}
(at address \texttt{a}, say), the abstract syntax will look like
\begin{alltt}
   VDecInitA (Class \(\mathit{cnm}\))
             (ObjPlace a)
             (DirectInit
                (EX (FnApp (ConstructorFVal T a \(\mathit{cnm}\))
                           [Var "x"])
                    base_se))
\end{alltt}
where $\mathit{cnm}$ is the identifier corresponding to the class
\texttt{class}.

The \texttt{ObjPlace} constructor is used to distinguish this from the
situation where a reference is being initialised.  The \texttt{EX}
constructor specifies that the current form is an expression (as
opposed to the statement that will be in this position once the
constructor body is entered).  The \texttt{base_se} value is the empty
side-effect record.  This will evolve as references to and updates of
memory occur.

Once the parameters to the constructor have been evaluated, the
constructor body can be entered.  This happens in rule
\ruleid{constructor-function-call}, for which see
Figure~\ref{fig:constructor-function-call}.
\begin{figure}[htbp]
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!constructor-function-call@\texttt{constructor-function-call}}%
\begin{alltt}
(* RULE-ID: constructor-function-call *)
     find_constructor_info s0 cnm args params mem_inits body \(\land\)
     (pdecls = MAP (\(\lambda\)((n,ty),a).
                        VDecInit ty (Base n)
                                    (CopyInit (EX a base_se)))
                   (ZIP (params, args))) \(\land\)
     (SOME this = ptr_encode s0 a (Class cnm) [cnm]) \(\land\)
     (cpfx = construct_ctor_pfx s0 mdp a cnm mem_inits) \(\land\)
     (newstmt =
        if is_catch body then
          let (bod,handlers) = dest_catch body
          in
            Block T pdecls
              [Catch (Block F cpfx [bod])
                     (MAP (\(\lambda\)(e,st).
                             (e, Block F [] [st; Throw NONE]))
                          handlers)]
        else Block T (pdecls ++ cpfx) [body])
   \(\Rightarrow\)
     mng (s0, EX (FnApp_sqpt (ConstructorFVal mdp subp a cnm)
                             args) se0)
         (s0 with <| thisvalue :=
                       SOME (ECompVal this (Ptr (Class cnm)));
                     stack updated_by
                       (CONS (s0.env, s0.thisvalue));
                     blockclasses updated_by stackenv_newscope;
                     exprclasses updated_by stackenv_newscope;
                     env := empty_env |>,
          ST newstmt (RVC (\(\lambda\)e. ConstructedVal subp a cnm)
                          se0))
\end{alltt}
    \end{minipage}
  \end{center}

  \caption{Making a Call to a Class Constructor}
\label{fig:constructor-function-call}
\end{figure}
The basic rule is complicated enough, and there is more complexity
hidden behind the auxiliary functions and relations.  The first
auxiliary is the relation \texttt{find_constructor_info}, which
appears in the rule's first hypothesis.  This relation treats its
first three parameters (\texttt{s0}, \texttt{cnm} and \texttt{args})
as inputs.  These are the current state, the name of the class being
constructed, and the actual arguments being passed to the constructor.
The remaining arguments to the relation are ``outputs''.  The variable
\texttt{params} is the list of formal parameters (names and types).
The variable \texttt{mem_inits} is the list of ``mem-initializers''
(see~\cite[\S12.6.2]{cpp-standard-iso14882}) associated with the
constructor, and \texttt{body} is the constructor's body.  The
\texttt{find_constructor_info} auxiliary is responsible for resolving
which constructor needs to be called, based on the types of the actual
arguments.

The second hypothesis of the rule constructs the sequence of variable
declarations corresponding to the parameters, using standard
functional programming auxiliaries \texttt{MAP} and \texttt{ZIP}.
Parameter passing is just like variable declaration\footnote{This does
  away with the \textsf{Cholera} approach which had a number of
  auxiliary relations effectively duplicating what occurred in
  variable declaration.}, and so the model's existing treatment of
declarations can be re-used to set up the binding between formal names
and actual values.  Note that the expressions that initialise the
parameters have already been fully evaluated, so that there will be no
expression evaluation done when the declarations come to be evaluated
(except for any class construction that may be called for).

The third hypothesis calculates a value for the \texttt{this} value.
The dynamic and static type of the \texttt{this} pointer will be the
same (as the pair $C$ and $[C]$ are passed to \texttt{ptr_encode}),
and thus there will not be any polymorphic dispatch to functions in
derived classes if any virtual functions are called in the constructor
bodies.

The fourth hypothesis constructs a \texttt{cpfx} of declaration calls
to initialise class members and bases.  This is all done in the
complicated function \texttt{construct_ctor_pfx} (defined in
\texttt{dynamicsScript}).  This constructs a sequence of declarations
to initialise the non-static members of the new class, and the class's
immediate bases.  The mem-initializers are consulted to see what
initializers should be provided.  (If a mem-initializer is not
provided for a given member or base, then that object will be value-
or default-initialized; see~\cite[\S12.6.2, paragraphs
3--4]{cpp-standard-iso14882}.)

For example, in Figure~\ref{fig:mem-inits}, before class \texttt{C}'s
constructor body is even entered, the parameters \texttt{cptr} and
\texttt{i} need to be declared and initialised with actual values.
Subsequently, all of \texttt{C}'s immediate bases (just \texttt{B} in
this case) need to be constructed, followed by its members
(\texttt{ptr} and \texttt{sz}).  Note that while the parameters need
to have space allocated for them, the bases and members do not
(because the space for the entire object was allocated at the
\texttt{VDecInit} stage).

\begin{figure}[htbp]
\begin{verbatim}
#include <cstring>

class B {
  int x;
public:
  B(int i) : x(i) {}
};

class C : public B {
  char *ptr;
  int sz;
public:
  C(char *cptr, int i)
    : B(cptr[i]), ptr(cptr), sz(strlen(cptr)) { }
};
\end{verbatim}
  \caption[\cpp{} Constructors with \emph{mem-initializers}]{\cpp{}
    Constructors with \emph{mem-initializers}.  (Available as
    \texttt{notes/mem-inits.cpp}.)}
\label{fig:mem-inits}
\end{figure}

Assume that the constructor has been called with parameters \texttt{x}
and \texttt{y}, and that these have evaluated to values \texttt{xval}
and \texttt{yval}. The sequence of declarations that are constructed
to precede the constructor body is given in
Figure~\ref{fig:constructor-vdecs}. The first two declarations are of
the parameters.  The next constructs the base \texttt{B}, and the last
two construct the non-static members.  The body of
\texttt{construct_ctor_pfx} is responsible for calculating the offsets
of the members (given as \texttt{Boff}, \texttt{ptroff} and
\texttt{szoff} in the figure.

\begin{figure}[hbtp]
\begin{verbatim}
  VDecInit (char *) cptr (CopyInit (NormE xval base_se))
  VDecInit int      i    (CopyInit (NormE yval base_se))

  VDecInitA B (ObjPlace (a + Boff))
              (DirectInit
                 (NormE
                    (FnApp (ConstructorFVal F (a + Boff) B)
                           [Deref(Plus (Var "cptr")
                                       (Var "i"))])
                    base_se))

  VDecInitA (char *) (ObjPlace (a + ptroff))
                     (CopyInit (NormE (Var "cptr") base_se))
  VDecInitA int      (ObjPlace (a + szoff))
                     (CopyInit (NormE (FnApp (Var "strlen")
                                             [Var "cptr"])
                                      base_se))
\end{verbatim}
  \caption[Variable Declarations Generated from
  Figure~\ref{fig:mem-inits}]{The variable declarations constructed to
    precede the body of \texttt{C}'s constructor (from
    Figure~\ref{fig:mem-inits}).}
\label{fig:constructor-vdecs}
\end{figure}

Note how the first argument of the \texttt{ConstructorFVal} form in
the construction of the base \texttt{B} is false; this is because
\texttt{B} is not the most-derived object.  If there were any shared
bases in the example, the most-derived object would be ``responsible''
for constructing them (see~\cite[\S12.6.2, paragraph
5]{cpp-standard-iso14882}).  If \texttt{C} had any non-static members
of class type, then these would be constructed with their
$\mathit{mdp}$ flag set to true.

When the constructor for the base class \texttt{B} comes to be called,
it will in turn initialise its members.  The constructor for
\texttt{B} is called with an argument (\texttt{cptr[i]}) that needs to
be evaluated in the context where the parameters are in scope, so it
is clear that the declarations for the parameters must come before the
base and member initialisations.

\paragraph{Object Destruction}
When an object of class type is first declared (with a
\texttt{VDecInit} form), it has memory allocated sufficient to contain
the new class in its entirety (including sub-objects).  This
allocation is reflected in the state's \texttt{allocmap}.  When the
block in which this declaration was made is left, this allocation is
forgotten.  At the same time, the destructor for the object must be
called.  This is modelled with the
\texttt{blockclasses} field of the state.%
\index{blockclasses (state field)@\texttt{blockclasses} (\texttt{state} field)}%
This is of type
\begin{verbatim}
   : constructed list list
\end{verbatim}
Where the type \texttt{constructed} is defined (see \HOLfile{states})
as
\begin{verbatim}
   constructed = NormalConstruct of construction_locn
               | SubObjConstruct of construction_locn
\end{verbatim}
and \texttt{construction_locn} is an abbreviation for
\begin{verbatim}
   :addr # CPP_ID # CPP_ID list
\end{verbatim}
The address is the address of the object which is to be destroyed, and
the two remaining are the class name and path which serve to identify
the object's type.  The inner list constructor of the type of
\texttt{blockclasses} reflects the fact that multiple objects may be
declared at the same scope level.  The outer list constructor appears
because of the stack discipline necessary for multiple nested scopes.

When an object of class type is declared, the rule responsible
(\ruleid{decl-vdecinit-start-evaluate-direct-class}) both allocates
the necessary memory, and adds address and type information for all of
the object's sub-classes and members (not just immediate bases, but
doing a complete traversal of the inheritance graph) to the
\texttt{blockclasses} field.  This is done by the
\texttt{update_blockclasses} relation defined in
\texttt{class_infoScript}.  The object information has to be added
to the list in the correct order so that objects will be destroyed in
reverse order of construction.

The rule for exitting from a block is then adjusted so that it can
only occur if the current scope's \texttt{blockclasses} information is
empty.  As long as it is not empty, the destructor corresponding to
the object on the top of the stack is set up to be called.  This is
done in rule \ruleid{block-exit-destructors-to-call}:
\begin{center}
  \begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: block-exit-destructors-to-call *)
     (s0.blockclasses = destroy_these :: bcs) \(\land\)
     \(\neg\)(destroy_these = []) \(\land\)
     final_stmt st c \(\land\)
     ((destcalls, s) =
        realise_destructor_calls (exception_stmt st) s0)
   \(\Rightarrow\)
     mng (s0, ST (Block T [] [st]) c)
         (s, ST (Block T [] (destcalls ++ [st])) c)
\end{alltt}
  \end{minipage}
\end{center}
This is another example of evolving syntax: the block that the flow of
control is about to leave, has this departure deferred with the
insertion of new statements before the block's final statement.  The
rule allowing an exit to eventually occur is \ruleid{block-exit}, for
which see Figure~\ref{fig:block-exit} (page~\pageref{fig:block-exit}).

Actually calling a destructor is straightforward because there are no
parameters, nor anything comparable to the mem-initializers.  The
requirement in the standard that sub-objects be destroyed before the
body of a destructor is entered is handled by the fact that the
sub-object information is entered into the \texttt{blockclasses} stack
ahead of the final encompassing object.

\paragraph{Using the Heap}
Classes, and other types, can be allocated on the heap with the
\texttt{new} operator.  For non-classes the rule is
\ruleid{new-nonclass}, in Figure~\ref{fig:new-nonclass}.
\begin{figure}[htbp]
\begin{center}
  \begin{minipage}{\textwidth}
\index{rule (dynamic)!new-nonclass@\texttt{new-nonclass}}
\index{New@\texttt{New}}
\begin{alltt}
(* RULE-ID: new-nonclass *)
     \(\neg\)class_type (strip_array ty) \(\land\)
     malloc s0 ty a \(\land\)
     (result_ty = case strip_const ty of
                     Array bty n -> bty
                  || somety -> ty) \(\land\)
     sizeof T (sizeofmap s0) ty sz \(\land\)
     (s = s0 with <|
            hallocmap updated_by (UNION) (range_set a sz) ;
            constmap := if const_type ty then
                          s0.constmap UNION range_set a sz
                        else s0.constmap DIFF range_set a sz
          |>) \(\land\)
     (SOME ptrval = ptr_encode s0 a result_ty [])
   \(\Rightarrow\)
     mng (s0, EX (New ty NONE) se)
         (s, EX (ECompVal ptrval (Ptr result_ty)) se)
\end{alltt}
\end{minipage}
\end{center}
\caption{Allocating a Non-Class Object on the Heap with \texttt{new}}
\label{fig:new-nonclass}
\end{figure}
When the address is found for the new object (using the
\texttt{malloc} auxiliary), the allocation is recorded in the state's
\texttt{hallocmap} field, rather than the \texttt{allocmap}, which is
used for local objects.  The \texttt{hallocmap} is not affected by
moving in and out of blocks.

When a class is to be allocated, a constructor must be called.  This
is reflected in the rule of Figure~\ref{fig:new-simple-class}.   The
hypotheses are very similar to the non-class rule, but the conclusion
differs because the class's constructor must be called before the
pointer to the object can be returned.
\begin{figure}[htbp]
\begin{center}
\index{rule (dynamic)!new-simple-class@\texttt{new-simple-class}}
\begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: new-simple-class *)
(* The T F parameters to the ConstructorFVal constructor indicate
    1. the object produced is most-derived, and
    2. it is not a sub-object (neither base, nor member) of some
       other object
*)
     (Class cnm = strip_const ty) \(\land\)
     malloc s0 ty a \(\land\)
     sizeof T (sizeofmap s0) ty sz \(\land\)
     (s = s0 with <|
             hallocmap updated_by (UNION) (range_set a sz) ;
             constmap := if const_type ty then
                           s0.constmap UNION range_set a sz
                         else s0.constmap DIFF range_set a sz
          |>) \(\land\)
     (SOME ptrval = ptr_encode s0 a ty [cnm])
   \(\Rightarrow\)
     mng (s0, EX (New ty (SOME args)) se)
         (s, EX (CommaSep (FnApp (ConstructorFVal T F a cnm) args)
                          (ECompVal ptrval (Ptr ty)))
                se)
\end{alltt}
\end{minipage}
\end{center}
\caption{Allocating a Class Object on the Heap}
\label{fig:new-simple-class}
\end{figure}

\section{Validation}
\label{sec:validation}

The deliverable includes a directory \texttt{holsrcs/testfiles}.  In
this directory there is some preliminary work towards the creation of
a symbolic evaluator, for demonstrating that programs in the model can
behave as one might expect.  This work builds on the ideas
in~\cite{netsem:popl2006}, allowing symbolic exploration of a semantic
definition that features non-deterministic branching.  For the moment,
the code only handles a sequence of external declarations not
requiring any expression evaluation, which is very minimalist.  More
in this vein would require a significant investment of work, though it
would be an appealing one as it might allow the semantics to pass a
test suite.

This tool requires some sort of parser for \cpp{} source code, as
having to write out abstract syntax trees by hand is a major
annoyance.  It's possible that the front-end of \texttt{g++} might be
usable in this regard.

Throughout the sources, there are a number of sanity theorems.  These
are identified by ML comments of the form \texttt{(*~SANITY~*)}.
There is one slightly more substantial result in the theory
\HOLfile{sanity}, but its proof pales beside those of transitivity,
reflexivity and anti-symmetry of name instantiation in
\HOLfile{instantiation}.

The file \HOLfile{concrete_tests} includes more sanity theorems, but
of a particular form: exploring the behaviour of the model when
applied to concrete examples.  The last test (\texttt{t6}) is name
resolution on the following, small program, featuring a local class.
\begin{center}
\begin{minipage}{\textwidth}
\begin{verbatim}
    int x;
    int f()
    {
      struct s {
        int g() { return x; }
        int x;
      };
      s val;
      val.x = x;
      return val.g();
    }
\end{verbatim}
\end{minipage}
\end{center}
The test confirms that the body of the function \texttt{f} is
interpreted as if it were
\begin{center}
  \begin{minipage}{\textwidth}
\begin{verbatim}
    int f()
    {
      struct s {
        int g() { return s::x; }
        int x;
      };
      s val;
      val.s::x = ::x;
      return val.s::g();
    }
\end{verbatim}
  \end{minipage}
\end{center}


\section{Omissions and Possible Fixes}
\label{sec:omissions}

\index{overloading}
The most significant omission in this semantics is a treatment of
overloading.  This is a complicated feature of the language, but one
that is purely syntactic, and one that is checked and resolved
entirely by the compiler.  If this semantics were to handle
overloading, it would be done in Phases~1~(Name Resolution) and
Phase~2~(Templates).  There a call to a bare \texttt{f} would
ultimately turn into a call into the \texttt{f} whose parameters'
types best matched the types of the actual arguments.  This resolved
call would then be to an exact name and type combination, so that
\texttt{f} might become \texttt{::ns::f(int,char)} for example.

Similarly, there is no treatment of operator overloading.  Again, any
modelling of this feature would naturally occur in Phases~1 and~2,
where calls to operators such as \texttt{+} would be resolved into
calls to functions over particular types, in particular namespaces and
classes.

Two other large omissions in the realm of statics are \texttt{const},
and protection statuses (including \texttt{friend} functions).  In
general, the \texttt{const}-ness of an expression influences the
selection of particular functions to call (more name resolution), and
can prevent certain expressions from being written at all.  These
latter constraints are an important part of the practice of
programming with \cpp{}, but again, are checked by the compiler.  The
semantics does model the fact that it is undefined behaviour to update
memory that has been declared as \texttt{const}.

Protection statuses (\ie, the designation of certain fields or base
classes as being \texttt{public}, \texttt{protected} or
\texttt{private}), are similarly a static mechanism, and have almost
no impact on the dynamics of a program.  (They make a difference to
the behaviour of \texttt{dynamic_cast}, and to the dynamic
type-matching that is done in exception handlers.)  I feel that all of
these omissions are justified given the commission to prefer treatment
of dynamics rather than static issues.

I believe the most significant dynamic omission is the failure to
support class r-values.  The model also omits \texttt{delete},
placement-\texttt{new}, and some of the constraints on what may or may
not be done with constructors (for example, that
in\cite[\S12.1,~para~15]{cpp-standard-iso14882}).

Class r-values would clearly be modelled almost as l-values, using the
\texttt{LVal}\index{LVal@\texttt{LVal}} constructor.  The greatest
complexity would come in having them returned from functions.  This
would require (potentially anonymous) space to be allocated for them
at the calling level, allowing copy constructors to be called to
install the returned value into the appropriate spot.  The
\texttt{exprclasses}%
\index{exprclasses (state field)@\texttt{exprclasses} (\texttt{state} field)}%
field of the state is designed to record such anonymously allocated
objects so that they can be appropriate destroyed when the enclosing
expression has finished its termination.

Other language features completely ignored (mainly on the grounds that
they are of less interest) are: enumerated types, \texttt{typedef}
declarations, unions, bit-field members and the \texttt{goto} and
\texttt{switch} statements.  Also, for example, while I provide a rule
for post-increment \texttt{++}, there is no rule for \texttt{--}.

\appendix
\section{Mechanised Sources}
\label{sec:sources}

The deliverable consists of a compressed \texttt{tar}-file, that when
unpacked consists of a directory called \texttt{qinetiq-cpp}, which in
turn contains four directories
\begin{itemize}
\item \texttt{holsrcs}, containing the HOL source files of the
  mechanisation.  These files will build with the version of HOL4
  present in the Subversion repository at SourceForge, with date
  \texttt{2007-10-13}.  See Section~\ref{sec:getting-hol} below
  for instructions on how this version of HOL can be retrieved, and
  how the deliverable's HOL source files can then be built and
  checked.
\item \texttt{talks}, containing the \LaTeX{} source and a PDF for the
  talk presented at the DARP meeting in Newcastle in April 2006.  The
  source assumes that the \LaTeX{} packages \texttt{latex-beamer} and
  \texttt{PSTricks} are available.
\item \texttt{docs}, containing \LaTeX{} sources and a PDF version of
  this document, as well as sources for the notes on the earlier
  deliverables (nos.~1--4).
\item \texttt{notes}, some \cpp{} source files that illustrate various
  aspects of \cpp{} behaviour.  An accompanying text file explains some
  of the behaviours.
\end{itemize}

\subsection{Building HOL Source-Files}
\label{sec:getting-hol}

\paragraph{Getting HOL From SourceForge}

To get a particular, dated, version of the HOL4 sources from the
Subversion~(\texttt{svn}) repository, one must issue the command
\begin{alltt}
   svn co -r \textit{date-spec} https://hol.svn.sf.net/svnroot/hol/HOL
\end{alltt}
where \textit{\ttfamily date-spec} is the desired date (best specified
as an ISO~8601 string) enclosed in braces.  The whole should in turn
be enclosed in quotes in order to avoid having the braces confuse the
command-line shell.  For example, \texttt{"\{2007-10-13\}"}.  When the
\texttt{svn} command is issued, the source code is downloaded from
SourceForge and put into a directory called \texttt{HOL}.  The source
code (and all the accompanying \texttt{svn} meta-data) fits into
200MB.

Once a copy of the sources have been downloaded, further commands can
be used to update this copy to correspond to different dates.  The
commands need to be issued from within the \texttt{HOL} directory.
The update command is
\begin{alltt}
   svn update -r \textit{date-spec}
\end{alltt}

\paragraph{Installing HOL} Once the sources have been downloaded, the
installation instructions from the page at
\url{http://hol.sourceforge.net} should be followed to build a copy of
HOL.  An installation of the Moscow~ML compiler (v2.01) will also be
required.

\paragraph{Building Deliverable Sources}
When HOL4 has been installed, the \texttt{Holmake} program (found in
the \texttt{HOL/bin} directory) can be run in the \texttt{holsrcs}
directory of the \cpp{} deliverable to create and check the logical
theories.

\newpage
\bibliographystyle{plain-annote}
\bibliography{deliverables}

\printindex

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
