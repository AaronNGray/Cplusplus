\documentclass[11pt]{article}

\usepackage{charter}
\usepackage{alltt}
\usepackage{url}
\usepackage{proof}
\usepackage{amsfonts}
\usepackage{underscore}
\usepackage{pstricks}
\usepackage{pst-node}
\usepackage{makeidx}

\include{cpp-macros}

\newcommand{\ie}{\emph{i.e.}}
\newcommand{\eg}{\emph{e.g.}}
\newcommand{\naive}{na\"\i{}ve}
\newcommand{\lbr}{\texttt{\{}}
\newcommand{\rbr}{\texttt{\}}}
\newcommand{\HOLfile}[1]{HOL:\texttt{#1}}

\title{A Formal Semantics for \cpp}
\author{Michael Norrish\\{\small \texttt{Michael.Norrish@nicta.com.au}}}
\date{}

\makeindex

\begin{document}
\maketitle
\tableofcontents

\section{Introduction}

This document attempts to present the substance of the mechanised
\cpp{} semantics that is developed in the accompanying HOL source
files (see Appendix~\ref{sec:sources}).  Those files sum to over
12$\,$000 lines; this document tries to cover both the important parts
in detail, and to describe the less important parts at a high level.

The HOL mechanisation itself is necessarily the only \emph{formal}
part of the deliverable.  This document quotes from the sources
liberally, and aims to make these relatively easily understood by
accompanying HOL extracts with English prose.  Where prose and rule
appear to conflict, this will almost certainly reflect a problem with
the prose and not the rule.  The rule has been type-checked, and in
some cases, will have also been validated to some extent.  (See
Section~\ref{sec:validation} for more on validation.)

This document supercedes all previous deliverables.

\subsection{Phases of Understanding}

When we attempt to understand the meaning of a \cpp{} source file (or
``translation unit'' to use the standardese), this task is best broken
down into three phases.

When we begin, we have a sequence of parsed \emph{external
  declarations} (see the Standard's formal grammar in its Annex A:
Grammar Summary).  Throughout this semantics, we assume that this
sequence is well-formed syntactically, that some trusted compiler has
already checked the sources for syntactic errors of the sort compilers
can detect.  For example, this means that we assume that there are no
variables left undeclared, and that all the various expressions are
well-typed.  This is a not inconsiderable simplification of the basic
task, but it does seem fair to claim that such analysis is not as
interesting a problem.  This abstract syntax, as consumed and
manipulated by the semantic model, is described in
Section~\ref{sec:basic-types} below.

The first phase of understanding, or of ascribing meaning, is to do
what I refer to as ``name resolution''.  In this phase, bare names are
resolved into fully-qualified names wherever possible.  For example,
this phase turns a program such as
\begin{verbatim}
   int x;
   int f(int i) { return i + x; }
\end{verbatim}
into
\begin{verbatim}
   int ::x;
   int ::f(int i) { return i + ::x; }
\end{verbatim}
where the names declared in the top, global namespace (\texttt{x} and
\texttt{f}) have been replaced with unambiguous versions of their
names wherever they occur.  Note that the result is no longer valid
\cpp{} (it is illegal to use the explicit qualification in names being
defined), but the next phase of understanding does not expect valid
\cpp{} in any case.  In the presence of hierarchical namespaces, and
class namespaces inheriting from bases, this phase of work is not
entirely trivial.  It is described in some detail in
Section~\ref{sec:phase1}.

The second phase of the semantics is to deal with templates.  Template
resolution takes a translation unit with most of its name resolved,
and where the unit consists of ``ground'' (non-template) and template
declarations or definitions.  The ground definitions may refer to
various template classes or functions.  If so, the appropriate
template instantiations need to be made, producing fresh ground
declarations.  These new declarations need to first have their names
resolved (requiring a nested ``call'' to Phase~1), and may in turn
require more template instantiations.  In fact, template instantiation
may never terminate.  Templates are further described in
Section~\ref{sec:templates}.

The final phase of the semantics is execution, or ``dynamics''.  In
this phase, top-level declarations are executed, resulting in the
dynamic initialisation of variables, which can in turn result in the
execution of source-code.  The exact order of evaluation of external
declarations is allowed to vary (see \S3.6.2), and may or may not
precede the execution of a program's \texttt{main} function.  The
rules governing dynamic behaviour specify what is to occur when
execution does occur, but do not specify how various executions are
knitted together.  All of the model's dynamic rules are presented in
Section~\ref{sec:phase3}.

\subsection{How to Read HOL Extracts}

There are two main forms of definition used in HOL, definition of
functions specified equationally, and inductive definition of
relations.  The former look similar to definitions in functional
programming languages, with features such as pattern-matching and
recursion common.  For example, the following is the definition of a
factorial function
\begin{alltt}
   (FACT 0 = 1) \(\land\)
   (FACT (SUC n) = SUC n * FACT n)
\end{alltt}
The individual equations are separated by conjunction symbols because
the text of the definition becomes the statement of the theorem
characterising the behaviour of the new constant.  (If the recursion
is not well-founded, or if there is some other error in the quoted
text, then HOL does not allow the definition to proceed, and no
theorem is produced.)

Inductive relations allow the definition of systems of rules, common
in the definitions of operational semantics.  For example, one might
write a big-step rule for applicative order reduction in the
$\lambda$-calculus as
\[
\infer{\Gamma \vdash M\,N\;\Downarrow \;v}{\Gamma \vdash M \;\Downarrow\; (\lambda x. M_0) &
  \Gamma \vdash N \;\Downarrow\;v_0 & (x\mapsto v_0),\Gamma \vdash M_0 \;\Downarrow\; v}
\]
This should be read as stating that an application $M\,N$ reduces to a
value $v$ if $M$ reduces to an abstraction ($\lambda x. M_0$), if $N$
reduces to some value $v_0$, and if the body $M_0$ reduces to $v$,
while the bound variable $x$ is linked to $v_0$.

The same rule might be presented in HOL syntax as
\begin{alltt}
     apeval G M (LAM x M0) \(\land\)
     apeval G N v0 \(\land\)
     apeval ((x,v0) :: G) M0 v
   \(\Rightarrow\)
     apeval G (APP M N) v
\end{alltt}
The use of the conjunction and implication symbols makes the
propositional structure of the rule explicit.  Also, the relation
being defined is always the first symbol (\texttt{apeval} here) of the
conclusion.

Note also how the \texttt{apeval} constant of this example is applied
to its three arguments in ``curried'' $\lambda$-calculus or
functional-programming style.  This is in contrast with ``standard''
mathematical style, where functions are typically applied to arguments
in parentheses separated by commas, as in $f(x,y,z)$.  Such tuples do
also appear in the model, but sequences of function or predicate
arguments are often just separated by whitespace, as above.

Where quotations are made from underlying HOL sources, the origin of
the quotation will be identified using the form \HOLfile{thyname}.
The source code for theory \texttt{thyname} is available in the file
\begin{alltt}
   holsrcs/thynameScript.sml
\end{alltt}
When compiled, the corresponding theory will have a readable
signature in the file
\begin{alltt}
   holsrcs/thynameTheory.sig
\end{alltt}

\subsubsection{HOL Syntax}

\paragraph{Pairs} The type of pairs of $\sigma$s and $\tau$s is
written \texttt{$\sigma$~\#~$\tau$}.  Pair values are written inside
parentheses, with components separated by commas, \eg, \texttt{(1,4)}.
\index{FST@\texttt{FST}} The function \texttt{FST} returns the first
component of a tuple, and \index{SND@\texttt{SND}}\texttt{SND} returns
the second.

\paragraph{Lists} Lists can either be empty (\texttt{[]}) or the
result of ``cons''-ing an element onto the front of an
existing list.  The list consisting of element \texttt{h} followed by
list \texttt{t} is written \texttt{h::t}. The type of lists comes
equipped with various standard functional language operations such as
\index{EL (list operation)@\texttt{EL} (list operation)}%
\index{CONS (list operation)@\texttt{CONS} (list operation)}%
\index{FOLDL (list operation)@\texttt{FOLDL} (list operation)}%
\index{++ (list operation)@\texttt{++} (list operation)}%
\index{ZIP (list operation)@\texttt{ZIP} (list operation)}%
\index{MAP (list operation)@\texttt{MAP} (list operation)}%
\index{MEM (list operation)@\texttt{MEM} (list operation)}%
\begin{alltt}
   ++    : 'a list -> 'a list -> 'a list
   CONS  : 'a -> 'a list -> 'a list
   EL    : num -> 'a list -> 'a
   FOLDL : ('a -> 'b -> 'a) -> 'a -> 'b list -> 'a
   MAP   : ('a -> 'b) -> 'a list -> 'b list
   MEM   : 'a -> 'a list -> bool
   ZIP   : 'a list -> 'b list -> ('a # 'b) list
\end{alltt}
The list append operation (\texttt{++}) is written as an infix.

\paragraph{Finite Maps} The finite map is a form of function where the
domain is guaranteed to be finite.  The type of finite maps from
$\sigma$ to $\tau$ is written \texttt{:$\sigma$~|->~$\tau$}.  The HOL
syntax for the application of a finite map \texttt{fm} to an element
\texttt{x}, is \texttt{fm~'~x}, with an apostrophe separating
function and argument.  (Note that the result of the application is
unspecified if the argument is not in the map's domain.)

The empty finite map (one with no domain) is \texttt{FEMPTY}, and
updating a map \texttt{fm} so that its value at \texttt{k} is
\texttt{v} (ignoring whether or not \texttt{fm} may have already had a
value for \texttt{k}), is written \texttt{fm |+ (k,v)}.

\paragraph{Records}\index{records (in HOL)}
Record literals are written as a sequence of assignment to field-names
in between ASCII angle brackets, thus:
\begin{verbatim}
   <| fld1 := 3; fld2 := 5; fld3 := (F,[]) |>
\end{verbatim}
New record values can be constructed from old ones with the
\texttt{with} keyword.  For example
\begin{verbatim}
   rec with <| fld2 := 10; fld6 := T |>
\end{verbatim}
is a record value that is everywhere identical to \texttt{rec} except
that its fields \texttt{fld2} and \texttt{fld6} have different
values.

When updating records, in addition to the assignment
syntax~(\texttt{:=}), one can also use \texttt{updated_by}, which
allows a function to be applied to the old value of the field.  So,
\begin{verbatim}
   rec with <| fld2 updated_by SUC; fld6 := T |>
\end{verbatim}
is a record value everywhere the same as \texttt{rec}, except that its
\texttt{fld6} is true, and its \texttt{fld2} is one bigger.

\section{Basic Types}
\label{sec:basic-types}

The most fundamental types in the semantics are those expressing the
basic abstract syntax of \cpp{}.  These are declared in a BNF-like
way.  For example, the declaration of \cpp{} types is (from
\HOLfile{types})
\begin{verbatim}
   CPP_Type =
     Void |
     BChar (* "Basic char" *) |
     Bool |
     Unsigned of basic_integral_type |
     Signed of basic_integral_type |
     Class of CPP_ID  |
     Float |
     Double |
     LDouble |
     Ptr of CPP_Type |
     MPtr of CPP_ID => CPP_Type | (* member pointer *)
     Ref of CPP_Type |
     Array of CPP_Type => num |
     Function of CPP_Type => CPP_Type list |
     Const of CPP_Type |
     TypeID of CPP_ID
\end{verbatim}
This definition allows recursion: for example, a \cpp{} type can be a
pointer to another \cpp{} type (using the \texttt{Ptr}
``constructor'').  In this simple prefix notation, the type of an
``array of ten pointers to \texttt{int}'', is written
\begin{verbatim}
   Array (Ptr (Signed Int)) 10
\end{verbatim}
(\texttt{Int} is one of the four possible values inhabiting
\texttt{basic_integral_type}, along with \texttt{Char}, \texttt{Short}
and \texttt{Long}.)

Similarly, a function taking two \texttt{int}s and returning a
\texttt{char} is written
\begin{verbatim}
   Function BChar [Signed Int; Signed Int]
\end{verbatim}

\paragraph{Identifiers}
In the presence of templates, identifiers can take on forms such as
\begin{verbatim}
   List<int>::fldname
\end{verbatim}

This means that identifiers are a type in the model that must in turn
be mutually recursive with the type of types.  In the example above,
the type \texttt{int} appears within an identifier.  It is also clear
that identifiers occur within types, because identifiers are the basis
for naming and referring to class types.

Therefore, we must add the following to the above definition of \cpp{}
types:
\index{IDComp@\texttt{IDComp}}
\index{IDConstant@\texttt{IDConstant}}
\begin{verbatim}
   CPP_ID = IDConstant of bool => IDComp list => IDComp

   ;

   IDComp = IDTempCall of string => TemplateArg list
          | IDName of string
\end{verbatim}
In other words, values of identifier type are constructed by applying
the function \texttt{IDConstant} to three arguments: a boolean
indicating whether or not this is an ``absolute'' identifier
(represented in the concrete syntax by prefixing it with \texttt{::});
a list of ID components and one final ID component.

An ID component might either be a simple name, or can be a simple name
applied to multiple ``template arguments''.  There are three sorts of
template arguments: types, templates and values; giving
\begin{verbatim}
   TemplateArg = TType of CPP_Type
               | TTemp of CPP_ID
               | TVal of TemplateValueArg
\end{verbatim}
So, the type above would be represented as
\begin{verbatim}
   IDConstant F [IDTempCall "List" [TType (Signed Int)]]
                (IDName "fldname")
\end{verbatim}


\paragraph{Expressions and Statements}

Expressions are specified in exactly the same way as types, with
constructors such as \texttt{Assign} (assignment), \texttt{Deref} (the
\texttt{*} or pointer dereferencing operator) and \texttt{New}.  The
abstract syntax need not be a perfect match for the concrete syntax.
For example, there is an \texttt{ExpTypeID} operator (for
\texttt{typeid} applied to an expression argument), and
\texttt{TyTypeID} for when \texttt{typeid} is applied to a type.

The rules presented in Section~\ref{sec:phase3} cover the dynamic
behaviours various expression forms.  The HOL declaration is in the
file \HOLfile{expressions}.

Statements are similar again (see \HOLfile{statements}), with
constructors such as \texttt{CIf}, \texttt{Ret} and \texttt{Block}.
However, the type here is rather more complicated because statements
not only include expressions but must be mutually recursive with other
syntactic categories: variable and class declarations, ``class
entries'' (those things that can appear with a \texttt{class}
declaration), and initializers (those things that appear in variable
declarations that also explicitly initialise the variable).

\subsection{Bytes \& Memory}
\label{sec:bytes-memory-states}

After specifying abstract syntax for programs, one must continue by
describing the state that is manipulated by the action of those
programs.   In fact, each of the three phases manipulates slightly
different states, and each will be detailed in the relevant sections.
However, there are a few general observations possible.

\paragraph{Bytes} The fundamental type in the dynamic semantics is
that of the byte.  (See \HOLfile{memory} for more on these matters.)
Using HOL4's support for $n$-bit words, it is possible to define a
type called \texttt{byte}, which is a word containing
\texttt{CHAR_BIT} many bits, where \texttt{CHAR_BIT} is a natural
number under-specified to be at least 8, but possibly more.

It is then possible to define representation and valuation functions
between the HOL types of integer and byte.  These functions are
partial, meaning that they can either return \texttt{NONE} to indicate
failure, or $\texttt{SOME}(v)$ to indicate the successful return of
the value $v$.  These functions capture, again in a suitably
underspecified way, how bytes can be translated into values, and how
those same values can be converted back into bytes.  For example, we
know that for the unsigned \texttt{char} type, all values in the range
$0$ up to $2^{\texttt{CHAR_BIT}}-1$ must have corresponding bit
patterns.  For types other than \texttt{char}, the use of functions in
both directions is perhaps not quite under-specified enough: it
assumes that if an implementation can represent a value at all, then
it will always represent a value in the same way.  For example, this
reduces, though does not eliminate, the opportunities for signed
zeroes to occur.

Each primitive type is given a fixed size (in numbers of bytes).  This
is done in an underspecified way so that again, one can only conclude
that there are enough bytes in an \texttt{int} value to represent the
mandated range of values (from $-(2^{16} - 1)$ up to $2^{16} - 1$).

In the model to come, the function most used is
\begin{verbatim}
   INT_VAL : CPP_Type -> byte list -> int option
\end{verbatim}
which attempts to interpret the given list of bytes as a value of the
provided type, and returns its integer value, if it has one.  The
function might return \texttt{NONE} if the list of bytes is of the
wrong length, or if it is not a valid bit pattern for the type.  (The
latter might occur if the required type is a pointer value and the
hardware checks such values for validity before even allowing them
into address registers.)

\paragraph{Memory}
Memory is represented as a function from natural numbers to bytes.
The address 0 is reserved as the representation for the null pointer.
Strictly speaking, one might imagine that the map should be from some
machine word (an array of four bytes, say) to bytes.  However, even
with the domain of the map being $\mathbb{N}$, any given program will
only be able to address a finite amount of memory because it will only
be able to generate a finite number of addresses.  (All pointer types
have a fixed, finite number of bytes making up their representations.)

\subsection{Hierarchical Environments}
\label{sec:hierarchical-environments}

To reflect the hierarchical nesting of namespaces and classes, the
model uses a type of hierarchical environments, giving maps from
structured names into information about those names.  These maps are
instances of a type called \texttt{fmaptree} (see \HOLfile{fmaptree}).
This type has one constructor:
\begin{verbatim}
   FTNode : 'value -> ('key |-> ('key,'value)fmaptree) ->
            ('key,'value)fmaptree
\end{verbatim}
The \texttt{|->} type operator returns finite maps, so
\texttt{FTNode} takes a value, and a finite map from keys to more
\texttt{fmaptree}s, and returns a new \texttt{fmaptree}.  This type
rather resembles the trie data structure.  Like lists and other
``container'' types, the \texttt{fmaptree} is polymorphic, both in the
type of keys, and the type of values.

The operation to lookup up the sub-tree at a particular key list position
is \texttt{apply_path}:
\begin{alltt}
  (apply_path [] ft = SOME ft) \(\land\)
  (apply_path (h::t) ft = if h \(\in\) FDOM (map ft) then
                             apply_path t (map ft ' h)
                          else NONE)

\end{alltt}

The functions \texttt{item} and \texttt{map} are also heavily used,
and return the value, and sub-trees of an \texttt{FTNode}
respectively.
\begin{verbatim}
   item (FTNode i fm) = i

   map (FTNode i fm) = fm
\end{verbatim}

In the particular context of \cpp{}, there are two sorts of
environment (see \HOLfile{environments}).  The first maps from
namespace components into values of type \texttt{envinfo}.  An
\texttt{envinfo} is a record of three components, each of which are
finite-maps.
\begin{verbatim}
   envinfo = <|
     varmap   : string |-> addr # CPP_ID # CPP_ID list ;
     typemap  : IDComp |-> CPP_Type ;
     classenv : IDComp |-> class_env
   |>
\end{verbatim}
The \texttt{varmap} is a map from variable names to their l-value
information.\footnote{It should be clear that an address is necessary
  to specify an object's identity.  The additional identifier and
  identifier list are used to store the dynamic information about
  class types that is necessary to implement polymorphism.  For more
  on this, see Section~\ref{sec:multiple-inheritance} below.}  The
domain of this map can be strings because only functions can have
template-structured names, and these do not live in memory in the same
way as objects.  The \texttt{typemap} maps ID components to types,
giving static information both for objects and functions.  The
\texttt{classenv} field gives information about any classes that might
be declared at this level of the namespace hierarchy.

The \texttt{environment} type is then an abbreviation for a
\begin{verbatim}
   (string, envinfo) fmaptree
\end{verbatim}
At each point in the namespace tree, indexed by a path (or list) of
names, there is an \texttt{envinfo} value about the objects and
classes stored in that scope.

The \texttt{class_env} type is an abbreviation for another sort of
\texttt{fmaptree}
\begin{verbatim}
   (IDComp, class_envinfo) fmaptree
\end{verbatim}
In other words, a \texttt{class_env} is a structured map, where the
components can be full-blown \texttt{IDComp} values.  This is
necessary because classes can be constructed from template calls
(whereas namespaces are necessarily identified by just strings).

The information attached to each node of a \texttt{class_env} is the
following record type:
\begin{verbatim}
   class_envinfo = <|
      (* ironically, the location of the static variables is
         only available dynamically, as classes are
         initialised *)
      statvars : string |-> addr # CPP_ID # CPP_ID list ;
      info     : state_class_info ;
      refs     : string # addr |-> addr # CPP_ID # CPP_ID list
   |>
\end{verbatim}
The \texttt{statvars} field records the same information for a class's
static variables as the \texttt{envinfo} records for normal
variables.  The \texttt{refs} field records per-class information
about reference members.  Both of these fields are only used
dynamically (as static variables are declared, and as new classes are
constructed respectively).  Finally, the \texttt{info} field records
the static information associated with a class.



\section{Phase 1: Name Resolution}
\label{sec:phase1}

Name resolution must occur in a separate phase before dynamic
evaluation, and must rewrite declarations so that their name
dependencies are made explicit.  This is exemplified by the program in
Figure~\ref{fig:name-res-separate-phase}, where the name \texttt{x}
that occurs in the function \texttt{ns1::f} must be a reference to the
\texttt{x} that occurs in the outermost, global namespace.  A \naive{}
execution of the sequence of declarations in the program would put the
global \texttt{x} into its namespace, and then enter namespace
\texttt{ns1}, where it would first declare the function \texttt{f},
and then the second \texttt{x}.  A later call to \texttt{ns1::f} would
correctly open up the entirety of the namespace, and immediately mask
the global \texttt{x} with \texttt{ns1::x}, causing the evaluation of
the body to proceed erroneously.
\begin{figure}[htbp]
\begin{verbatim}
   int x = 3;
   namespace ns1 {
     int f(int n) { return n + x; }
     int x = 2;
   }
\end{verbatim}
\caption{A program demonstrating the need to have name resolution be a
  separate phase before dynamic evaluation.}
\label{fig:name-res-separate-phase}
\end{figure}

Even if one imagined a version of the dynamics that did perform name
resolution as it evaluated declarations, this semantics would still
need to transform the body of \texttt{ns1::f} to include the correct
reference to \texttt{::x}.  The rest of this section of the report
will describe the relation that turns the program in
Figure~\ref{fig:name-res-separate-phase} into
\begin{verbatim}
   int ::x = 3;
   int ::ns1::f(int n) { return n + ::x; }
   int ::ns1::x = 2;
\end{verbatim}

\subsection{The Name Resolution State}
\label{sec:name-resol-state}

In order to track the current set of names that are in scope, Phase~1
uses two environments, as per
Section~\ref{sec:hierarchical-environments} above, to capture what is
known about the current nested scopes, as well as some extra fields to
describe the names that are \emph{visible}.  For example, in the
program of Figure~\ref{fig:name-res-separate-phase}, the global
\texttt{x} is visible when \texttt{::ns1::f} is defined, but there is
no \texttt{x} in the namespace \texttt{::ns1}, at least at that stage.

The HOL definition (see \HOLfile{name_resolution}):
\begin{verbatim}
   P1state = <|
     current_nspath : string list ;
     dynclasses : string |-> bool # IDComp list #
                             TemplateArg list ;
     dynobjs : string |-> bool # IDComp list #
                          TemplateArg list # dynobj_type ;
     dynns : string |-> string list ;
     global : state ;
     accdecls : ext_decl list
   |>
\end{verbatim}
The three \texttt{dyn} fields record what names are visible in three
different categories: namespaces~(\texttt{dynns}),
classes~(\texttt{dynclasses}) and objects~(\texttt{dynobjs}).  Each
maps to information sufficient to provide an exact location for the
name.

In the case of namespace names, it is enough to provide a path from
the root, and such a path will just be of strings.  For objects and
classes, the path has to be of ID components because objects and
classes can be nested inside classes (and classes might be template
classes).  The boolean also records whether or not the name is local
or non-local.  The list of \texttt{TemplateArg} values records any
template parameters that the name may be associated with if it is a
template.  Finally, in the case of objects, it is also necessary to
record what sort of object the name is.  The options are given in the
type \texttt{dynobj_type}:
\begin{verbatim}
   dynobj_type =
      dStatMember | dMember | dVirtualMember | dNormalObj
\end{verbatim}
Note that in this context an ``object'' might actually be a function
(and it is functions that provide the interest); elsewhere funtions
are not considered objects because they don't occupy allocated
memory.

The \texttt{global} field of a \texttt{P1state} is a state from the
dynamic semantics.  In Phase~1 the vast majority of the information
stored in such a state is ignored; the state is part of the
\texttt{P1state} only for its two environments, which are accessed as
the fields \texttt{genv} (the global environment), and \texttt{env}
(the local environment).
\index{genv (state field)@\texttt{genv} (\texttt{state} field)}%
\index{env (state field)@\texttt{env} (\texttt{state} field)}%

Finally, the \texttt{accdecls} field records the accumulating
translated declarations.  It is this that provides the final output of
Phase~1.

\subsection{Template Names}

One significant issue is the resolution of names in templates.  When a
template definition is instantiated, it is important to specify how
the names occuring in the template bind.  Typically, such names might
bind to global names that are in scope at the point of the template's
definition, or to member functions associated with the template
argument.

The rule is actually fairly straightforward, at least in principle:
function names are allowed to bind to template names when the
statically determined types of the function arguments refer to
template parameters.  Such names have to be left alone in Phase~1.



\section{Phase 2: Templates}

\label{sec:templates}

In this section, I describe how the semantics models templates.  I
have been inspired by Siek and Taha~\cite{DBLP:conf/ecoop/SiekT06},
though as I shall discuss, the dynamics of their model is too
simplistic for the full language of templates, in particular handling
template parameters that are themselves references to templates
(``higher order templates'' if you will).\footnote{Siek and Taha do
  model \texttt{typedef} declarations within classes, which I do not.}

One might imagine that it be possible to treat templates at
``run-time'', as if one had written a one-pass \cpp{} interpreter.
However, the example in Figure~\ref{fig:templates-not-interpretable}
demonstrates that such a goal is impossible, that one would have to
write a two pass interpreter at the very least.  Any reference to the
figure's \texttt{List} template, perhaps within a function that was
called at a great stack depth, causes the need to statically
initialise the global \texttt{node\_count} before the program even
begins.  A \naive{} interpreter that attempts to execute the program
source as it sees it, will come unstuck.

As the interpreter sees the template declarations above, it does
nothing.  Then it performs its global declarations, and jumps into
main.  At this point it has already failed to do the right thing.
Instead, the putative interpreter would have to scan the whole program
for template applications so that it can generate the appropriate
global variable initialisations.  This is no better than explicitly
pre-compiling templates, so I have adopted an explicit two-phase
compilation approach.

\begin{figure}
\begin{verbatim}
  template <class T> class List {
    T item;
    List *next;
    static int node_count;
  };

  template<class T> int List<T>::node_count = 0;
\end{verbatim}
\caption{A program demonstrating the difficulty of interpreting
  templates.}
\label{fig:templates-not-interpretable}
\end{figure}



Finally, we need to specify the possible sorts of arguments that can
be passed to templates.  The Standard is quite explicit
here~\cite[\S14.3~para~1]{cpp-standard-iso14882}, there are three
sorts of arguments: types, templates, and ``non-type, non-template''
arguments (meaning references to objects with linkage, or numbers).
Thus:
\begin{verbatim}
   TemplateArg = TType of CPP_Type
               | TTemp of CPP_ID
               | TVal of TemplateValueArg
\end{verbatim}
Finally, there are four different sorts of non-type, non-template
arguments~\cite[\S14.3.2~para~1]{cpp-standard-iso14882}:
\begin{verbatim}[t]{cl}
   TemplateValueArg =
       TNum of int
     | TObj of CPP_ID
         (* id is of suitable global (one that has
            linkage etc). *)
     | TMPtr of CPP_ID => CPP_Type
     | TVAVar of string (* => CPP_Type *)
         (* can have a value (of the given type)
            substituted for this *)
\end{verbatim}
This presentation is slightly simplified because the standard also
allows arithmetic on these arguments, where this is appropriate
(between \texttt{TNum} and \texttt{TVAVar} parameters).

This is a complicated type, and it does assume that some previous
phase of analysis has determined which references are to class types,
and which are to namespaces.  In this way, something like
\texttt{x::y::z} can be split up to include namespaces within a
\texttt{TopName} component, and sub-fields or sub-classes within
\texttt{IDFld} structuring.

Similarly, a string such as \texttt{x::t<int>} is ambiguous without
some static analysis being performed to determine whether \texttt{x}
is a namespace or a class.  If \texttt{x} is a class, then \texttt{t}
must be a template member function, but if it is a namespace, then
\texttt{t} might be either a class template or a function template.

Further note that there can be at most two template calls within an
identifier.  If there are two, then the outermost is a class template,
and the second will occur last, and will be a template member
function.

\subsection{Instantiation and Matching}

(This seection describes formalisation done in
\HOLfile{instantiation}.)

\medskip
\noindent Types and identifiers can be \emph{instantiated}: mappings
from variable names to values are applied over the structure of the
value (type or identifier), and occurrences of variable names are
replaced by the appropriate element from the range of the function.
Because there are three sorts of variables (corresponding to the three
different sorts of template argument), an instantiation is actually a
triple of functions (one for each sort of variable).

In Siek and Taha~\cite{DBLP:conf/ecoop/SiekT06}, instantiation is a
very elegant operation.  In a more faithful model of more of \cpp,
more complexities intrude.  In addition to the need for three
mappings, the model must also accept that instantiation can result in
an invalid result.  Instantiation must become partial, which is
modelled by making the types of the various instantiation functions be
of the form
\[
\texttt{inst<}\tau\texttt{>} : \mathit{substitution} \to \tau
\to \tau\;\textsf{option}
\]
The partiality arises at the lowest level, as in the following
example:
\begin{verbatim}
   template<class T> void f<T>(int x) { T::staticfield = x; }
   void g() { f<int>(3); }
\end{verbatim}
This must be an error because it is not sensible to write
\texttt{int::staticfield}.  (Other type substitutions may also cause
this to be an error, but this error can be detected as the
substitution is done, without any need to lookup information about the
argument.)

The partiality of instantiation does not prevent us from defining a
partial order over types, such that $\tau_1 \leq \tau_2$ when $\tau_2$
is a more specialised/instantiated version of $\tau_1$.  As in Siek
and Taha~\cite{DBLP:conf/ecoop/SiekT06}, we can prove reflexivity,
transitivity, and antisymmetry (up to renaming of free variables).

Given the partial order, it is straightforward to find the best match
amongst a set of template definitions for a given template call.

\subsection{Program Instantiation}

Siek and Taha have an elegant model for program instantiation.  A
program is a sequence of definitions (of classes, and of static member
functions).  A definition may cause an existing template to be
instantiated because of a reference to that template within the
definition.  When a member function definition is encountered, if its
body includes a reference to other functions, these functions may need
to be instantiated.

For example, when analysing the program in Figure~\ref{fig:taha-prog},
the Siek and Taha's model will see the reference to
\texttt{Foo<T*>::f()} in the definition of \texttt{Bar<T>::g()} and
instantiate the definition of \texttt{Foo} (it knows that it does not
already have an instantiation for a type of the form \texttt{Foo<T*>}).
This instantiation will result in a template definition (one with free
variables), which may or may not be required in the rest of the
program.
\begin{figure}
\begin{verbatim}
   template <class T> class Foo { static int f(); };
   template <class T> int Foo<T>::f() { return 3; }

   template <class T> class Bar { static int g(); };
   template <class T> int Bar<T>::g() { return Foo<T*>::f(); }
\end{verbatim}
  \caption{In Siek and Taha's model, the definition of
    class \texttt{Foo<T>} will get instantiated to provide a definition
    of class \texttt{Foo<T*>} when a reference to that type is seen
    inside the definition of \texttt{Bar<T>::g}.}
\label{fig:taha-prog}
\end{figure}

This model breaks down in the presence of template parameters that are
templates because it becomes impossible to determine the dependencies
of a template definition.  In the program in
Figure~\ref{fig:taha-problem}, it is impossible to tell what
definition should be instantiated when processing the definition of
\texttt{Baz<A>::g}.  In the presence of template parameters, Siek and
Taha's model is too eager.

\begin{figure}
\begin{verbatim}
   template <class T> struct Foo { static int f(); };
   template <class T> int Foo<T>::f() { return 3; }

   template <class T> struct Bar { static int f(); };
   template <class T> int Bar<T>::f() { return 4; }

   template <template <class> class A> struct Baz {
     static int g();
   };
   template <template <class> class A>
   int Baz<A>::g() {
     return A<int>::f();
   }

   int main() { return Baz<Foo>::g(); }
\end{verbatim}
  \caption{Siek and Taha's model's early instantiation breaks down
    when it sees the definition of \texttt{Baz<A>::g}.  At this point,
    it can not tell which template is being instantiated in the body.
    By way of contrast, my model doesn't instantiate anything until it
    sees the definition of \texttt{main}.
    (This program is available as
    \texttt{notes/siek-taha-tempvar.cpp})}
\label{fig:taha-problem}
\end{figure}

My model only performs instantiations when there is a ground instance
to drive the instantiation.  Otherwise, it is similar to what is
presented in Siek and Taha.  In particular, it is important to avoid
instantiating member functions unless they are called for.

The model in the \texttt{templates} script is based around a working
state of four components: Templates, Residuals, Needs and
Declarations.  The Templates are those declarations encountered so far
which are of templates.  The Residuals are those ``resolved''
declarations that have either been encountered, or which have been
instantiated from Templates, and are thus ``ground'' or variable-free.
A resolved declaration is one that has had all of its dependencies
appropriately instantiated, or at least recorded.  The Needs are those
declarations that have been required for a resolution, and for which
there have been template declarations, but no definitions.  Needs can
be functions (class-members, including constructors and destructors,
or normal top-level functions), and static data members of classes.
Finally, the Declarations are the declarations that still need to be
processed, coupled with a number specifying how much work has been
done to the declaration so far (all declarations start at level 0).

The Declarations component of the instantation state can grow as well
as shrink, and it is this that can cause compilation to fail to
terminate.

Values in the Declarations component can be declarations or
definitions, and can be of classes, variables and functions.  The
behaviour on encountering declarations of ground entities is rather
involved, and detailed in Table~\ref{tab:ground-decls}.  The basic
idea is that any ground definition can cause the instantiation of
templates.  Such instantiations are always governed by the requirement
that the best match is found.  Successful instantiations are stored in
the Residuals component, so duplicate work is avoided.

Instantiations are done in two phases.  First any template classes
required are instantiated.  This instantiation can in turn prompt
further instantiation because a template class can have template
members, or template ancestors.  if the required types can be
instantiated without causing an infinite loop, the original definition
will eventually return to the top of the Declarations list, but at
Level 1.  This time, the definition is scanned to see if it depends on
any functions or static variables.   These references may or may not
have definitions (though they will all at least have declarations).
Those with definitions are instantiated and put onto the list of
Declarations.  Those without end up in Needs.

When a template declaration is encountered, this is put straight into
the Templates component.  When a template definition is encountered,
this may resolve an outstanding Need, so it is checked against all
current Needs.  Those that can instantiate against the new Template
definition are put onto the Declarations list.

\begin{table}
\hspace{-3em}
\begin{tabular}{lp{0.32\textwidth}p{0.32\textwidth}p{0.32\textwidth}}
  & \multicolumn{1}{c}{\textbf{Function}} &
  \multicolumn{1}{c}{\textbf{Class}} &
  \multicolumn{1}{c}{\textbf{Variable}} \\
  \textbf{Decl.}
  &
  \small \textbf{L0:}
  Add declarations of any referred to template types
  to the list of Declarations still to be processed.
  &
  % Class
  \small \textbf{L0:}
  If not already in Residuals, and a template application, find best
  instantiation for this type and add its instantiated definition
  (less any member function definitions) to
  list of Declarations still to be processed.
  &
  \small \textbf{L0:} Declarations can only be of non-template variables
  (template variables are declared inside class definitions).  Add to
  Residuals and continue.
  \\ \\
  \textbf{Defn.}
  &
  % Function 0
  \small\textbf{L0:} If not already present in Residuals, extract any
  template
  types, and put declarations of
  these into Declarations, ahead of this function definition at
  Level~1.
  &
  % Class 0
  \small \textbf{L0:} Extract any template types from the data-member
  definitions, and put Level~0 declarations for these into
  Declarations, followed by this declaration at Level~1.
  &
  % Variable 0
  \small \textbf{L0:} Add any referenced template types to
  declarations at Level~0 (such types may occur in the initialising
  expression for the variable), followed by the same declaration at
  Level~1.
  \\[1ex]
  &
  % Function 1
  \small \textbf{L1:} Extract any function and static
  variable references, and
  add those with definitions (once instantiated with best match)  to
  Declarations at Level 0.  Those
  functions or static variables without definitions are added to
  Needs.
  &
  % Class 1
  \small \textbf{L1:}
  Required types have been dealt with: now check for definitions of
  any static data members.  Those not present are added to Needs.
  Best matched members are added to Declarations at Level~0.
  &
  % Variable 1
  \small \textbf{L1:} Check initialising expression for references to
  template functions, or other static variables.  Add instantiated
  definitions (for those with definitions) to
  Declarations list at Level~0.  Add others to Needs.
\end{tabular}
\caption{Behaviour of program instantiation on ground declarations}
\label{tab:ground-decls}
\end{table}

\paragraph{Caveat} Unlike Siek and Taha's model, there hasn't been any
validation of my model of program instantiation, whether by the proof
of theorems, or by simulation of concrete examples.





\section{Phase 3: Dynamics}
\label{sec:phase3}

Much of the core semantics in this section is based on the C semantics
presented in my PhD thesis~\cite{Norrish98}.  In particular, details
of the way in which side effects are created and applied remain the
same, as does the use of an evaluation context, and the way in
unspecified order of evaluation is handled.

\subsection{Dynamic States}
\label{sec:dynamic-states}

The dynamic semantics updates values of the type \texttt{state} (see
\HOLfile{states}), given in full in Figure~\ref{fig:state-type}.  The
first four components of the state are sets of addresses.  The
\texttt{allocmap} and \texttt{initmap} sets are from my C
model~\cite{Norrish98}, and record which addresses have been allocated
and initialised, respectively.  The new field \texttt{hallocmap} is
necessary to allow memory to be allocated on the heap, and for its
life-span to persist beyond the end of the current block.  The second
new field, \texttt{constmap} records which memory has been allocated
with the \texttt{const} \emph{cv}-qualifier.  (Updating such memory
causes undefined behaviour.)

\begin{figure}[htbp]
\footnotesize
\begin{verbatim}
   state = <|
     allocmap : addr -> bool ;  (* the set of stack-allocated addresses *)
     hallocmap: addr -> bool ;  (* the set of heap-allocated addresses *)
     constmap : addr -> bool ;  (* the set of read-only addresses *)
     initmap  : addr -> bool ;  (* the set of initialised addresses *)

     fnmap    : CPP_ID |-> fn_info ;
                (* map from function 'names' to type information about
                   the given functions *)
     fnencode : CPP_ID |-> byte list ;
                (* map encoding function 'name' as a byte sequence
                   so that its address can be stored in memory *)
     fndecode : byte list |-> CPP_ID ;
                (* map inverting fnencode *)

     genv: environment ; (* non-local environment *)
     env : environment ; (* local version of the above *)

     locmap   : addr -> byte ;
                (* memory.  Domain might also be ( void * ) words *)

     stack    : (environment # CExpr option # (addr->bool)) list ;
                (* stack of environment, this and allocation info.  
                   Updated as blocks are entered and left *)

     thisvalue: CExpr option ;
                (* the value (i.e., this will always be an ECompVal
                   with a pointer value) of the this expression *)

     blockclasses : constructed list list ;
     exprclasses  : construction_locn list list
       (* the stack of objects that need to have destructors
          called.  First field is for automatic objects that have
          block-delimited lifetimes.  Second is for temporary
          objects that need to be destroyed at the end of the
          full enclosing expression *)
     ;

     current_exns : CExpr list
                    (* stack of exceptions that might be subjected
                       to a bare throw *)
   |>
\end{verbatim}
  \caption{The HOL type of dynamic state.  There are two environment
    values, \texttt{genv}, and \texttt{env}.  The former is for
    non-local, persistent identifiers, the latter for local
    identifiers.  Because there is no such thing as a local namespace,
    there will only be a top-level node in the \texttt{env} field
    (which may, however point to an arbitrarily deep
    \texttt{class_env}).}
\label{fig:state-type}
\end{figure}

\subsection{The Dynamic Relation}

\newcommand{\mng}{\texttt{mng}}

The fundamental relation in the dynamics semantics is \mng{} (or
``meaning''), which is a binary relation on states and abstract syntax
forms.  For reasons to do with the prevention of function call
interleaving (explained below in Section~\ref{sec:small-step-stmts}),
this one relation is used for both expression and statement forms.
(One might otherwise imagine two mutually recursive relations: one for
statements and the other for expressions.)

Thus the type of \mng{} is
\begin{alltt}
   : (state # ExtE) -> (state # ExtE) -> bool
\end{alltt}
making it a binary relation on pairs of states and \emph{extended
  expressions}.  An extended expression is either
\begin{itemize}
\item a syntactic expression coupled with a side effect information
  record (containing the three fields, \texttt{update\_map},
  \texttt{ref\_map} and \texttt{pending\_ses}, ($R$, $\Upsilon$ and
  $\Pi$ in the terminology of my thesis)); or
\item a statement coupled with a continuation, which latter is a
  function that takes a value and returns an expression.  This latter
  is used to recreate the expression in which the function call
  that generated the statement occurred.  Also, all expressions within
  statements (such as those that appear as guards in loops and
  \texttt{if}-statements), are actually extended expressions.
\end{itemize}

In \HOLfile{statements}, the declaration of extended expression
(\texttt{ExtE}) is thus mutually recursive with the type of
statements:
\index{ExtE@\texttt{ExtE}}
\index{EX@\texttt{EX}}
\index{ST@\texttt{ST}}
\begin{verbatim}
   ExtE = EX of CExpr => se_info
        | ST of CStmt => conttype
\end{verbatim}

Most of the time reduction occurs between expressions and expressions,
or between statements and statements, allowing one to imagine that one
has the $\rightarrow_e$ and $\rightarrow_s$ from the C semantics.
For example, when evaluating expressions, rules in the dynamics have
conclusions of the form
\begin{alltt}
   mng (s0, EX e0 se0) (s, EX e se)
\end{alltt}
where \texttt{s0} and \texttt{s} are the initial and final states;
\texttt{e0} and \texttt{e} are the initial and final expression forms;
and \texttt{se0} and \texttt{se} are the initial and final ``side
effect records''.

Similarly, when evaluating statements, conclusions are typically of
the form
\begin{alltt}
   mng (s0, ST st0 c) (s, ST st c)
\end{alltt}
where \texttt{st0} and \texttt{st} are the initial and final statement
forms.  Note that the continuation (\texttt{c} above) never changes
within statement evaluation, meaning that statement rules will always
actually repeat the given continuation from initial to final tuple.

\subsection{Special Syntactic Forms}
\label{sec:spec-synt-forms}

In the abstract syntax types representing both expressions and
statements, I have added special forms that only arise as a result of
evaluation and could never be seen in an input program.  The most
important of these are the forms for representing values and l-values
within the expression type.

\index{ECompVal@\texttt{ECompVal}|textbf}
The \texttt{ECompVal} constructor has type
\begin{alltt}
   : byte list -> CPP_Type -> CExpr
\end{alltt}
and represents values as sequences of bytes, coupled with their type.

\index{LVal@\texttt{LVal}|textbf}
The \texttt{LVal} constructor is used to represent l-values, and has
type
\begin{alltt}
   : addr -> CPP_Type -> CPP_ID list
\end{alltt}
Thus, an l-value is represented by a combination of its base address
and its type, along with the list of identifiers that allow us to
represent the dynamic types of basic object orientation; see
Section~\ref{sec:basic-oo} below.

In addition, there is an analogue to \texttt{LVal} for functions,
called \texttt{FVal}.  This represents the identity of a function, and
has type:
\begin{alltt}
   : CPP_ID -> CPP_Type -> CExpr option -> CExpr
\end{alltt}
A function is identified by its name, its type, and if a (non-static)
member function, the expression denoting the class object for which it
is to be called.

\index{UndefinedExpr@\texttt{UndefinedExpr}}
Finally, there is the special value \texttt{UndefinedExpr} used to
represent the occurrence of undefined behaviour within an expression.

\subsection{Simple Expression Rules}
\label{sec:simple-expr-rules}

\paragraph{Literals} We begin with two rules for literals.  We don't
have any rules for other literal forms, such as floating point
constants, though it is clear what they would look like.
\index{Cnum@\texttt{Cnum}}%
\index{rule (dynamic)!number-literal@\texttt{number-literal}}%
\begin{alltt}
(* RULE-ID: number-literal *)
     (REP_INT (Signed Int) n = SOME bl)
   \(\Rightarrow\)
     mng (s, EX (Cnum n) se)
         (s, EX (ECompVal bl (Signed Int)) se)
\end{alltt}

The only difference with character constants is that the underlying
number is pushed into a different sized space:
\index{Cchar@\texttt{Cchar}}%
\index{rule (dynamic)!char-literal@\texttt{char-literal}}
\begin{alltt}
(* RULE-ID: char-literal *)
     (REP_INT BChar n = SOME bl)
   \(\Rightarrow\)
     mng (s, EX (Cchar n) se) (s, EX (ECompVal bl BChar) se)
\end{alltt}

\paragraph{Variables} Looking up object variables becomes a little
complicated in the presence of references and object orientation.
\index{Var@\texttt{Var}}%
\index{rule (dynamic)!var-to-lvalue@\texttt{var-to-lvalue}}%
\begin{alltt}
(* RULE-ID: var-to-lvalue *)
     (lookup_type s vname = SOME ty0) \(\land\)
     object_type ty0 \(\land\)
     (lookup_addr s vname = SOME (a,cnm,p)) \(\land\)
     (ty = if class_type ty0 then Class cnm else ty0)
   \(\Rightarrow\)
     mng (s, EX (Var vname) se) (s, EX (LVal a ty p) se)
\end{alltt}
\index{lookup_type@\texttt{lookup_type}}%
The call to \texttt{lookup_type} determines the variable's static
type, which will have been set in the appropriate part of the state
when the variable was declared.  The second premise checks to see that
the variable is of object type.  If so, the variable will have an
address.  Accompanying the address is information (\texttt{cnm} and
\texttt{p}) that gives dynamic type information if the object is of
class type.

It may not be clear how a variable may come to have a dynamic type
that is separate from its static type.  In fact, this is only possible
in the presence of references, which are treated as aliases for real
variables.  Thus, in a function such as
\begin{verbatim}
   int f(C &c) { return c.memfn(); }
\end{verbatim}
the variable \texttt{c} is initialised to ``point at'' some existing
variable, and the address maps are set up so that \texttt{c} is indeed
a perfect alias for some existing l-value.  But, the argument may in
fact have been a derived class of \texttt{C}, and so \texttt{c}'s
dynamic type won't be the same as its static type.

Variables can also denote functions:
\index{FVal@\texttt{FVal}}%
\index{Var@\texttt{Var}}%
\index{rule (dynamic)!var-to-fvalue@\texttt{var-to-fvalue}}
\begin{alltt}
(* RULE-ID: var-to-fvalue *)
     (lookup_type s vname = SOME ty) \(\land\)
     function_type ty \(\land\)
     vname IN FDOM s.fnencode
   \(\Rightarrow\)
     mng (s, EX (Var vname) se) (s, EX (FVal vname ty NONE) se)
\end{alltt}


\paragraph{Contextual Evaluation}
\index{valid_econtext@\texttt{valid_econtext}}
Just as in the C semantics, most nested evaluation of expressions is
mediated through one rule: \label{rule:econtext-expr}
\index{rule (dynamic)!econtext-expr@\texttt{econtext-expr}}
\begin{alltt}
(* RULE-ID: econtext-expr *)
     mng (s0, EX e0 se0) (s, EX e se) \(\land\)
     valid_econtext f
   \(\Rightarrow\)
     mng (s0, EX (f e0) se0) (s, EX (f e) se)
\end{alltt}
Here, \texttt{f} is a function of type \texttt{:CExpr->CExpr},
but restricted by the predicate \texttt{valid_econtext}.  This
predicate restricts where evaluation can occur.  For example, a
function satisfying \texttt{valid_econtext} would be
\[
\lambda e.\;\;\texttt{CAnd}\;e\;e_2
\]
for all possible values $e_2$.  Such a function allows reduction to
occur to the left of the \texttt{CAnd} constructor (\ie,
\texttt{\&\&}).  The corresponding function with its ``hole'' on the
right of the \texttt{CAnd} is not a valid context function.

\index{UndefinedExpr@\texttt{UndefinedExpr}}
If an undefined behaviour occurs, this is reflected by having the
expression that caused it become the special \texttt{UndefinedExpr}
value.  This value can rise to the top of any expression:
\index{rule (dynamic)!econtext-undefinedness@\texttt{econtext-undefinedness}}%
\begin{alltt}
(* RULE-ID: econtext-undefinedness *)
     valid_econtext f
   \(\Rightarrow\)
     mng (s, EX (f UndefinedExpr) se) (s, EX UndefinedExpr se)
\end{alltt}

The notion of where a function l-value decays into a pointer to a
function is also controlled by a context:
\index{valid_fvcontext@\texttt{valid_fvcontext}}%
\index{rule (dynamic)!fcontext@\texttt{fcontext}}
\begin{alltt}
(* RULE-ID: fcontext *)
     fnid IN FDOM s.fnencode \(\land\)
     (s.fnencode ' fnid = bytes) \(\land\)
     valid_fvcontext f
   \(\Rightarrow\)
     mng (s, EX (f (FVal fnid ty NONE)) se)
         (s, EX (f (ECompVal bytes (Ptr ty))) se)
\end{alltt}
The definition of \texttt{valid_fvcontext} is
\begin{alltt}
   valid_fvcontext f =
      valid_econtext f \(\land\)
      \(\forall\)args. \(\neg\)(f = \(\lambda\)f'. FnApp f' args)
\end{alltt}
stating that a function l-value can decay as in the rule above, as
long as it is not at the head of a function application.

\index{valid_lvcontext@\texttt{valid_lvcontext}}%
\index{lval2rval@\texttt{lval2rval}}%
Finally, there is the rule allowing normal l-values to decay into
their r-value forms (the ``l-value to r-value conversion''):
\index{rule (dynamic)!lvcontext@\texttt{lvcontext}}%
\begin{alltt}
(* RULE-ID: lvcontext *)
     valid_lvcontext f \(\land\)
     lval2rval (s0,e0,se0) (s,e,se)
   \(\Rightarrow\)
     mng (s0, EX (f e0) se0) (s, EX (f e) se)
\end{alltt}
The \texttt{lval2rval} relation can result in an
\texttt{UndefinedExpr} if the l-value causes a reference to a value
that has already been updated within the same phase of execution, as
might happen in the expression \texttt{i++ + i} for example.
Otherwise, if the l-value denotes an object not of class type, the
l-value turns into a list of bytes (an \texttt{ECompVal}), ready for
further manipulations to occur.

\paragraph{Operators} The rules governing the behaviour of the
standard operators are as in the original C semantics.  The rules for
the standard computational binary operators (arithmetic and shift
operators) are presented in Figure~\ref{fig:capbinary-rules}, and
depend on an auxiliary relation \texttt{binop_meaning}, which is
defined in \HOLfile{operators}.  Being a relation, it allows for
nondeterminism and failure.

Were the model to cope with operator overloading correctly, these
rules would remain unchanged.  Operator overloading would be resolved
in Phases~1 and~2, allowing uses of overloaded operators to be
rewritten to the function calls that they really are.
\begin{figure}[htbp]
\index{CApBinary@\texttt{CApBinary}}%
\index{rule (dynamic)!binop-fails@\texttt{binop-fails}}%
\index{rule (dynamic)!binop-computes@\texttt{binop-computes}}%
\begin{alltt}
(* RULE-ID: binop-fails *)
     (\(\forall\)res restype. \(\neg\)binop_meaning s f \(\!\)v1 (strip_const type1)
                                       v2 (strip_const type2)
                                       res restype)
   \(\Rightarrow\)
     mng (s, EX (CApBinary f (ECompVal v1 type1)
                             (ECompVal v2 type2)) se0)
         (s, EX UndefinedExpr se0)
\end{alltt}

\begin{alltt}
(* RULE-ID: binop-computes *)
     binop_meaning s f v1 (strip_const type1)
                       v2 (strip_const type2)
                       res restype
   \(\Rightarrow\)
     mng (s, EX (CApBinary f (ECompVal v1 type1)
                             (ECompVal v2 type2)) se)
         (s, EX (ECompVal res restype) se)
\end{alltt}
\caption{Rules for the standard binary operators}
\label{fig:capbinary-rules}
\end{figure}

There are analogous rules for the standard unary operators (arithmetic
and logical negation, unary plus, and bit-wise complement), presented
in Figure~\ref{fig:capunary-rules}.
\begin{figure}[htbp]
\index{CApUnary@\texttt{CApUnary}}%
\index{rule (dynamic)!unop-computes@\texttt{unop-computes}}%
\index{rule (dynamic)!unop-fails@\texttt{unop-fails}}%
\begin{alltt}
(* RULE-ID: unop-computes *)
     unop_meaning f ival (strip_const t) result rt
   \(\Rightarrow\)
     mng (s, EX (CApUnary f (ECompVal ival t)) se)
         (s, EX (ECompVal result rt) se)
\end{alltt}

\begin{alltt}
(* RULE-ID: unop-fails *)
     (\(\forall\)res rt. \(\neg\)unop_meaning f ival (strip_const t) res rt)
   \(\Rightarrow\)
     mng (s0, EX (CApUnary f (ECompVal ival t)) se0)
         (s0, EX UndefinedExpr se0)
\end{alltt}
\caption{Rules for the standard unary operators}
\label{fig:capunary-rules}
\end{figure}

\paragraph{Sequential Operators}
The logical operators \texttt{\&\&} and \texttt{||}, the ternary
conditional operator \texttt{?:}, and the comma operator all evaluate
their arguments in a prescribed order, and must exhaust the pending
side effects that may have accumulated in a state before they can move
from one argument to the next, if indeed they move on at all.   For
example, the rule where logical-and returns false is
\index{rule (dynamic)!and-false@\texttt{and-false}}%
\begin{alltt}
(* RULE-ID: and-false *)
     is_zero t v
   \(\Rightarrow\)
     mng (s, EX (CAnd (ECompVal v t) sub2) se)
         (s, EX (ECompVal (signed_int 0) Bool) se)
\end{alltt}
When the first argument is true (non-zero), the truth value of the
second argument is the result.  The conversion of the second argument
to a truth value is achieved by negating twice:
\index{rule (dynamic)!and-true@\texttt{and-true}}%
\begin{alltt}
(* RULE-ID: and-true *)
     ~is_zero t v \(\land\)
     is_null_se se
   \(\Rightarrow\)
     mng (s, EX (CAnd (ECompVal v t) sub2) se)
         (s, EX (CApUnary CNot (CApUnary CNot sub2)) base_se)
\end{alltt}
\index{is_null_se@\texttt{is_null_se}|textbf}%
The \texttt{is_null_se} predicate tests whether or not a side effect
record is empty of pending side effects.
\index{base_se@\texttt{base_se}|textbf}%
The \texttt{base_se} value is the empty side effect record; it is the
appropriate starting point for a new phase of execution after a
sequence point has been reached.

\medskip
\noindent
\index{CommaSep@\texttt{CommaSep}}%
The comma operator (\texttt{CommaSep} here) always evaluates both of
its arguments.  As with the other operators, evaluation of the first
argument is handled by the contextual evaluation rule; we need only
provide a rule for when the left-hand expression has been fully
evaluated.
\index{rule (dynamic)!comma-progresses@\texttt{comma-progresses}}%
\begin{alltt}
(* RULE-ID: comma-progresses *)
     final_value (EX e1 se)
   \(\Rightarrow\)
     mng (s0, EX (CommaSep e1 e2) se)
         (s0, EX (RValreq e2) base_se)
\end{alltt}
\index{RValreq@\texttt{RValreq}}%
The special \texttt{RValreq} form is used to force l-values to
evaluate to r-values if possible.  (See~\cite[\S3.3.3]{Norrish98} for
why this form is necessary.)
\index{final_value@\texttt{final_value}|textbf}%
The \texttt{final_value} predicate (from \HOLfile{statements}) checks
an extended expression to confirm that it represents a completely
evaluated form.  Its definition is
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
   (final_value (EX e se) =
      is_null_se se \(\land\)
      ((\(\exists\)v t. e = ECompVal v t) \(\lor\)
       (\(\exists\)a t p. e = LVal a t p))) \(\land\)

   (final_value (ST s c) = F)
\end{alltt}
\end{minipage}
\end{center}

\paragraph{Pointer Operations}
The two significant pointer operations are dereferencing and
address-taking (the \texttt{*} and \texttt{\&} operators
respectively).  \cpp{} adds two class-related variants of these
operations to the existing pair, which come across from C practically
unchanged.  Thus the rule for taking an address:
\index{Addr@\texttt{Addr}}%
\index{rule (dynamic)!addr-lvalue@\texttt{addr-lvalue}}
\begin{alltt}
(* RULE-ID: addr-lvalue *)
(* See 5.3.1 p2-5 - taking the address of an lvalue *)
     (SOME result = ptr_encode s a t pth)
   \(\Rightarrow\)
     mng (s, EX (Addr (LVal a t pth)) se)
         (s, EX (ECompVal result
                          (Ptr (static_type (t,pth)))) se)

\end{alltt}
\index{LVal@\texttt{LVal}}%
The function
\texttt{static_type}\index{static_type@\texttt{static_type}} computes
the static type for a l-value given access to the type and path of
identifiers.  (For non-class values, the static type is simply the
second argument to \texttt{LVal}.)

There must be two rules for dereferencing a normal pointer; it may or
may not point to a valid object.  In fact, there must also be a third
rule because of the possibility that the pointer value being
dereferenced is actually a pointer to a function. These rules are presented in
Figure~\ref{fig:deref-rules}.
\begin{figure}[htbp]
\index{rule (dynamic)!deref-objptr@\texttt{deref-objptr}}%
\index{rule (dynamic)!deref-objptr-fails@\texttt{deref-objptr-fails}}%
\index{rule (dynamic)!deref-fnptr@\texttt{deref-fnptr}}%
\index{Deref@\texttt{Deref}}%
\begin{alltt}
(* RULE-ID: deref-objptr *)
(* 5.3.1 p1 - pointer to an object type *)
     object_type t \(\land\)
     (SOME mval = ptr_encode s addr t' pth) \(\land\)
     (static_type (t',pth) = t)
   \(\Rightarrow\)
     mng (s, EX (Deref (ECompVal mval (Ptr t))) se)
         (s, EX (LVal addr t' pth) se)


(* RULE-ID: deref-objptr-fails *)
     object_type t \(\land\)
     ((\(\forall\)addr t' p. \(\neg\)(SOME mval = ptr_encode s addr t' p)) \(\lor\)
      (\(\exists\)t' p. SOME mval = ptr_encode s 0 t' p))
   \(\Rightarrow\)
     mng (s, EX (Deref (ECompVal mval (Ptr t))) se)
         (s, EX UndefinedExpr se)


(* RULE-ID: deref-fnptr *)
(* 5.3.1 p1 - pointer to a function type *)
     v IN FDOM s.fndecode
   \(\Rightarrow\)
     mng (s, EX (Deref
                  (ECompVal v
                            (Ptr (Function retty argtys))))
                se)
         (s, EX (FVal (s.fndecode ' v)
                      (Function retty argtys)
                      NONE) se)
\end{alltt}
\caption{Rules for ``C-style'' dereferencing of pointers}
\label{fig:deref-rules}
\end{figure}

\medskip
\noindent More interesting from a \cpp{} perspective are the rules for
taking the address of class-members (and then using those pointers to
members to access members).  The concrete syntax for this is
rather ugly:
\begin{verbatim}
   struct C { int x; int y; };
   int C::* cintptr = &C::x; // or &C::y
\end{verbatim}
\index{MemAddr@\texttt{MemAddr}}%
In the abstract syntax, the address taking operation is written
\texttt{MemAddr}, of type
\begin{verbatim}
   : CPP_ID -> IDComp -> CExpr
\end{verbatim}
where the first argument is the name of the class, and the second is
the name of the field.

If the member whose address is being taken is actually a static
member, then a normal pointer is generated, as can be seen from the
type attached to the \texttt{ECompVal} in the conclusion of the rule.
(There is a similar rule for taking the address of a static member
function.)
\index{rule (dynamic)!mem-addr-static-nonfn@\texttt{mem-addr-static-nonfn}}%
\begin{alltt}
(* RULE-ID: mem-addr-static-nonfn *)
(* 5.3.1 p2 *)
     object_type ty \(\land\)
     MEM (FldDecl fldname ty, T, prot)
         (cinfo s cname).fields \(\land\)
     (lookup_addr s (mk_member cname fldname) =
        SOME (addr, pth)) \(\land\)
     (SOME ptrval = ptr_encode s addr ty (SND pth))
   \(\Rightarrow\)
     mng (s, EX (MemAddr cname fldname) se)
         (s, EX (ECompVal ptrval (Ptr ty)) se)
\end{alltt}
\index{cinfo@\texttt{cinfo}}
The function \texttt{cinfo} takes a state and a class-name and returns
the information about that class in the form of a record, one of whose
fields is called \texttt{fields}, being a list of all the declarations
occurring within the class.

\bigskip\noindent
The more interesting case occurs when the member is not static.
\index{rule (dynamic)!mem-addr-nonstatic@\texttt{mem-addr-nonstatic}}%
\begin{alltt}
(* RULE-ID: mem-addr-nonstatic *)
     (encode_offset cnm fldname = SOME bl) \(\land\)
     ((\(\exists\)prot. MEM (FldDecl fldname ty, F, prot)
                  (cinfo s cnm).fields) \(\lor\)
      (\(\exists\)prot v rt args bod.
          MEM (CFnDefn v rt fldname args bod, F, prot)
              (cinfo s cnm).fields \(\land\)
          (ty = Function rt (MAP SND args))))
   \(\Rightarrow\)
     mng (s, EX (MemAddr cnm fldname) se)
         (s, EX (ECompVal bl (MPtr cnm ty)) se)
\end{alltt}
Functions and data members are not declared in quite the same way
within a class (because the functions may be accompanied by their
implementations), which explains the disjunctive hypothesis above.
The function \texttt{encode_offset} takes a class and field-name and
returns the encoding of this offset as a list of bytes.  It is that is
will be written into memory if the offset is stored in a variable.

\bigskip\noindent
Once one has a pointer-to-member value, one can dereference it, as
long as one also had a class object to hand.  Unlike normal C-style
dereferencing, dereferencing a pointer-to-member is a binary
operator.  The concrete C++ syntax looks like:
\begin{verbatim}
   int f(int C::* cintptr, C c)
   {
     return c.*cintptr;
   }
\end{verbatim}
There is also a \texttt{->*} operator for when one has a pointer to a
class (by analogy with the \texttt{->} operator for field
dereferencing).  In the abstract syntax, the one operator is called
\texttt{OffsetDeref}.\index{OffsetDeref@\texttt{OffsetDeref}}

The rule is complicated by the fact that if the pointer to a member is
to a virtual function, then the result must be a reference to a
virtual function in the class on which the dereference is
performed.
\index{rule (dynamic)!offset-deref@\texttt{offset-deref}}%
\begin{alltt}
(* RULE-ID: offset-deref *)
     (encode_offset cnm2 fldname = SOME bl) \(\land\)
     (fld = if function_type fldty then
              let (r,a) = dest_function_type fldty
              in
                if is_virtual s cnm2 fldname r a then
                  IDConstant F [] fldname
                else
                  mk_member cnm2 fldname
            else
              mk_member cnm2 fldname)
   \(\Rightarrow\)
     mng (s, EX (OffsetDeref
                     (LVal a (Class cnm1) p)
                     (ECompVal bl (MPtr cnm2 fldty)))
                se)
         (s, EX (SVar (LVal a (Class cnm1) p) fld)
                se)
\end{alltt}
The invariant in the model is that if a reference is made to a virtual
function, then it must occur as the right-hand argument of a
field-selection as a bare name (hence the
\texttt{IDConstant~F~[]}\dots above), and conversely that if a
reference is not to a virtual function, then the field dereference
must be to a completely qualified identifier.\footnote{Note the
  contrast with C: in \cpp, one can write \texttt{c.::B::fld}, which
  is unambiguous, if ugly, about which \texttt{fld} member is meant.}

It is possible to have null member pointers
(see~\cite[\S4.11]{cpp-standard-iso14882}).  We specify
\texttt{encode_offset} in such a way that the null member pointer
constant is not in its range, and add the rule
\index{rule (dynamic)!offset-deref-fails@\texttt{offset-deref-fails}}%
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: offset-deref-fails *)
     T
   \(\Rightarrow\)
     mng (s, EX (OffsetDeref
                   (LVal a (Class cnm1) p)
                   (ECompVal null_member_ptr (MPtr cnm2 fldty)))
                se)
         (s, EX UndefinedExpr se)
\end{alltt}
\end{minipage}
\end{center}
It is undefined behaviour to apply the null member pointer to any
class.

\paragraph{Assignment}
The rules for assignment do not need to change from their presentation
in C.  Nonetheless, this semantics adopts Clive
Feather's\index{Feather, Clive} proposal~\cite{Feather2000} for
handling the infamous language in the standard:
\begin{quotation}
\itshape
    Between the previous and next sequence point an  object
    shall  have  its  stored  value modified at most once by the
    evaluation of an expression.  Furthermore, the  prior  value
    shall  be  accessed  only  to  determine  the  value  to  be
    stored.
\end{quotation}
Rather than count references made on the RHS of an assignment, as in
my thesis~\cite{Norrish98}, the model now is that references can occur
before updates, but not the other way round.  This makes the rules for
assignment considerably simpler, at the cost of requiring an analysis
of all possible execution paths to see if any of them result in an
update before a reference.

\index{Assign@\texttt{Assign}}%
The rule for a completed assignment expression is:
\begin{center}
\label{rule:assign-completes}
\index{rule (dynamic)!assign-completes@\texttt{assign-completes}}%
\begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: assign-completes *)
    \(\neg\)class_type lhs_t \(\land\)
    (nonclass_conversion s (v0,t0) (v,lhs_t) \(\land\) (* 5.17 p3 *)
     (se = add_se (a, v) se0) \(\land\) (resv = ECompVal v lhs_t)
                          \(\lor\)
     (\(\forall\)v. \(\neg\)nonclass_conversion s (v0, t0) (v, lhs_t)) \(\land\)
     (resv = UndefinedExpr) \(\land\)
     (se = se0))
   \(\Rightarrow\)
     mng (s, EX (Assign NONE (LVal a lhs_t [])
                             (ECompVal v0 t0)) se0)
         (s, EX resv se)
\end{alltt}
\end{minipage}
\end{center}
The \texttt{NONE} value that is the first argument ot \texttt{Assign}
is where a binary operator can be installed, implementing the
\texttt{op=} syntax (\texttt{+=}, \texttt{>>=} etc.).  The rule that
deals with this is
\index{CApBinary@\texttt{CApBinary}}%
\index{rule (dynamic)!assign-op-assign@\texttt{assign-op-assign}}
\begin{alltt}
(* RULE-ID: assign-op-assign *)
     T
   \(\Rightarrow\)
     mng (s0, EX (Assign (SOME f) (LVal n t p) e) se0)
         (s0, EX (Assign NONE
                         (LVal n t p)
                         (CApBinary f (LVal n t p) e)) se0)

\end{alltt}
(Note that the hypothesis true (\texttt{T}) means there are no
preconditions on this transition occurring.)



\subsection{Statements in a Small-step Style}
\label{sec:small-step-stmts}

One might imagine that stating the statement part of a dynamic
semantics in a small-step style should be easy.  (My
thesis~\cite[\S7.1]{Norrish98} explains why the way I formulated
statements in a big-step style was a mistake.) The literature contains
many examples of how to express constructs such as \texttt{while} and
\texttt{if} in a small-step style.  However, this is not as
straightforward as one might think because of the need to prevent
function bodies from interleaving.

Imagine a program such as that in Figure~\ref{fig:two-functions}, and
how one might evaluate the return-expression in \texttt{main}.  If one
simply expanded the bodies of the called functions into the expression
as the functions were ready to be called, one would be permitting the
simultaneous evaluation of the bodies of \texttt{f} and \texttt{g}.
But the \cpp{} standard explicitly forbids this (\S1.8~fn8), and the C
standard also hints that it is forbidden.
\begin{figure}[htbp]
\begin{verbatim}
   int global;
   int f(int x) { return global * 2 + x; }
   int g(int y) { while (y > 0) { global += 2; y--; } }

   int main(void) {
     global = 10;
     return f(6) + g(10);
   }
\end{verbatim}
\caption{Where Functions Must Not Interleave}
\label{fig:two-functions}
\end{figure}

One has to arrange the semantics so that expression evaluation can
continue non-deterministically until a function call is encountered
and the function call is made (after arguments have been evaluated).
At this point, all further evolution of the program must occur within
the function body, no matter how deeply nested the function call may
have been within an enclosing expression.  (This problem does not
occur if statement evaluation is big-step because the hypothesis in
the expression rule for a function call would be a statement rule that
required the complete evaluation of the function body.)

\index{FnApp@\texttt{FnApp}} At the base level, a function call turns
an \texttt{EX} piece of syntax into an extended expression tagged with
\texttt{ST}.  The rule \ruleid{global-function-call} of
Figure~\ref{fig:global-function-call} governs (normal) function calls:
\begin{figure}[hbtp]
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!global-function-call@\texttt{global-function-call}}%
\label{rule:global-function-call}
\begin{alltt}
(* RULE-ID: global-function-call *)
     find_best_fnmatch s0 fnid (MAP valuetype args)
                       rtype params body \(\land\)
     (pdecls = MAP (\(\lambda\)((n,ty),a).
                       VDecInit ty (Base n)
                                   (CopyInit (EX a base_se)))
                   (ZIP (params, args)))
   \(\Rightarrow\)
     mng (s0, EX (FnApp_sqpt (FVal fnid ftype NONE) args) se)
         (s0 with <| stack updated_by 
                       (CONS (s0.env, s0.thisvalue, 
                              s0.allocmap));
                     thisvalue := NONE;
                     blockclasses updated_by stackenv_newscope ;
                     exprclasses updated_by stackenv_newscope ;
                     env := empty_env |>,
          ST (Block T pdecls [body]) (return_cont se rtype))
\end{alltt}
\end{minipage}
\end{center}
\caption{Making a call to a global (\ie, non member) function}
\label{fig:global-function-call}
\end{figure}

\index{return_cont@\texttt{return_cont}}%
(For the details behind \texttt{return_cont}, and the \texttt{RVC}
function that appears in the next rule, see
Section~\ref{sec:refs-returned-from-fns}.  For the operations applied
to \texttt{s0}, setting up the new function's scope, see
Section~\ref{sec:statements-blocks}.)  At this point, the standard
rule for evaluating an expression within a context
(\ruleid{expr-econtext}, p\pageref{rule:econtext-expr}) can not fire,
because its hypothesis is of the form
\[
\texttt{mng (s0, EX e0 se0) (s, EX e se)}
\]
Instead, the new rule
\label{rule:econtext-stmt}
\begin{alltt}
(* RULE-ID: econtext-stmt *)
     mng (s0, EX e se0) (s, ST stmt c) \(\land\)
     valid_econtext f
   \(\Rightarrow\)
     mng (s0, EX (f e) se0) (s, ST stmt (cont_comp f c))
\end{alltt}
can fire, turning the enclosing expression into a statement form, with
an ever more elaborate continuation.   The r\^ole of the continuation
is to do no more than record where the function-call was, so that when
the statement form finishes execution, its result can be slotted back
into the appropriate expression.

These rules have specified what happens when an expression evaluation
switches to a statement evaluation.  In the opposite direction, when a
function call is about to return, one of the rules is
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!return-rvalue@\texttt{return-rvalue}}
\label{rule:return-rvalue}
\begin{alltt}
(* RULE-ID: return-rvalue *)
     is_null_se se0
   \(\Rightarrow\)
     mng (s, ST (Ret (EX (ECompVal v t) se0)) (RVC c se))
         (s, EX (c (ECompVal v t)) se)
\end{alltt}
\end{minipage}
\end{center}
In this situation, the \texttt{return} statement has completely
evaluated its argument into a value, and there are no remaining side
effects to be evaluated.  This means that the value can be put back
into the containing expression tree, and expression evaluation can
continue.  This is reflected by the switch from \texttt{ST} to
\texttt{EX}, and the application of the continuation \texttt{c} to the
value.

Note how the argument to the return statement is itself an extended
expression.  This means that the argument will be tagged with
\texttt{EX} initially, but may later evolve to be a statement and
continuation (tagged with \texttt{ST}) if the return-expression
includes a function call.  This means that the rule for evaluation of
the argument of return is
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!return-eval-under@\texttt{return-eval-under}}
\begin{alltt}
(* RULE-ID: return-eval-under *)
     mng (s1, exte0) (s2, exte)
   \(\Rightarrow\)
     mng (s1, ST (Ret exte0) c) (s2, ST (Ret exte) c)
\end{alltt}
\end{minipage}
\end{center}
where \texttt{exte0} and \texttt{exte} may be statements or
expressions.

\paragraph{Statement Evaluation Strategy}
The basic idea behind all of the rules for statements are that they
should be evaluated until they yield a ``final'' form.  As is
explained further in Section~\ref{sec:refs-returned-from-fns} below,
such an evaluation has to be done in the context of the continuation
that is accompanying the statement.  In essence, a final form is both
one that can not be further evaluated, and also something that can be
returned to a higher level as some sort of result.  The definition of
\texttt{final_stmt} is from \HOLfile{statements}:
\index{final_stmt@\texttt{final_stmt}|textbf}%
\index{final_value@\texttt{final_value}}%
\begin{alltt}
  (final_stmt EmptyStmt c = T) \(\land\)
  (final_stmt Break c = T) \(\land\)
  (final_stmt Cont c = T) \(\land\)
  (final_stmt (Ret e) c =
     case c of
        LVC f se0 -> (\(\exists\)a t p se. (e = EX (LVal a t p) se) \(\land\)
                                 is_null_se se)
     || RVC f se0 -> final_value e) \(\land\)
  (final_stmt (Throw exn) c = \(\exists\)e. (exn = SOME e) \(\land\)
                                  final_value e) \(\land\)
  (final_stmt _ c = F)
\end{alltt}
\index{Throw@\texttt{Throw}}%
\index{EmptyStmt@\texttt{EmptyStmt}}%
\index{Ret@\texttt{Ret}}%
The \texttt{Throw} form implements exceptions (for which, see
Section~\ref{sec:exceptions}); most statements will evaluate to either
an \texttt{EmptyStmt}, or a \texttt{Ret}.

\subsubsection{Simple Statements}
\label{sec:simple-statements}

The rules for the simplest statement forms, expression statements
(using the \texttt{Standalone}
``constructor''\index{Standalone@\texttt{Standalone}}) and
if~statements are given in Figure~\ref{fig:simple-stmts}.  While an
expression statement explicitly terminates (yielding an
\texttt{EmptyStmt}), the if statement just evolves into one of its two
branches.
\begin{figure}[htbp]
\index{rule (dynamic)!standalone-evaluates@\texttt{standalone-evaluates}}%
\index{rule (dynamic)!standalone-finishes@\texttt{standalone-finishes}}%
\index{rule (dynamic)!if-eval-guard@\texttt{if-eval-guard}}%
\index{rule (dynamic)!if-true@\texttt{if-true}}%
\index{rule (dynamic)!if-false@\texttt{if-false}}%
\index{CIf@\texttt{CIf}}
\begin{alltt}
(* RULE-ID: standalone-evaluates *)
     mng (s1, exte) (s2, exte')
   \(\Rightarrow\)
     mng (s1, ST (Standalone exte) c)
         (s2, ST (Standalone exte') c)


(* RULE-ID: standalone-finishes *)
     is_null_se se \(\land\)
     final_value e
   \(\Rightarrow\)
     mng (s, ST (Standalone e) c) (s, ST EmptyStmt c)


(* RULE-ID: if-eval-guard *)
     mng (s0, RVR guard) (s, RVR guard')
   \(\Rightarrow\)
     mng (s0, ST (CIf guard t e) c)
         (s, ST (CIf guard' t e) c)


(* RULE-ID: if-true *)
     scalar_type t \(\land\)
     is_null_se se \(\land\)
     \(\neg\)is_zero t v
   \(\Rightarrow\)
     mng (s, ST (CIf (EX (ECompVal v t) se) thenstmt elsestmt) c)
         (s, ST thenstmt c)


(* RULE-ID: if-false *)
     scalar_type t \(\land\)
     is_null_se se \(\land\)
     is_zero t v
   \(\Rightarrow\)
     mng (s, ST (CIf (EX (ECompVal v t) se) thenstmt elsestmt) c)
         (s, ST elsestmt c)
\end{alltt}
\caption{Statement Rules for Expression and If Statements}
\label{fig:simple-stmts}
\end{figure}

\index{loops}%
\index{CLoop}%
\paragraph{Loops} The loop forms in \cpp{} are modelled just as they
were in my thesis~\cite[\S3.4.5]{Norrish98}, as syntactic sugar for
forms involving one loop and different arrangements of the
\texttt{Trap}, \texttt{continue} and \texttt{break} primitives.
This allows just one, unconditional rule for all loops:
\begin{center}
  \begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: loop *)
     T
   \(\Rightarrow\)
     mng (s, ST (CLoop guard bdy) c)
         (s, ST (CIf guard (Block F [] [bdy; CLoop guard bdy])
                           EmptyStmt) c)
\end{alltt}
  \end{minipage}
\end{center}

\paragraph{Traps, and Loop Interruptions}
\index{Trap@\texttt{Trap}}%
\index{Break@\texttt{Break}}%
\index{Cont@\texttt{Cont}}%
Again, following my thesis, the rules for traps are straightforward,
though relatively plentiful because of the different possible
combinations of \texttt{continue} (written \texttt{Cont}) and
\texttt{break} (written \texttt{Break}).  The simplest rules for these
forms are presented in Figure~\ref{fig:traps}.  The rule for the way
in which \texttt{break}, \texttt{continue}, \texttt{return} and
exceptions all cause flow of control to alter within a block is
presented in Section~\ref{sec:statements-blocks} below.

\begin{figure}[htbp]
\index{rule (dynamic)!trap-stmt-evaluation@\texttt{trap-stmt-evaluation}}%
\index{rule (dynamic)!trap-break-catches@\texttt{trap-break-catches}}%
\index{rule (dynamic)!trap-continue-catches@\texttt{trap-continue-catches}}%
\index{rule (dynamic)!trap-continue-passes-break@\texttt{trap-continue-passes-break}}%
\index{rule (dynamic)!trap-break-passes-continue@\texttt{trap-break-passes-continue}}%
\index{rule (dynamic)!trap-emptystmt-passes@\texttt{trap-emptystmt-passes}}%
\index{rule (dynamic)!trap-ret-passes@\texttt{trap-ret-passes}}%
\begin{alltt}
(* RULE-ID: trap-stmt-evaluation *)
     mng (s0, ST st c) (s, ST st' c)
   \(\Rightarrow\)
     mng (s0, ST (Trap tt st) c) (s, ST (Trap tt st') c)

(* RULE-ID: trap-break-catches *)
     T
   \(\Rightarrow\)
     mng (s, ST (Trap BreakTrap Break) c) (s, ST EmptyStmt c)

(* RULE-ID: trap-continue-catches *)
     T
   \(\Rightarrow\)
     mng (s0, ST (Trap ContTrap Cont) c) (s0, ST EmptyStmt c)

(* RULE-ID: trap-continue-passes-break *)
     T
   \(\Rightarrow\)
     mng (s, ST (Trap ContTrap Break) c) (s, ST Break c)

(* RULE-ID: trap-break-passes-continue *)
     T
   \(\Rightarrow\)
     mng (s, ST (Trap BreakTrap Cont) c) (s, ST Cont c)

(* RULE-ID: trap-emptystmt-passes *)
     T
   \(\Rightarrow\)
     mng (s0, ST (Trap tt EmptyStmt) c) (s0, ST EmptyStmt c)

(* RULE-ID: trap-ret-passes *)
     final_value e
   \(\Rightarrow\)
     mng (s, ST (Trap tt (Ret e)) c) (s, ST (Ret e) c)
\end{alltt}
  \caption{Dynamic Rules for Loop Interruptions and Traps}
  \label{fig:traps}
\end{figure}

\paragraph{Declarations in Guards}
\cpp{} allows variables to be declared in the guard positions of loop
forms and if statements.  This is a syntactic nicety that we can assume
has been compiled away.  For example, something like
\begin{verbatim}
   if (int i = e) { ... }
\end{verbatim}
can be rewritten into
\begin{verbatim}
   { int i = e; if (i) { ... } }
\end{verbatim}
I take a similar attitude to \cpp's relaxation of C's rule that
declarations and statements can intermingle.  Such an intermingling
can be rewritten to successive nested blocks, all of which respect the
basic C rule that a block is a sequence of declarations followed by a
sequence of statements.

\subsubsection{Statements in Blocks}
\label{sec:statements-blocks}

\index{Block@\texttt{Block}}
The compound statement is the basic syntactic structure expressing
scope at the statement level.  Its manifestation in this model is as
the constant \texttt{Block}, with type
\begin{verbatim}
   : bool -> var_decl list -> CStmt list -> CStmt
\end{verbatim}
The initial boolean field is used to record whether or not a block has
been entered.  It starts as false (\texttt{F}).  The rule for entering
a block is
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-entry@\texttt{block-entry}}
\begin{alltt}
(* RULE-ID: block-entry *)
     T
   \(\Rightarrow\)
     mng (s, ST (Block F vds sts) c)
         (s with <| stack updated_by
                      (CONS (s.env, s.thisvalue, s.allocmap));
                    blockclasses updated_by
                      stackenv_newscope ;
                    exprclasses updated_by
                      stackenv_newscope |>,
          ST (Block T vds sts) c)
\end{alltt}
\end{minipage}
\end{center}
\index{stack (state field)@\texttt{stack} (\texttt{state} field)}%
\index{env (state field)@\texttt{env} (\texttt{state} field)}%
The \texttt{blockclasses} and \texttt{exprclasses} fields are to do
with pending destructor calls, and are further explained in
Section~\ref{sec:exceptions}.  The field \texttt{stack} is a stack of
local environments, coupled with a stack of values for the
\texttt{this} pointer.  When a block is entered, the old value for
the environment needs to be stored so that it can be restored on block
exit.  Recall that the field \texttt{env} stores all of the
information about \emph{local} entities.  Information on non-local
entities is all recorded in the \texttt{genv} field.

After a block is entered, its variable declarations must be executed.
This is handled by the rule \ruleid{block-declmng}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-declmng@\texttt{block-declmng}}
\begin{alltt}
(* RULE-ID: block-declmng *)
     declmng mng (d0, s0) (ds, s)
   \(\Rightarrow\)
     mng (s0, ST (Block T (d0 :: vds) sts) c)
         (s, ST (Block T (ds ++ vds) sts) c)
\end{alltt}
\end{minipage}
\end{center}
\index{declmng relation@\texttt{declmng} relation}%
The auxiliary \texttt{declmng} (which takes \texttt{mng} as a
parameter, allowing it to recurse back to it) has type
\begin{verbatim}
   : ((state # ExtE) -> (state # ExtE) -> bool) ->
     (var_decl # state) -> (var_decl list # state) -> bool
\end{verbatim}
The ``return'' of a list of new variable declarations allows
termination to be indicated (by returning the empty list), and also
allows complicated object constructions, which involve multiple calls
to initialise sub-objects, done through special forms of variable
declaration.  There is more on the simple forms of \texttt{declmng} in
Section~\ref{sec:simple-declarations} below.

When the declaration list is exhausted, execution of a block's body of
statements can proceed.  The congruence rule for a block is
\ruleid{block-stmt-evaluate}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-stmt-evaluate@\texttt{block-stmt-evaluate}}%
\begin{alltt}
(* RULE-ID: block-stmt-evaluate *)
     mng (s0, ST st c) (s, ST st' c)
   \(\Rightarrow\)
     mng (s0, ST (Block T [] (st :: sts)) c)
         (s, ST (Block T [] (st' :: sts)) c)
\end{alltt}
\end{minipage}
\end{center}
Note the form of \texttt{Block} required: it must have no further
variable declarations to evaluate, and must have been entered (has its
boolean flag set to~\texttt{T}).

\index{EmptyStmt@\texttt{EmptyStmt}}
If the first statement inside a \texttt{Block} is, or becomes, an
\texttt{EmptyStmt}, and there are more statements beyond it to
evaluate, then the \texttt{EmptyStmt} can be discarded:
\begin{center}
  \begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: block-emptystmt *)
     \(\neg\)(sts = [])
   \(\Rightarrow\)
     mng (s, ST (Block T [] (EmptyStmt::sts)) c)
         (s, ST (Block T [] sts) c)
\end{alltt}
\end{minipage}
\end{center}

Alternatively, if the head statement is an exception or interruption
form, and it is followed by other statements, then it causes all
following statements to disappear:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-interrupted@\texttt{block-interrupted}}
\begin{alltt}
(* RULE-ID: block-interrupted *)
     final_stmt exstmt c \(\land\)
     \(\neg\)(exstmt = EmptyStmt) \(\land\)
     \(\neg\)(sts = [])
   \(\Rightarrow\)
     mng (s, ST (Block T [] (exstmt::sts)) c)
         (s, ST (Block T [] [exstmt]) c)
\end{alltt}
\end{minipage}
\end{center}

Then, when a final statement is the only thing remaining in a block,
the block itself can exit, clearing its local stack frame in the
environment, and propagating the final statement upwards.  This gives
us \ruleid{block-exit}, in Figure~\ref{fig:block-exit}.
\begin{figure}
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-exit@\texttt{block-exit}}
\begin{alltt}
(* RULE-ID: block-exit *)
     (s.stack = (env,this,amap) :: stk') \(\land\)
     final_stmt st c \(\land\)
     (s.blockclasses = []::bcs) \(\land\)
     (s.exprclasses = []::ecs)
   \(\Rightarrow\)
     mng (s, ST (Block T [] [st]) c)
         (s with <| stack := stk';
                    allocmap := amap;
                    env := env;
                    thisvalue := this;
                    blockclasses := bcs;
                    exprclasses := ecs |>,
          ST st c)
\end{alltt}
\end{minipage}
\end{center}
\caption{Exiting a block}
\label{fig:block-exit}
\end{figure}
\index{blockclasses (state field)@\texttt{blockclasses} (\texttt{state} field)}%
By requiring that the \texttt{blockclasses} and \texttt{exprclasses}
components of the state be empty at their heads, we require that all
local objects have had their destructors called (for more on this, see
Section~\ref{sec:object-lifetimes}).  If this condition is met, the
various stacks can be popped, and the final statement lifted up a
level.  In this way, a return statement deep within multiple blocks
can eventually make its way to the top level, where its value can be
passed to the continuation through rules \ruleid{return-rvalue}
(page~\pageref{rule:return-rvalue}) or \ruleid{return-lvalue}
(page~\pageref{rule:return-lvalue}). 

\index{ST@\texttt{ST}} \index{EX@\texttt{EX}} Such a return can not
happen prematurely: the two \texttt{return} rules both have
\texttt{EX} tags in their ``result'' arguments, and the rule
\ruleid{block-stmt-evaluate}, as well as all the other rules calling
for statement evaluation recursively, requires its recursive call to
be an \texttt{ST}-to-\texttt{ST} evaluation.

\subsubsection{Simple Declarations}
\label{sec:simple-declarations}

This section discusses simple declaration forms, which are treated in
a way that is similar to the treatment in my thesis.  Declarations
involving class types are typically not simple, and are discussed in
Sections~\ref{sec:basic-oo} (basic object orientiation)
and~\ref{sec:object-lifetimes} (object lifetimes). There are two
simple forms of declaration: a bare declaration of a variable, such as
\begin{verbatim}
   int x;
\end{verbatim}
or a declaration coupled with an initialisation
\begin{verbatim}
   int x = 3;
\end{verbatim}
\index{VDec@\texttt{VDec}} \index{VDecInit@\texttt{VDecInit}} These
two different forms are represented with the constructors
\texttt{VDec} and \texttt{VDecInit} respectively, both constructing
values in the \texttt{var_decl} type.

\index{declmng relation@\texttt{declmng} relation}%
As already mentioned, the \cpp{} mechanisation uses an auxiliary
relation \texttt{declmng} to do most variable declaration work.  This
relation is defined in \HOLfile{declaration_dynamics}.  Its simplest
rule is 
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-vdec-nonclass@\texttt{decl-vdec-nonclass}}%
\begin{alltt}
(* RULE-ID: decl-vdec-nonclass *)
     vdeclare s0 ty name s \(\land\)
     object_type ty \(\land\)
     \(\neg\)class_type (strip_array ty)
   \(\Rightarrow\)
     declmng mng (VDec ty name, s0) ([], s)
\end{alltt}
  \end{minipage}
\end{center}
\index{vdeclare@\texttt{vdeclare}}
This rule states that if one is declaring a variable of non-class type
(and which is not an array of a class type), then it suffices to
allocate space for it through the \texttt{vdeclare} relation, storing
its address in the appropriate part of the state's environment, and
also recording the type.  The empty list in the second argument to
\texttt{declmng} signals that no further work needs to be done for
this declaration.

When a variable is to be initialised, this can occur as a direct
initialisation:
\begin{verbatim}
   int x(3);
\end{verbatim}
or as a copy-initialiation:
\begin{verbatim}
   inx x = 3;
\end{verbatim}
\index{DirectInit0@\texttt{DirectInit0}}%
For non-classes this syntactic difference makes no difference in
behaviour.  The first rule is for the direct initialisation
(\texttt{DirectInit0} form), where the transition is immediately to a
copy-initialisation:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-init-start-eval-dnonclass@\texttt{decl-init-start-eval-dnonclass}}
\begin{alltt}
(* RULE-ID: decl-vdecinit-start-evaluate-direct-nonclass *)
     ~class_type ty \(\land\)
     vdeclare s0 ty name s \(\land\)
     (SOME (a,pth) = lookup_addr s name) \(\land\)
     (loc = if ref_type ty then RefPlace NONE name 
            else ObjPlace a)
   \(\Rightarrow\)
     declmng mng
             (VDecInit ty name (DirectInit0 [arg]), s0)
             ([VDecInitA ty loc (CopyInit (EX arg base_se))], s)
\end{alltt}
\end{minipage}
\end{center}
\index{VDecInitA@\texttt{VDecInitA}}%
\index{vdeclare@\texttt{vdeclare}}%
The transition is to the \texttt{VDecInitA} form, which records where
the initialisation is to be performed.  The \texttt{vdeclare} relation
is used, as before, to allocate space for the new object, and
subsequent steps in the evaluation of the declaration will fill this
space in.  (In the case of a reference, \texttt{vdeclare} will not
allocate any space, but will record a type for the new name.)

\index{CopyInit@\texttt{CopyInit}}%
The rule for the \texttt{CopyInit} form is similar: there is a
transition to the \texttt{VDecInitA} form and a call to
\texttt{vdeclare}. (As it happens this rule can be applied for the
declaration and initialisation of class objects too.)
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-init-start-eval-copy@\texttt{decl-init-start-eval-copy}}%
\begin{alltt}
(* RULE-ID: decl-init-start-eval-copy *)
     vdeclare s0 ty name s \(\land\)
     (SOME (a,pth) = lookup_addr s name) \(\land\)
     (loc = if ref_type ty then RefPlace NONE name 
            else ObjPlace a)
   \(\Rightarrow\)
     declmng mng
             (VDecInit ty name (CopyInit arg), s0)
             ([VDecInitA ty loc (CopyInit arg)], s)
\end{alltt}
\end{minipage}
\end{center}

Once a \texttt{VDecInitA} form has been achieved, the initialising
expression can be evaluated.
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-vdecinit-evaluation@\texttt{decl-vdecinit-evaluation}}%
\begin{alltt}
(* RULE-ID: decl-vdecinit-evaluation *)
     mng (s0, exte) (s, exte') \(\land\)
     ((f = CopyInit) \(\lor\) (f = DirectInit))
   \(\Rightarrow\)
     declmng mng (VDecInitA ty loc (f exte), s0)
                 ([VDecInitA ty loc (f exte')], s)
\end{alltt}
\end{minipage}
\end{center}
Note that the initialisor form \texttt{f} can only be a
\texttt{DirectInit} when initialising classes.  All non-class objects
will be a \texttt{CopyInit} form by this point. 

When initialising a non-reference, expressions that yield l-values
must be allowed to undergo the ``l-value to r-value'' conversion:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-vdecinit-lval2rval@\texttt{decl-vdecinit-lval2rval}}%
\begin{alltt}
(* RULE-ID: decl-vdecinit-lval2rval *)
     lval2rval (s0,e0,se0) (s,e,se) \(\land\)
     \(\neg\)ref_type ty \(\land\)
     ((f = CopyInit) \(\lor\) (f = DirectInit))
   \(\Rightarrow\)
     declmng mng (VDecInitA ty loc (f (EX e0 se0)), s0)
                 ([VDecInitA ty loc (f (EX e se))], s)
\end{alltt}
\end{minipage}
\end{center}

\paragraph{Finishing an Initialisation}
When a non-class, non-reference initialisation is ready, the rule
\ruleid{decl-vdecinit-finish} of Figure~\ref{fig:decl-vdecinit-finish}
will apply.  The value of the initialising expression is first
converted to be of the appropriate type, and the resulting value
(\texttt{v'}, a list of bytes), is copied into memory using the
\texttt{val2mem}\index{val2mem@\texttt{val2mem}} relation.  Note that
the state's \texttt{initmap} is also initialised in the
process.  The fact that the location attached to the
\texttt{VDecInitA} constructor is an \texttt{ObjPlace} ensures that
the variable being initialised is not a reference.%
\index{initmap (state field)@\texttt{initmap} (\texttt{state} field)}%
\begin{figure}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-vdecinit-finish@\texttt{decl-vdecinit-finish}}%
\index{nonclass_conversion@\texttt{nonclass_conversion}}%
\begin{alltt}
(* RULE-ID: decl-vdecinit-finish *)
     nonclass_conversion s0 (v,ty) (v',dty) \(\land\)
     is_null_se se \(\land\)
     ~class_type dty \(\land\)
     (s = val2mem (s0 with initmap updated_by (UNION) rs) a v') \(\land\)
     (rs = range_set a (LENGTH v')) \(\land\)
     ((f = CopyInit) \(\lor\) (f = DirectInit))
   \(\Rightarrow\)
     declmng mng (VDecInitA dty
                            (ObjPlace a)
                            (f (EX (ECompVal v ty) se)), s0)
                 ([], s)
\end{alltt}
\end{minipage}
\caption{Finishing the Initialisation of a Non-class, Non-reference
  Variable}
\label{fig:decl-vdecinit-finish}
\end{figure}

\subsection{Exceptions}
\label{sec:exceptions}
\newcommand{\ethrow}{\texttt{EThrow}}

Exceptions are modelled in a way similar to the treatment of
\texttt{return}, \texttt{break} and \texttt{continue}.  One difference
is that exceptions propagate further: the \texttt{return} ``value''
only propagates up as far as a function call (within an expression).
In contrast, an exception will continue to propagate up through the
call-stack until it hits a suitable handler.

\index{EThrow@\texttt{EThrow}} \index{Throw@\texttt{Throw}} This much
allows a preliminary sketch of the behaviour.  The \texttt{throw} form
is actually an expression (\texttt{EThrow}), but we set things up so
that there is a statement-level version of \texttt{throw} as well
(\texttt{Throw}), and it will be this that propagates through
statement syntax.  The rule \ruleid{expression-throw-some} describes
the behaviour when \texttt{EThrow} has an argument:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!expression-throw-some@\texttt{expression-throw-some}}%
\begin{alltt}
(* RULE-ID: expression-throw-some *)
     T
   \(\Rightarrow\)
     mng (s, EX (EThrow (SOME e)) se)
         (s, ST (Throw (SOME (EX e se))) c)
\end{alltt}
\end{minipage}
\end{center}
The variable \texttt{c} represents the continuation that would
normally convert the result of the statement into a value to be
inserted into a containing expression tree.  Because thrown
values can't ever turn into values until they initialise a handler,
this $c$ can be anything at all.

At the statement level, the \texttt{Throw} form takes an extended
expression as an argument.  This evaluates its argument as one might
expect (rule \ruleid{throw-expr-evaluation})
\begin{center}
\begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: throw-expr-evaluation *)
     mng (s0, RVR e0) (s, RVR e)
   \(\Rightarrow\)
     mng (s0, ST (Throw (SOME e0)) c) (s, ST (Throw (SOME e)) c)
\end{alltt}
\end{minipage}
\end{center}

When a \texttt{throw}'s expression has been completely evaluated, we
have something that can then propagate upwards through the abstract
syntax of statements.  Because of the way the rules for loops and
\texttt{if}-statements work, their sub-statements are never executed
while still sub-statements.

We already have a rule specifying how \texttt{throw}-statements traverse
\texttt{Block} values: \ruleid{block-interrupted}, repeated here: 
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-interrupted@\texttt{block-interrupted}}
\begin{alltt}
(* RULE-ID: block-interrupted *)
     final_stmt exstmt c \(\land\)
     \(\neg\)(exstmt = EmptyStmt) \(\land\)
     \(\neg\)(sts = [])
   \(\Rightarrow\)
     mng (s, ST (Block T [] (exstmt::sts)) c)
         (s, ST (Block T [] [exstmt]) c)
\end{alltt}
\end{minipage}
\end{center}
The predicate \texttt{final_stmt} is true of \texttt{throw} and
\texttt{return} statements with fully evaluated arguments, as well as
of \texttt{break}, \texttt{continue} and the \textsf{EmptyStmt} form.
The latter doesn't cause an interruption, so is excluded by the second
hypothesis to the rule.  The final hypothesis ensures that there isn't
an infinite loop on this rule.  The same predicate is used in the rule
for exiting a block (\ruleid{block-exit}, page~\pageref{fig:block-exit}).

There is also rule \ruleid{trap-exn-passes} for exception statements
escaping the \texttt{Trap} form (which is used for handling
\texttt{continue} and \texttt{break}):
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!trap-exn-passes@\texttt{trap-exn-passes}}%
\begin{alltt}
(* RULE-ID: trap-exn-passes *)
     exception_stmt exn
   \(\Rightarrow\)
     mng (s, ST (Trap tt exn) c) (s, ST exn c)
\end{alltt}
\end{minipage}
\end{center}

\medskip
Because exceptions arise from expressions, the statement level rules
need to acknowledge this possibility.  Thus, this rule for
\texttt{if} (\ruleid{if-exception}):
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!if-exception@\texttt{if-exception}}%
\index{CIf@\texttt{CIf}}%
\begin{alltt}
(* RULE-ID: if-exception *)
     is_exnval guard
   \(\Rightarrow\)
     mng (s, ST (CIf guard thenstmt elsestmt) c)
         (s, mk_exn guard c)
\end{alltt}
\end{minipage}
\end{center}
where the definition of \texttt{is_exnval} is (from
\HOLfile{statements})\index{is_exnval@\texttt{is_exnval}}
\begin{alltt}
   (is_exnval (ST (Throw (SOME e)) c) = final_value e) \(\land\)
   (is_exnval _ = F)
\end{alltt}
The function \texttt{mk_exn} takes an exception value and
replaces its continuation information with something appropriate for
the level of the containing statement: \index{mk_exn@\texttt{mk_exn}}
\begin{verbatim}
   mk_exn (ST (Throw (SOME e)) c0) c = ST (Throw (SOME e)) c
\end{verbatim}

Of course, exceptions can arise in all the other expressions that
appear within statement forms, so there are similar rules for the
standalone expression and \texttt{return} forms, as well as for the
statement-level \texttt{throw} form itself.  (The rule
\ruleid{expression-throw-some} turns an \texttt{EThrow} into a
\texttt{Throw} statement immediately, without evaluating the argument.
When the argument \emph{is} evaluated, it may itself cause an
exception.)

Because exceptions can arise in variable declarations, there is also a
rule for handling these.  This is \ruleid{block-declmng-exception}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!block-declmng-exception@\texttt{block-declmng-exception}}%
\begin{alltt}
(* RULE-ID: block-declmng-exception *)
     ((f = CopyInit) \(\lor\) (f = DirectInit)) \(\land\)
     declmng mng (d0, s0) ([VDecInitA ty loc (f e)], s) \(\land\)
     is_exnval e \(\land\)
     (e = ST (Throw (SOME ex)) c')
   \(\Rightarrow\)
     mng (s0, ST (Block T (d0 :: vds) sts) c)
         (s, ST (Block T [] [Throw (SOME ex)]) c)
\end{alltt}
\end{minipage}
\end{center}
Again, note how the continuation initially associated with the
exception (\texttt{c'}) is ignored.


\subsubsection{Handling Exceptions}

Handling exceptions is done with the \texttt{try-catch} form, which is a
sequence of handlers associated with a statement that might raise an
exception.  In the concrete syntax, programmers write something like
\newcommand{\suplus}{\ensuremath{^+}}
\newcommand{\sustar}{\ensuremath{^*}}
\begin{alltt}
   try \{
     \emph{statement}\sustar
   \}
   \emph{handler}\suplus
\end{alltt}
where a \emph{handler} is of the form
\begin{alltt}
   catch (\emph{guard}) \{ \emph{statement}\sustar \}
\end{alltt}
and a \emph{guard} can be ``\texttt{...}'' (\ie, three full-stops), a
type, or a standard parameter declaration (associating a type with a
name).

At the abstract syntax level, this is captured by the following HOL
declarations (in \texttt{statementsScript}):
\begin{alltt}
   exn_pdecl = (string option # CPP_Type) option

   stmt = ...
        | Catch of CStmt => (exn_pdecl # CStmt) list
\end{alltt}

\bigskip
\noindent
Statements can evaluate as usual under a \texttt{Catch}
\ruleid{catch-stmt-evaluation}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!catch-stmt-evaluation@\texttt{catch-stmt-evaluation}}%
\index{Catch@\texttt{Catch}}%
\begin{alltt}
(* RULE-ID: catch-stmt-evaluation *)
     mng (s0, ST st c) (s, ST st' c)
   ==>
     mng (s0, ST (Catch st hnds) c) (s, ST (Catch st' hnds) c)
\end{alltt}
\end{minipage}
\end{center}
Non-exception statements pass through \texttt{Catch} statements,
ignoring the handlers \ruleid{catch-normal-stmt-passes}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!catch-normal-stmt-passes@\texttt{catch-normal-stmt-passes}}%
\begin{alltt}
(* RULE-ID: catch-normal-stmt-passes *)
     final_stmt st c \(\land\)
     \(\neg\)exception_stmt st
   \(\Rightarrow\)
     mng (s0, ST (Catch st hnds) c) (s0, ST st c)
\end{alltt}
\end{minipage}
\end{center}

There are three rules governing how handlers interact with thrown
exceptions.  The first describes the behaviour when the handler
parameter is given as ``\texttt{...}'' \ruleid{catch-all}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!catch-all@\texttt{catch-all}}%
\begin{alltt}
(* RULE-ID: catch-all *)
     (exn = SOME (EX e base_se))
   \(\Rightarrow\)
     mng (s0, ST (Catch (Throw exn) ((NONE, hnd_body) :: rest)) c)
         (s0 with current_exns updated_by (CONS e),
          ST (Block F [] [hnd_body; ClearExn]) c)
\end{alltt}
\end{minipage}
\end{center}
\index{current_exns (state field)@\texttt{current_exns} (\texttt{state} field)}%
\index{ClearExn@\texttt{ClearExn}}%
This rule introduces two new features, the \textsf{current\_exns}
field of the program state, and the \textsf{ClearExn} statement-form.
Both are present to support the ability of programs to use
\texttt{throw} without an argument to re-throw the ``current
exception''.  This is covered below in Section~\ref{sec:throw-none}.

Otherwise, the behaviour is clear: if the top handler has
``\texttt{...}'' as its parameter, then this handler is entered (and
the other handlers are discarded).

When the top handler has an explicitly-typed parameter, the handler is
only entered if the type of the thrown value matches: 
\ruleid{catch-specific-type-matches} in
Figure~\ref{fig:catch-specific-type-matches}. 
\begin{figure}[htbp]
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!catch-specific-type-matches@\texttt{catch-specific-type-matches}}%
\begin{alltt}
(* RULE-ID: catch-specific-type-matches *)
     (exn = SOME (EX e base_se)) \(\land\)
     exception_parameter_match s0 pty (value_type e) \(\land\)
     (pname = case pnameopt of SOME s -> Base s
                            || NONE -> (Base " no name "))
   \(\Rightarrow\)
     mng (s0, ST (Catch 
                   (Throw exn)
                   ((SOME(pnameopt, pty), hnd_body) :: rest)) 
                 c)
         (s0 with current_exns updated_by (CONS e),
          ST (Block F [VDecInit pty pname
                                    (CopyInit (EX e base_se))]
                      [hnd_body; ClearExn]) c)
\end{alltt}
\end{minipage}
\end{center}
\caption{Catching a Typed Exception}
\label{fig:catch-specific-type-matches}
\end{figure}

The string \texttt{" no name "} is chosen arbitrarily as the name of
the invisible temporary if the handler has just a type as its
parameter and no associated name.  This name is chosen so as to not
mask any existing names in scope (no legal \cpp{} program can have
variable names that include spaces).

If the declared type \texttt{pty} matches the type of the exception
value, then the exception value copy-initialises the parameter, and
the handler body is executed.  The constant
\texttt{exception_parameter_match} checks the match, embodying the
rules in~\cite[\S15.3, paragraph 3]{cpp-standard-iso14882}.  If there
is no match, then the remaining handlers have to be tried
\ruleid{catch-specific-type-nomatch}:
\begin{center}
  \begin{minipage}{\textwidth}
\index{rule (dynamic)!catch-specific-type-nomatch@\texttt{catch-specific-type-nomatch}}%
\begin{alltt}
(* RULE-ID: catch-specific-type-nomatch *)
     (exn = SOME (EX e base_se)) \(\land\)
     \(\neg\)exception_parameter_match s0 pty (value_type e)
   \(\Rightarrow\)
     mng (s0, ST (Catch 
                    (Throw exn)
                    ((SOME(pnameopt, pty), hnd_body) :: rest)) 
                 c)
         (s0, ST (Catch (Throw exn) rest) c)
\end{alltt}
  \end{minipage}
\end{center}
If no handlers, remain, the exception propagates further
\ruleid{catch-stmt-empty-hnds} (generalised to allow any statements to
pass through):
\begin{center}
  \begin{minipage}{\textwidth}
\index{rule (dynamic)!catch-stmt-empty-hnds@\texttt{catch-stmt-empty-hnds}}%
\begin{alltt}
(* RULE-ID: catch-stmt-empty-hnds *)
     T
   \(\Rightarrow\)
     mng (s0, ST (Catch st []) c) (s0, ST st c)
\end{alltt}
  \end{minipage}
\end{center}

\subsubsection{Using \texttt{throw} with No Argument}
\label{sec:throw-none}

If flow of control is within an exception handler, or within a
function body that has been called from such, then it is permissible
to use the expression \texttt{throw} without any arguments to cause
the current exception to be rethrown.  This requires the model to
track what the current handled exception is.  More, the standard
requires the state to track the notion of ``most recently caught''
exception~\cite[\S15.1, paragraph 7]{cpp-standard-iso14882}), which
requires the state to track a stack of exceptions that have been
caught.

The expression version \ethrow{} is converted to the statement form as
soon as it is encountered \ruleid{expression-throw-none}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!expression-throw-none@\texttt{expression-throw-none}}%
\begin{alltt}
(* RULE-ID: expression-throw-none *)
     T
   \(\Rightarrow\)
     mng (s, EX (EThrow NONE) se) (s, ST (Throw NONE) c)
\end{alltt}
\end{minipage}
\end{center}
(The choice of $c$ is again irrelevant.)

There are then two rules for the statement form \texttt{Throw~NONE}.
If there is a current exception, all is well
\ruleid{bare-throw-succeeds}:
\begin{center}
  \begin{minipage}{\textwidth}
\index{rule (dynamic)!bare-throw-succeeds@\texttt{bare-throw-succeeds}}%
\index{current_exns (state field)@\texttt{current_exns} (\texttt{state} field)}%
\begin{alltt}
(* RULE-ID: bare-throw-succeeds *)
     (s0.current_exns = e::es)
   \(\Rightarrow\)
     mng (s0, ST (Throw NONE) c)
         (s0 with current_exns := es,
          ST (Throw (SOME (EX e base_se))) c)
\end{alltt}
\end{minipage}
\end{center}
Otherwise, the program must call the \texttt{::std::terminate} function
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!bare-throw-fails@\texttt{bare-throw-fails}}%
\begin{alltt}
(* RULE-ID: bare-throw-fails *)
     (s0.current_exns = [])
   \(\Rightarrow\)
     mng (s0, ST (Throw NONE) ct)
         (s0, ST (Standalone (EX callterminate base_se)) ct)
\end{alltt}
\end{minipage}
\end{center}
where the special expression \texttt{callterminate} is defined to be 
\begin{verbatim}
   FnApp (Var (IDConstant T [IDName "std"] 
                          (IDName "terminate"))) 
         []
\end{verbatim}

\index{ClearExn@\texttt{ClearExn}}%
Above, the rules for handlers also use a statement-form
\texttt{ClearExn}.  This special value has the following rule
\ruleid{clear-exn}:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!clear-exn@\texttt{clear-exn}}
\begin{alltt}
(* RULE-ID: clear-exn *)
     (s0.current_exns = e::es)
   \(\Rightarrow\)
     mng (s0, ST ClearExn c)
         (s0 with current_exns := es, ST EmptyStmt c)
\end{alltt}
\end{minipage}
\end{center}
This ensures that when a handler finishes the most recently caught
exception is no longer recorded as such.  If a handler rethrows the
current exception, or throws a fresh exception of its own, and this
exception escapes the handler, then the flow of control will never
reach the \textsf{ClearExn}, and this rule will not fire.

\subsubsection{Exception Specifications}

The standard's \S15.4 specifies a method whereby functions can specify
which exception types they will produce.  If an unexpected exception
value occurs, this results in a call to \texttt{std::unexpected}.
This is not modelled in the dynamic semantics as it can be emulated
with a compile-time rewriting of the program.  If a function
\texttt{f} is specified to only raise exceptions X and Y, then it can
be rewritten to be
\begin{center}
\begin{minipage}{\textwidth}
\begin{verbatim}
   f(args)
   {
     try {
       body
     }
     catch (X) { throw; }
     catch (Y) { throw; }
     catch (...) { std::unexpected(); }
   }
\end{verbatim}
\end{minipage}
\end{center}

\subsubsection{Exceptions and Object Lifetimes}

Exceptions complicate the story about the construction and destruction
of objects.  When a constructor runs it will typically cause a
sequence of sub-objects to also be constructed. If at any stage, an
exception is raised during this process, then those objects that have
been constructed need to have their destructors called, but naturally,
those that haven't yet been constructed shouldn't have destructors
called.

Consider for example
\begin{alltt}
  Class::Class(objty p1) : b1(3), b2(\(e\)) \{ \(\mathit{body}\) \}
\end{alltt}
There are three objects that have their constructors called as a
result of a call to this constructor.  One is the parameter
\texttt{p1}, and the other are the base classes (or data-members)
\texttt{b1} and \texttt{b2}.  When this constructor is called,
\texttt{p1} is always eventually destroyed, but (sub-)objects
\texttt{b1} and \texttt{b2} should live on, unless $\mathit{body}$ or
$e$ cause an exception to be raised.

To get this situation to work in the model, the state's
\texttt{blockclasses} field has to record two sorts of object
construction (which are to be unwound later), sub-object creation and
normal object creation.  When a block exits normally, sub-object
destructors are not called, but instead delayed so that they can be
recorded as having the same lifetime as the enclosing object.  For
more on this, see Section~\ref{sec:object-lifetimes}.

\subsection{Basic Object-Orientation}
\label{sec:basic-oo}

The inspiration for this part of the semantics is the article by
Wasserrab~\emph{et al}~\cite{wasserrab-nst-OOPSLA06}, which provides a
detailed model for multiple inheritance in a simple \cpp-like
language.

\subsubsection{Class Declarations}
\label{sec:class-declaration}
A class declaration is similar to the original C model's declaration
of a \texttt{struct} type.  A class declaration takes two parameters,
the name of the class, and an optional ``class-info''
argument.\footnote{The information argument is optional to allow the
  situation where a forward declaration of a class occurs.}  The
class-info, if present, is a list of fields, coupled with a list of
ancestors.  The latter allows inheritance from zero or many ancestors.
Each ancestor is coupled with a boolean flag indicating whether or not
it is a \texttt{virtual} ancestor.  As the model ignores protection
issues, there is no scope for indicating protection status for
ancestors.

The fields are of two sorts, declarations of members (whether of
``data'' fields or member functions), and nested classes.  Member
declarations are accompanied by a flag indicating whether or not they
are static, and a protection indicator (i.e., \texttt{public},
\texttt{protected}, or \texttt{private}).  Again, protection
information is entirely ignored: any field access is assumed to have
been OK-ed earlier by the compiler.

Member function definitions give the function's name, return-type,
parameter list (types and names), function body, and a flag indicating
whether or not it is virtual.  (Of course, even in the absence of an
explicit declaration that a member function is virtual, it may be so
because of an ancestor's prior declaration.)

When a class declaration is encountered , its member functions are
entered into the state's function map.  The same function map is used
for normal (non-class) functions, but the structured nature of \cpp{}
identifiers allows the model to distinguish both sorts of function.

\subsubsection{Class Values and Member Functions}
\label{sec:class-values}
Classes can not be converted into r-values like other values.  This is
because of the problems that arise with multiple inheritance.  In
particular, with multiple inheritance in place, it is no longer true
that one can extract the byte sequence for a given l-value by starting
at the base address and taking as many bytes from memory as the size
of the type.  In particular, virtual base classes may be at completely
different places in memory, not necessarily even contiguous with the
rest of the object.  (This is demonstrated for the \texttt{g++}
compiler by the little program in
\texttt{notes/mult-inheritance-layout.cpp}.)

Absence of support for r-values means that, in this model, one can not
assign classes, pass them as parameters, or return them from
functions.  However, because references are supported (see
Section~\ref{sec:reftypes}) much idiomatic \cpp{} is still covered by
the model.

\index{LVal@\texttt{LVal}!and dynamic types}
%
The presence of classes means that the model's presentation of
l-values changes from the way it was in the original C model.  In
particular, an l-value that is statically typed as a base class needs
to know dynamically that it is really of a derived type.  This
information is traditionally recorded in \texttt{vtable} fields.
Following Wasserrab~\emph{et al}, my model instead records an
additional path accompanying every l-value.  This path is a list of
strings, listing the path through the ancestry-tree that leads from
the most-derived class to the static class type.  Moreover, the type
that accompanies every l-value (recall that the \texttt{LVal}
constructor takes three arguments, an address, a type and a list of
identifiers), will have as the type, the \emph{dynamic} type
of the l-value.

\index{member functions!virtual}
Consider, for example, the code in Figure~\ref{fig:oo-example}.  The
body of function \texttt{g} constructs the l-value \texttt{*b} when it
calls \texttt{f}.  As in the C model, this l-value will be associated
with some address, and the static type, which is \texttt{Class~B}.
The actual l-value will be of the form
\begin{alltt}
   LVal a (Class D2) [D2,D1,B]
\end{alltt}
The last element of the paths in l-values is always the static class
of the value.

In Figure~\ref{fig:oo-example}, the expression of interest is
\texttt{b->f()}, which is syntactic sugar for \texttt{((*b).f)()}.
(Note how the member selection is syntactically subordinate to the
function application.)  The \ruleid{virtual-fn-member-select}
rule (see Figure~\ref{fig:virtual-fn-member-select}) governs the
evaluation of \texttt{(*b).f} once the left-hand-side (\texttt{*b})
has evaluated to an l-value.\footnote{Even when the model allows for
  class r-values, they will be given a memory location (and thus, a
  life-time).  This will enable them to also be l-values.  In essence,
  it is not possible to create an object of any sort without giving it
  a location.  Contrast numbers, which can be ``created'', and not
  given a memory location, simply by writing them down.}

\begin{figure}[hbtp]
\begin{verbatim}
   class B {
     public: virtual int f() { return 3; }
   };

   class D1 : public B {
     public: int f() { return 4; }
   };

   class D2 : public D1 { };

   int g(class B *b) { return b->f(); }

   int main()
   {
     D2 d;
     return g(&d);
   }
\end{verbatim}
\caption{C++ code demonstrating OO-polymorphism.  The program will
  return 4. Though it appears as if \texttt{B}'s function \texttt{f}
  is called, the version of \texttt{f} called will actually be that
  attached to \texttt{D1}.}
\label{fig:oo-example}
\end{figure}

\begin{figure}[hbtp]
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!virtual-fn-member-select@\texttt{virtual-fn-member-select}}%
\begin{alltt}
(* RULE-ID: virtual-fn-member-select *)
     (s,\lbr\rbr) |- LAST Cs has least method
                 (IDName fld) -:
                 (static_retty,F,args0,body0) via
                 Ds \(\land\)
     (s,\lbr\rbr) |- (C,Cs ^ Ds) selects
                 (IDName fld) -:
                 (dyn_retty,F,args,body) via
                 Cs'
   \(\Rightarrow\)
     mng (s, EX (SVar (LVal a (Class C) Cs)
                      (IDConstant F [] (IDName fld))) se)
         (s, EX (FVal (mk_member (LAST Cs') (IDName fld))
                      (Function dyn_retty (MAP SND args))
                      (SOME (LVal a (Class C) Cs'))) se)

\end{alltt}
\end{minipage}
\end{center}
\caption{The rule for virtual member function dispatch}
\label{fig:virtual-fn-member-select}
\end{figure}

\index{vtables}
In our model, the l-value's address will be the same as the address of
its most-derived class.  In other words, the \texttt{a} of the rule
will be the same as the address of the object \texttt{d}.  This is not
what happens in typical compilers, which will actually make the
pointer to the \texttt{B} sub-class point at the address of that
sub-object's fields in the wider object's memory layout.  Then, the
fact that the most-derived class is a \texttt{D2} is implicitly
recorded in the \texttt{vtable}, which will contain a pointer to
\texttt{D1::f}.

In the rule, the variable \texttt{C} containing the name of the static
class will be \texttt{D2}, and \texttt{Cs}, the path variable, will be
\texttt{[D2,D1,B]}.  The \texttt{fld} variable will be \texttt{f}.
Then, the first hypothesis will check the class hierarchy to determine
where an \texttt{f} can be found, starting at the static type, i.e.,
at \texttt{B}.  This will reveal that, with respect to \texttt{B}
there is an \texttt{f} at path \texttt{[B]}.  This will be the value
for \texttt{Ds}.  The same check determines four pieces of information
about the function: its static return type (in the variable
\texttt{static_retty}, that it is not static (virtual functions can
not be static), and what its arguments and body are (\texttt{args0},
and \texttt{Body0}).

The second hypothesis calculates which function must be called given
the class's dynamic type.  This is complicated because of the need to
handle multiple inheritance (the definition of
``\texttt{selects-via}'' is discussed below in
Section~\ref{sec:multiple-inheritance}), but in this case, the path
\texttt{Cs'} will be found to be \texttt{[D2,D1]}, and the information
\texttt{(dyn_retty,F,args,body)} found will be that for the function
\texttt{D1::f}.

\index{mk_member@\texttt{mk_member}}
The result of the rule in this circumstance is that the expression
\texttt{b->f} turns into a reference to the function \texttt{D1::f}
(this is the call to \texttt{mk_member}), coupled with with the fact
that the function call is being made on an object whose dynamic type
is \texttt{D2}, and whose static type is \texttt{D1} (as is
appropriate for the body of the function).

Note that the function in this rule is known to be virtual by virtue
of the fact that the fieldname is unqualified: it is of the form
\[
\texttt{IDConstant~F~[]~(IDName~fld)}
\]
Name resolution will ensure that non-virtual members all have
qualified fields.

\paragraph{Other Sorts of Member Function}

There are two other sorts of member functions in \cpp{}: static
members functions, and normal functions.  Each sort has its own rule
in the semantics.
\index{member functions!static}
First, the rule for static member functions:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!static-fn-member-select@\texttt{static-fn-member-select}}%
\begin{alltt}
(* RULE-ID: static-fn-member-select *)
     (s,\lbr\rbr) |- path (LAST Cs) to class_part fldid via Ds \(\land\)
     (s,\lbr\rbr) |- LAST Ds has least method
                  (IDtl fldid) -: (retty,T,ps,body)
                  via [LAST Ds] \(\land\)
     (ftype = Function retty (MAP SND ps)) \(\land\)
     is_qualified fldid
   \(\Rightarrow\)
     mng (s, EX (SVar (LVal a (Class cnm) Cs) fldid) se)
         (s, EX (FVal fldid ftype NONE) se)
\end{alltt}
\end{minipage}
\end{center}
\index{is_qualified@\texttt{is_qualified}}%
The third hypothesis (\texttt{is_qualified}) checks that the field
name has multiple components to it.  This qualification will be
introduced by name resolution if not already provided by the user.
Name resolution will also ensure that the name given to the field is
qualified with the name of the class where the field actually
resides.

\index{class_part@\texttt{class_part}}%
Strictly, in this rule, the first hypothesis is redundant because of
this pre-processing: we know that the field will occur in the class
that is at the end of the path \texttt{Ds}, and that this final
element will be equal to the class-part of the identifier.  The second
hypothesis reinforces this: the deduced path from \texttt{LAST~Ds}
(which equals \texttt{class_part~fldid}) to the host class for the
given field is the singleton \texttt{[LAST~Ds]}.  Because the member
is static (witness the \texttt{T} as argument 2 of the 4-tuple
returned by \texttt{least-method}), the final function value does not
include a class component.

\index{member functions!non-static}
The rule for normal, non-static  member functions is given in
Figure~\ref{fig:nstatic-fn-member-select}. 
\begin{figure}
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!nstatic-fn-member-select@\texttt{nstatic-fn-member-select}}%
\begin{alltt}
(* RULE-ID: nstatic-fn-member-select *)
     (s,\lbr\rbr) |- path (LAST Cs) to class_part fldid via Ds \(\land\)
     (s,\lbr\rbr) |- LAST Ds has least method
                  (IDtl fldid) -: (retty,F,ps,body)
                  via [LAST Ds] \(\land\)
     (ftype = Function retty (MAP SND ps)) \(\land\)
     is_qualified fldid
   \(\Rightarrow\)
     mng (s, EX (SVar (LVal a (Class cnm) Cs) fldid) se)
         (s, EX (FVal fldid ftype
                      (SOME (LVal a (Class cnm) (Cs ^ Ds))))
                se)
\end{alltt}
\end{minipage}
\end{center}
\caption{Selecting a Non-static Member Function}
\label{fig:nstatic-fn-member-select}
\end{figure}
This is very similar to the rule for static functions, but this time
the identity of the class for which the function is being called is
important, and recorded in the third argument to \texttt{FVal}.  The
dynamic type of the object stays the same, but the static type is
adjusted to reflect the class where the function being called is
defined.

\paragraph{Field Selection}
Field selection is also based on the notion of being able to find the
most-derived declaration of the given field in the ancestor hierarchy.
There is no need to worry about adjusting \texttt{this} pointers, or
performing analyses with dynamic types as field selections are always
done with respect to a class's static type.  However, there is an
additional complexity, stemming from the need to give addresses to
selected fields, so that they can become well-formed l-values.  In
turn, this relies on knowing how a class is laid out in memory.

The standard \emph{does} require that fields belonging to a particular
class type be laid out in the order in which they appear\footnote{The
  order is actually required to hold as long as they have the members
  have the same access-specifiers, but the model doesn't handle
  accessibility.}  But there is no specification of how base
sub-objects are laid out.  (Recall, moreover, that in the presence of
a virtual base-class, an object that is not most-derived may be split
over distinct parts of memory.)

The rule for finding the offset of a non-static data member is given
in Figure~\ref{fig:nstatic-data-field-select}.
\begin{figure}
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!nstatic-data-field-select@\texttt{nstatic-data-field-select}}%
\begin{alltt}
(* RULE-ID: nstatic-data-field-select *)
     (s,\lbr\rbr) |- path (LAST p) to cnm2 via p' \(\land\)
     (s,\lbr\rbr) |- LAST p' has least
                 (IDtl fldid) -: (ty, F)  (* F = non-static *)
                 via [LAST p'] \(\land\)
     object_type ty \(\land\)
     (mdp = (cnm1 = cnm2) \(\land\) (p = [cnm1])) \(\land\)
     is_qualified fldid \(\land\)
     (class_part fldid = cnm2) \(\land\)
     (SOME offn = lookup_offset s mdp fldid)
   \(\Rightarrow\)
     mng (s, EX (SVar (LVal a (Class cnm1) p) fldid) se)
         (s, EX (LVal
                  (a + subobj_offset s (cnm1, p ^ p') + offn)
                  ty
                  (SND (default_path ty))) se)
\end{alltt}
\end{minipage}
\end{center}
\caption{Calculating the Offset of a Non-static Data Member}
\label{fig:nstatic-data-field-select}
\end{figure}
Recall that static analysis done by Phase~1 will have turned all data
field references into fully-qualified identifiers.  That means the
dynamics already knows exactly which sub-class holds the desired
field.  In the rule, that sub-class is \texttt{cnm2}.  The first
hypothesis confirms that there is indeed a path from the static type
of the l-value to that sub-class (which might be itself, of course).
The second hypothesis then both extracts the type of the field and
confirms that it is not static.

The rule also determines whether or not the sub-class is actually the
most-derived class, and records this in the boolean variable
\texttt{mdp}.  This is done so that the underspecified calculation in
\texttt{lookup_offset} can return a different value for field offsets
depending on whether or not a class is most-derived.  (It seems very
unlikely that an implementation would do this; most would put any
virtual bases at the end of their internal layout, meaning that all
other offset calculations could proceed undisturbed.)

The variable \texttt{offn} is the offset of the field within its host
class.  The function \texttt{subobj_offset} is used to calculate the
offset of the sub-class within the larger containing (dynamic) class,
allowing a final offset to be calculated.  Finally, the second
component of \texttt{default_path~ty} function returns the singleton
list consisting of the class name if \texttt{ty} is a class type, and
the empty list otherwise.


\index{vtables}%
\paragraph{What of vtables?}
The use of paths \emph{\`a la} Wasserrab~\emph{et al.} does away with
the need for vtables.  On the other hand, we wouldn't want to specify
the model in such a way as to preclude this perfectly reasonable
implementation strategy.  In particular, vtables will be catered for
just as in the standard, by maintaining that it is only in POD
(``plain old data'') types where one can rely on the address of the
first field being the same as the address of the containing
\texttt{struct}.  The calculation of sizes must also be
under-specified to allow for the presence of extra, user-invisible
data at the start of a class.

\subsubsection{Casting and Other Type Conversions}
We have already seen one use of implicit conversion from one type of
value to another, in the rule \ruleid{assign-completes}
(p\pageref{rule:assign-completes}), where the relation
\texttt{nonclass_conversion} is used to this end.  This relation
governs the way in which various values are allowed to be silently
converted from one type to another.  Its definition is from the file
\HOLfile{declaration_dynamics}, and is repeated in
Figure~\ref{fig:nonclass-conversion}.
\begin{figure}
\index{nonclass_conversion@\texttt{nonclass_conversion}}
\begin{alltt}
  nonclass_conversion s (v1,ty1) (v2,ty2) =
    let ty1 = strip_const ty1
    and ty2 = strip_const ty2
    in
      (integral_type ty1 \(\land\) integral_type ty2 \(\lor\)
       \(\exists\)ty0. (ty1 = Ptr ty0) \(\land\) (ty2 = Ptr Void)) \(\land\)
      (\(\exists\)i. (INT_VAL ty1 v1 = SOME i) \(\land\)
           (SOME v2 = REP_INT ty2 i))
              (* includes null pointer conversion *)
         \(\lor\)
      (strip_ptr_const ty1 = strip_ptr_const ty2) \(\land\) (v1 = v2)
         \(\lor\)
      (\(\exists\)c1 c2 addr pth1 pth2.  (* this is an upcast *)
          (ty1 = Ptr (Class (LAST pth1))) \(\land\) (ty2 = Ptr (Class c2)) \(\land\)
          (SOME v1 = ptr_encode s addr (Class c1) pth1) \(\land\)
          (s,\lbr\rbr) |- c2 casts pth1 into pth2 \(\land\)
          (SOME v2 = ptr_encode s addr (Class c1) pth2))
         \(\lor\)
      (\(\exists\)ty0 base derived p fld.
          (ty1 = MPtr base ty0) \(\land\) (ty2 = MPtr derived ty0) \(\land\)
          (s,\lbr\rbr) |- path derived to base unique \(\land\)
          (derived, p) IN rsubobjs (s,\lbr\rbr) \(\land\)
             (* rsubobjs ensures base is not virtual *)
          (LAST p = base) \(\land\)
          (v2 = v1) \(\land\)
          ((SOME v1 = encode_offset base fld) \(\lor\)
           (v1 = null_member_ptr)))
         \(\lor\)
      (\(\exists\)ty0 c. (* null pointer conversion for pointers to member *)
          (ty1 = Signed Int) \(\land\) (SOME v1 = REP_INT (Signed Int) 0) \(\land\)
          (ty2 = MPtr c ty0) \(\land\) (v2 = null_member_ptr))
\end{alltt}
\caption{The \texttt{nonclass_conversion} relation for implicit type
  conversions.  Based on the standard's \S4.}
\label{fig:nonclass-conversion}
\end{figure}

\index{dynamic_cast@\texttt{dynamic_cast}}
The most important of \cpp{}'s explicit casts is the
\texttt{dynamic_cast} operation which allows for run-time checked
manoeuvering around a class hierarchy.  First up-casts to unambiguous bases
are permitted (this is the rule for references; there are parallel
rules for the dynamic casting of pointers):
\index{rule (dynamic)!dyncast-derived-base-ref@\texttt{dyncast-derived-base-ref}}%
\begin{alltt}
(* RULE-ID: dyncast-derived-base-ref *)
(* assume that base is accessible (checked by compiler) *)
     (strip_const dty = Class dcnm) \(\land\)
     (s,\lbr\rbr) |- path (LAST p) to dcnm unique \(\land\) (* static check *)
     (s,\lbr\rbr) |- path (LAST p) to dcnm via p'
   \(\Rightarrow\)
     mng (s, EX (DynCast (Ref dty) (LVal a (Class scnm) p)) se)
         (s, EX (LVal a (Class scnm) (p ^ p')) se)
\end{alltt}
The second hypothesis is strictly redundant in the dynamics; along
with the base's accessibility, this will be checked before the
dynamics gets a chance to execute.  The third hypothesis is where the
extended path from the dynamic type up to the new base is
constructed.

In the other direction (back down a class hierarchy), dynamic casts
can fail, and require the source type to be polymorphic (\ie, the
source class should have at least one virtual function).  The rule
governing this behaviour appears in
Figure~\ref{fig:dyncast-base-other-ref}. 
\begin{figure}[htbp]
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!dyncast-base-other-ref@\texttt{dyncast-base-other-ref}}%
\begin{alltt}
(* RULE-ID: dyncast-base-other-ref *)
     (strip_const dty = Class dcnm) \(\land\)
     (src_dynty = Class scnm) \(\land\)
     polymorphic s (LAST p) \(\land\)
     (s,\lbr\rbr) |- path scnm to dcnm via p' \(\land\)
     (result =
      if (s,\lbr\rbr) |- path scnm to dcnm unique then
        (* should also check accessible, though I think this
           could be done statically *)
        LVal a src_dynty p'
      else
        EThrow (SOME (New (Class bad_cast_name) NONE)))
   \(\Rightarrow\)
     mng (s, EX (DynCast (Ref dty) (LVal a src_dynty p)) se)
         (s, EX result se)
\end{alltt}
\end{minipage}
\end{center}
\caption{Performing a Polymorphic \texttt{dynamic_cast}}
\label{fig:dyncast-base-other-ref}
\end{figure}
Note how the dynamic type of the l-value does not change: it remains
as \texttt{src_dynty}.  Instead the accompanying path value adjusts:
shifting from a path that leads up as far as \texttt{LAST~p} (the
original static type), to one that leads to the class \texttt{dcnm}.
In this way, a \texttt{dynamic_cast} can move the static type from one
branch of the ancestry tree to another; in one step, one can do more
than just make a down-cast.

\index{bad_cast exception@\texttt{bad_cast} exception}
When there isn't a class of the desired type available, a reference
cast causes a \texttt{bad_cast} exception to be thrown.  The
accompanying rule for dynamic-casting of pointer values has the
pointer converted to a null pointer if the destination type is unreachable.


\subsection{Reference Types}
\label{sec:reftypes}

Reference types pose problems in the contexts where they are
distinctive:
\begin{itemize}
\item passed as parameters to functions;
\item returned from functions;
\item when they are initialised.
\end{itemize}

Otherwise, it is obvious how the existing semantics should treat
references: they are l-values.  References are only created from
l-values, and in the reverse direction, l-values can turn into
r-values as required.  They will do the right things when of
\texttt{class} types because they will have the Wasserrab style paths
attached.  In other words, a reference to a base class may actually be
an l-value referring to a derived class.

The remaining sub-sections explain what happens in the three
interesting situations.

\paragraph{Omissions}
\begin{itemize}
\item The semantics does not handle references to functions.
  Supporting these will require more rules in the dynamic semantics,
  but these rules will be directly analogous to the rules presented
  below: wherever an \clvalue{} constructor (which is for l-values of
  object type) appears, there will need to also be a rule for
  \cfvalue{}, which is for function values.
\item The semantics doesn't handle initialisation of \texttt{const}
  references from r-values.
\end{itemize}


\subsubsection{References as Parameters}

When a formal parameter is of reference type, the actual parameter
needs to stay an l-value rather than reduce to an r-value.  When the
called function's environment is being established in its local stack
frame, the binding for the formal name can be directly to the actual
l-value's address and type.  In other words, nothing is allocated in
memory to represent the reference.  This is not very likely in an
actual environment, which will probably have an address in memory
somewhere.  (The only way to detect this (and this would require the
use of undefined behaviour) would be know where local variables were
allocated, and to scan this area byte-by-byte, presumably starting at
the address of some other, non-reference, local parameter.)

This requires a change to the existing semantics, to remove function
arguments from the l-value context (as defined by
\texttt{valid_lvcontext}.\index{valid_lvcontext@\texttt{valid_lvcontext}}
In order to allow some function arguments to decay into r-values, a
new rule is introduced:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!fnapp-lval2rval@\texttt{fnapp-lval2rval}}%
\begin{alltt}
(* RULE-ID: fnapp-lval2rval *)
     lval2rval (s0,e0,se0) (s,e,se) \(\land\)
     fn_expects_rval s0
       (case s0.thisvalue of
           SOME (ECompVal bytes (Ptr ty)) -> SOME ty
        || _ -> NONE)
       f
       (LENGTH pfx)
   \(\Rightarrow\)
     mng (s0, EX (FnApp f (pfx ++ (e0 :: sfx))) se0)
         (s, EX (FnApp f (pfx ++ (e :: sfx))) se)
\end{alltt}
\end{minipage}
\end{center}
The variables \texttt{pfx} and \texttt{sfx} are lists of expressions
corresponding to the other actual parameters being passed to the
function $f$.  The predicate \texttt{fn_expects_rval} examines the
type of \texttt{f} to determine whether or not the argument at the
given position (\texttt{LENGTH~pfx} here) is required to be an l-value.

The rule that determines that a function application's sequence point
has been reached (\ruleid{function-call-sqpt}) must also change.
Previously, this rule checked that the function and all of the
arguments had been fully evaluated, and being ``fully evaluated''
meant ``had been evaluated to a value (consisting of a list of
bytes)''.  The new rule checks that every parameter is either a
byte-list value (when the function doesn't expect a reference type),
or an l-value:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!function-call-sqpt@\texttt{function-call-sqpt}}%
\begin{alltt}
(* RULE-ID: function-call-sqpt *)
     (fty = Function retty argtys) \(\land\)
     EVERYi (\(\lambda\)i e. if ref_type (EL i argtys) then
                     \(\exists\)a t p. e = LVal a t p
                   else \(\exists\)v t. e = ECompVal v t)
            params \(\land\)
     is_null_se se
   \(\Rightarrow\)
     mng (s, EX (FnApp (FVal fnid fty eopt) params) se)
         (s, EX (FnApp_sqpt (FVal fnid fty eopt) params)
                base_se)
\end{alltt}
\end{minipage}
\end{center}
The \texttt{EVERYi} function (from \HOLfile{utils}) is of type
\begin{verbatim}
   : (num -> 'a -> bool) -> 'a list -> bool
\end{verbatim}
and checks whether or not every element of a list satisfies the given
predicate, but where the predicate is also given access to the
element's index in the list.

\subsubsection{References Returned from Functions}
\label{sec:refs-returned-from-fns}

In order to return a reference from a function, the model must not
force the ``l-value to rvalue'' conversion that would normally turn
l-value expressions in \texttt{return} statements into r-values.  But
it must also allow that conversion to occur when appropriate.  This in
turn requires the model to be able to recognise when a function is due
to return a reference as opposed to a normal value.  The model
achieves this by encoding this expectation in the continuation that
accompanies every statement evaluation.

\index{return_cont@\texttt{return_cont}}%
The rules for function calls (see, for example
\ruleid{global-function-call} on
page~\pageref{rule:global-function-call}) construct the continuation
with a call to \texttt{return_cont}.  The continuation type is defined
in \HOLfile{statements}:
\begin{verbatim}
  conttype = RVC of (CExpr -> CExpr) => se_info
           | LVC of (CExpr -> CExpr) => se_info
\end{verbatim}
meaning that a continuation stores both the side effect record that is
to accompany the re-established expression, and a function which will
construct it when given the result of the function call.

The definition of \texttt{return_cont} is
\begin{verbatim}
  return_cont se ty = if ref_type ty then LVC I se
                      else RVC I se
\end{verbatim}
where \texttt{I} is the identity combinator (the function equal to
$(\lambda x.\;x)$).

In the continuations, the ``tags'', \texttt{RVC} and \texttt{LVC},
allow other rules to determine what is expected.  To return to the
example of the ``l-value to r-value'' conversion, this is done by the
following rule:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!return-lval2rval@\texttt{return-lval2rval}}%
\index{lval2rval@\texttt{lval2rval}}%
\begin{alltt}
(* RULE-ID: return-lval2rval *)
     lval2rval (s0,e,se0) (s,e,se)
   \(\Rightarrow\)
     mng (s0, ST (Ret (EX e0 se0)) (RVC c ret_se))
         (s, ST (Ret (EX e se)) (RVC c ret_se))
\end{alltt}
\end{minipage}
\end{center}
The continuation that accompanies every statement is the second
argument of the \texttt{ST} tag. Also note that the first argument of
a \ckey{return} might itself be another statement.  If the original
expression contained a function call, the body of the called function,
a statement, would eventually become the top of the expression.  In
this rule, the use of the inner \texttt{EX} tag precludes this
possibility.

There are two rules allowing a \ckey{return} statement to pass its
expression-value to the continuation.  The rule for returning normal
values is \ruleid{return-rvalue} (we saw this rule earlier, in
Section~\ref{sec:small-step-stmts}):
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!return-rvalue@\texttt{return-rvalue}}%
\begin{alltt}
(* RULE-ID: return-rvalue *)
     is_null_se se0
   \(\Rightarrow\)
     mng (s, ST (Ret (EX (ECompVal v t) se0)) (RVC c se))
         (s, EX (c (ECompVal v t)) se)

\end{alltt}
\end{minipage}
\end{center}

\smallskip\noindent
The rule for returning a reference \ruleid{return-lvalue} is similar:
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!return-lvalue@\texttt{return-lvalue}}%
\label{rule:return-lvalue}
\begin{alltt}
(* RULE-ID: return-lvalue *)
     is_null_se se0
   \(\Rightarrow\)
     mng (s, ST (Ret (EX (LVal a t p) se0)) (LVC c se))
         (s, EX (c (LVal a t p)) se)

\end{alltt}
\end{minipage}
\end{center}

\subsubsection{Declaring References}

When a reference is declared, it must also be initialised, and the
initialising expression must be an l-value.  But normal
initialisations need to be able to turn l-values into r-values so
there is an ``lvalue-to-rvalue'' rule for variable declarations that
are accompanied by initialisations (this rule earlier appeared in
Section~\ref{sec:simple-declarations}):
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-vdecinit-lval2rval@\texttt{decl-vdecinit-lval2rval}}%
\begin{alltt}
(* RULE-ID: decl-vdecinit-lval2rval *)
     lval2rval (s0,e0,se0) (s,e,se) \(\land\)
     \(\neg\)ref_type ty \(\land\)
     ((f = CopyInit) \(\lor\) (f = DirectInit))
   \(\Rightarrow\)
     declmng mng (VDecInitA ty loc (f (EX e0 se0)), s0)
                 ([VDecInitA ty loc (f (EX e se))], s)
\end{alltt}
  \end{minipage}
\end{center}

A variable declaration of reference type is ready to ``fire'' when its
initialising expression has reduced to an l-value, and when there are
no remaining side effects in the side effect record.  At this point,
the variable address map in the state is updated to point at the
l-value's address, and the type map is also updated to make the type
of the name the same as the type of the l-value.
This step is controlled by the rule \ruleid{decl-vdecinit-finish-ref},
for which see Figure~\ref{fig:decl-vdecinit-finish-ref}.
\begin{figure}[hbtp]
\begin{center}
  \begin{minipage}{\textwidth}
\index{rule (declaration dynamics)!decl-vdecinit-finish-ref@\texttt{decl-vdecinit-finish-ref}}%
\begin{alltt}
(* RULE-ID: decl-vdecinit-finish-ref *)
(* if isSome, aopt is the address of a containing class *)
     is_null_se se \(\land\)
     ((f = CopyInit) \(\lor\) (f = DirectInit)) \(\land\)
     (if class_type ty1 then
        (s0,\lbr\rbr) |- dest_class ty1 casts p into p'
      else (p' = p)) \(\land\)
     (s = new_addr_binding refnm aopt (a,dest_class ty2,p') s0)
   \(\Rightarrow\)
     declmng mng
             (VDecInitA (Ref ty1)
                        (RefPlace aopt refnm)
                        (f (EX (LVal a ty2 p) se)), s0)
             ([], s)
\end{alltt}
  \end{minipage}
\end{center}
\caption{How References are Initialised}
\label{fig:decl-vdecinit-finish-ref}
\end{figure}




\subsection{Polymorphism \& Multiple Inheritance}
\label{sec:multiple-inheritance}

As suggested in earlier deliverables, multiple inheritance has been
modelled by following the approach described in Wasserrab \emph{et
  al}~\cite{wasserrab-nst-OOPSLA06}.  The changes supporting this
addition to the model are relatively minor and almost all appear in
the theory \texttt{class_info}, where a number of new definitions
appear.

\newcommand{\Cs}{\mathit{Cs}} \newcommand{\fld}{\mathit{fld}}

At the top level, the rule for calculating the function that will be
called dynamically (\ruleid{function-member-select}) has changed
slightly.  It now reads
\[
\infer{
  \begin{array}{l}
    \statebrack{\textsf{Ex}((\clvalue(a,\texttt{Class}\;C,\Cs))\;\mathbf{.}\;
      \fld,\mathit{se}),\sigma} \rightarrow \\
    \qquad\left\langle\textsf{Ex}\left(\cfvalue\left(
        \begin{array}{l}
          \texttt{MFn}\;(\last(\Cs'))\;\fld,\\
          (\funtype{\mathit{argtys}}{\mathit{dynret}}),\\
          \SOME{(\clvalue\;a\;(\texttt{Class}\;C)\;\Cs')}
        \end{array}\right),
      \mathit{se}\right),\sigma\right\rangle
  \end{array}}{
  \begin{array}{c}
    \sigma \vdash \last(\Cs) \textrm{ has least method } \fld :
    \funtype{\mathit{statargs}}{\mathit{statret}} \textrm{ via } Ds \\
    \sigma \vdash (C,\Cs \,@_p\, Ds) \textrm{ selects } \fld :
    \funtype{\mathit{dynargs}}{\mathit{dynret}} \textrm{ via } \Cs'
  \end{array}}
\]
This rule describes how the call to method $\fld$ is resolved
for an object located at address $a$, with dynamic type $C$, and where
the static type of the object is the last element of the list $\Cs$.
The list $\Cs$ is also a path through the class hierarchy, starting at
the dynamic type and ending at the current static type.  (Note that an
object's dynamic type is determined on object creation, and persists
for an object's entire life-time.  In contrast, an object's static
type is the type ascribed to it by a particular piece of code.
Different pieces of code may well ``see'' the same object as having
different types.  In this sense, an object's dynamic type is
unchanging, but it will have a variety of static types across the text
of a program.  Confusing, but true!)

The first premise (``has-least-method'') examines the static type of
the object for which the method will be called, $\last(\Cs)$.
Starting at that point in the hierarchy it looks upwards (\ie, towards
base classes) for the nearest base class that provides an
implementation of the desired method.  This base-class might be
$\last(\Cs)$ itself, in which case the path found ($Ds$) will be
empty.  There must also be a unique closest ancestor providing the
desired method.  If this isn't the case, then there will have been a
compile-time error, as the call will be statically ambiguous.

The second premise (``selects-via'') then determines the dynamic
location of the desired method.  There are two cases.  The simple case
is when there is a unique best method for the dynamic type, $C$.
Imagine, for example, that there is a four-element singly-linked
inheritance graph, from base $B_0$ down to most-derived $B_3$, with
implementations of the method $\fld$ at $B_0$ and $B_2$.  If the
object is actually of type $B_3$, but is statically seen as type
$B_1$, then $C$ is $B_3$, and $\Cs$ will be $[B_3,\,B_2,\,B_1]$.  The
first premise (``has-least-method'') determines that, starting at
$B_1$ (the static type) there is an implementation of $\fld$ at path
$[B_1, B_0]$.  This will be the instantiation of the rule's variable
$Ds$.

The simple case for ``selects-via'' checks whether or not there is
also a least method for the dynamic type (ignoring, for the moment,
the path giving the static type).  Thus
\[
\infer{\sigma \vdash (C,\Cs) \textrm{ selects } \fld \textrm{ via } \Cs'}{\sigma \vdash C \textrm{ has least method } \fld :
  \funtype{\mathit{argtys}}{\mathit{retty}} \ \textrm{ via } \Cs'}
\]
In the simple example, we will thus conclude that \[
\sigma \vdash (B_3,[B_3,B_2,B_1,B_0]) \textrm{ selects } \fld
\textrm{ via } [B_3,B_2]
\]
so that the call will be to the implementation of $\fld$ in $B_2$, and
the \texttt{this} pointer will be adjusted so that the type and path
information associated with its value will be $(B_3,[B_3,B_2])$ (a
dynamic type of $B_3$, as always, and a static type of $B_2$).

The same rule applies in a much more complicatd seeming situation,
where multiple inheritance and shared base objects come into play.
Consider the program in Figure~\ref{fig:diamond-cpp}.  When the call
to \texttt{cref.f()} is made, the type and path associated with the
reference will be $(D,[D,C_1])$.  Statically, the reference is a
\texttt{C1} value, but dynamically, it's really of class
\texttt{D}. The first premise in rule \ruleid{function-member-select}
finds that there is a path ($\mathit{Ds}$ in the rule) which is
appropriate for \texttt{f}.  This path is $[B]$.  The fact that the
path does not include the derived object's name, and is just a bare
reference to a class indicates that it is a path to a shared base.
When such a path is the second argument of path concatenation (the
$@_p$ operator in the second premise), the result is just the second
argument, so that the second hypothesis in the rule becomes
\[
\sigma \vdash (D,[B]) \textrm{ selects } f :
\funtype{\texttt{void}}{\texttt{int}} \textrm{ via } \Cs'
\]
\begin{figure}[hbtp]
\begin{verbatim}
#include <iostream>

class B {
public:
  virtual int f() { std::cout << "B's f\n"; return 3; }
  virtual ~B() { }
};

class C1 : virtual public B {
};

class C2 : virtual public B {
public:
  virtual int f() { std::cout << "C2's f\n"; return 4; }
};

class D : public C1, public C2 {
};

int dosomething(C1 &cref)
{
  return cref.f();
}

int main()
{
  D d;
  return dosomething(d);
}
\end{verbatim}
\caption{Multiple inheritance with shared base objects.  (This program is
in the \texttt{notes} directory with name \texttt{diamond-multinherit.cpp}.)}
\label{fig:diamond-cpp}
\end{figure}

The first, simple, rule for ``selects-via'' resolves this.  Ignoring
the path $[B]$, the simple rule checks whether or not there is a
unique least path to an \texttt{f} from $D$.  There is such a path,
and it is $[D,C_2]$.  So, the call to \texttt{cref.f()} ends up being
a call to the \texttt{f} in class $C_2$, in an ``unrelated'' part of
the object hierarchy.
\[
\rule{0.2\textwidth}{.1mm}
\]

For those situations where there is not a unique path from the dynamic
type to a best selection, there is another more complicated rule
defining ``selects-via''.  In Figure~\ref{fig:lopsided-v}, the
inheritance hierarchy looks like
\[
\psset{rowsep=3ex,nodesep=2mm,colsep=2em}
\begin{psmatrix}
\texttt{\psframebox{B}} \\
\texttt{Left1}\\
\texttt{\psframebox{Left2}} & & \texttt{\psframebox{Right}}\\
& \texttt{D}
\end{psmatrix}
\ncline{1,1}{2,1}
\ncline{2,1}{3,1}
\ncline{3,1}{4,2}
\ncline{3,3}{4,2}
\]
where the boxed class names are those that implement the function
\texttt{f}.  The question is which \texttt{f} will be called when the
dynamic type is \texttt{D}, and when the static type is
\texttt{Left1}.  There is no unique, least implementation of
\texttt{f} visible from the dynamic type (\texttt{D}), so the simple
rule does not apply.  Instead, the notion of \emph{overrider} is
introduced via the rule
\[
\infer{\sigma\vdash (C,\Cs) \textrm{ selects }\fld : m \textrm{ via }
  \Cs'}{
\begin{array}{c}
  \forall m\;\Cs'. \;\;\neg \;\sigma \vdash C \textrm{ has least }\fld : m
\textrm{ via } \Cs'\\
\sigma \vdash (C,\Cs) \textrm{ has overrider } \fld : m \textrm{ via }
\Cs'
\end{array}}
\]
where the static type of the value again plays a role.  In this case,
the \texttt{f} that gets called is that in \texttt{Left2}.  For
further details on exactly how this is defined, see either
\texttt{class_infoScript}, or
Wasserab~\emph{et~al}~\cite{wasserrab-nst-OOPSLA06}.

\begin{figure}[hbtp]
\begin{verbatim}
#include <iostream>

class B {
public:
  virtual void f() { std::cout << "B's f\n"; }
  virtual ~B() { }
};

class Left1 : public B { };

class Left2 : public Left1 {
public:
  virtual void f() { std::cout << "Left2's f\n";  }
};

class Right {
public:
  virtual void f() { std::cout << "Right's f\n"; }
  virtual ~Right() { }
};

class D : public Left2, public Right { };

void dosomething(Left1 &l1ref) { l1ref.f(); }

int main()
{
  D d;
  // d.f();  would be statically ambiguous
  dosomething(d);
  return 0;
}
\end{verbatim}
\caption{A lop-sided `V' inheritance hierarchy.  Available as
  \texttt{notes/lopsided-v.cpp}.}
\label{fig:lopsided-v}
\end{figure}

\subsection{Object Lifetimes}
\label{sec:object-lifetimes}

\paragraph{Constructors}
Handling constructors has easily wrought the greatest change to the
simple C model.  The basic approach taken has been to encode as much
as possible with ``evolving syntax''.  Just as \texttt{while} can be
modelled by having
\[
\texttt{while}\;\texttt{(}G\texttt{)}\;\mathit{body}
\] become \[
\texttt{if}\;\texttt{(}G\texttt{)}\;\texttt{\{}\mathit{body}\texttt{;}\;\texttt{while}\;\texttt{(}G\texttt{)}\;\mathit{body} \texttt{\}}
\]
so too do calls to \cpp{} constructors create new programs ``in
place''.  The advantage of this approach is that there is less need
for relatively complicated state to be recorded in yet more fields in
the big record type \texttt{state} (see Figure~\ref{fig:state-type}).
Instead, programs can unfold into more elaborate forms directly.  The
disadvantage of this approach is that the original syntax may not
support enough forms, requiring new special syntax to be created, or
for existing forms to be extended with new parameters.

\index{Block@\texttt{Block}}
The existing handling of block-statements is an example of this latter
disadvantage.  In particular, the abstract syntax has a constructor
\texttt{Block} with type
\begin{verbatim}
   : bool -> decl list -> stmt list
\end{verbatim}
where the boolean flag indicates whether or not the block has been
entered yet.  In this way, the abstract syntax has values in it that
can't be written down in the concrete syntax.  (Simiarly, the original
thesis model for C included the \texttt{RVR} constructor and the
$\hat{f}$ intermediate form for function calls.)

Constructors are intimately tied up with declarations and
initialization.  In the simple C world, a variable comes into being in
two stages.  First space in memory is allocated for the variable
(whether on the stack or heap), and the variable name is associated
with that space for the span of the variable's life.  Then there is an
optional initialization phase, when the piece of memory associated
with the variable space is filled in with some value.

The \cpp{} model is similar.  All new objects (but not references)
must be associated with some new space.  Then they may or may not be
initialised.  Additionally, in \cpp{}, an object that is only
declared, and which does not appear to be initialised, will actually
have its default constructor called.

The abstract syntax supporting this is all defined in
\HOLfile{statements}:

\begin{center}
\begin{tabular}{lll}
Constructor & Argument Types & Description\\
\hline
\texttt{VDec} & $\mathit{name},\mathit{type}$ & no initialization\\
\texttt{VDecInit} &
$\mathit{name},\mathit{type},\mathit{initializer}$ &
initialization (unallocated) \\
\texttt{VDecInitA} &
$\mathit{varlocation},\mathit{type},\mathit{initializer}$ &
initialization (space allocated)
\end{tabular}
\end{center}

For example, when a class is declared with no explicit initialization
of any sort, meaning that the default constructor will be called, the
syntax moves through all three stages.  The abstract syntax
corresponding to something like
\begin{verbatim}
{
   classname c;
   ...
}
\end{verbatim}
will be \texttt{VDec "c" classname}.  Because this is a class type,
rule \ruleid{decl-vdec-class} will fire (and can do so immediately),
and the declaration will become \texttt{VDecInit "c" classname init},
where the form of \texttt{init} will encode the fact that a direct
initialization is being performed, and that there are no arguments.
Then the rule \ruleid{decl-vdecinit-start-evaluate-direct-class}
fires.  Side conditions of this rule cause space to be allocated (at
address \texttt{a}), the state's maps from names to addresses be
updated, and for the construction of the class to be recorded so that
it can be destroyed later.

The syntax also evolves to become
\begin{verbatim}
   VDecInitA classname (ObjPlace a) init'
\end{verbatim}
where the new initializer records that a function call to a
constructor is about to happen, and where that construction will
happen (\ie, \texttt{init'} includes a reference to \texttt{a}).

There are three forms of initializer.  The first two are
\texttt{DirectInit0} and \texttt{DirectInit} and correspond to direct
initialization~\cite[\S 8.5 paragraph 12]{cpp-standard-iso14882}.  The
\texttt{DirectInit0} constructor takes as arguments a list of
expressions.  In this way, concrete syntax such as
\begin{verbatim}
{
  Classname c(x,&y,z+1);
}
\end{verbatim}
is directly modelled.  (When the rule \ruleid{decl-vdec-class} fires,
the newly created \texttt{DirectInit0} constructor takes an empty list
of arguments.)

The \texttt{DirectInit} constructor takes one argument, an ``extended
expression'', which will initially be an expression constructed by an
application of the special constructor
\texttt{ConstructorFVal}\index{ConstructorFVal@\texttt{ConstructorFVal}}
to the same argument list.  This form needs to be an extended
expression so that the body of the constructor (a statement) can be
entered.

The other form of initializer is constructed by the function
\texttt{CopyInit}.  This corresponds to the syntax
\begin{verbatim}
{
  type varname = expression;
  ...
}
\end{verbatim}
which is a
copy-initialization~\cite[\emph{ibid}]{cpp-standard-iso14882}.  When
the type of the new object is not a class, there is no difference
between copy-initialization and direct-initialization, reflected in
the rule \ruleid{decl-vdecinit-start-evaluate-direct-nonclass}, which
moves from a \texttt{DirectInit0} to a \texttt{CopyInit} initializer.

When a \texttt{CopyInit} initializer completes its evaluation,
yielding a value, that value be copied across into the space earlier
allocated for the object.  For non-class types this is done with the
same \texttt{val2mem} helper function that is used to apply side
effects.  For class types, this copying must be performed by a call to
the copy constructor.

\paragraph{Constructor Calls}
The expression form corresponding to a constructor call uses the
expression form for function applications, but with a special form in
the place of the function value.  This allows the normal evaluation of
function applications (with the unspecified order of evaluation of
arguments, for example).  The function value position is filled by a
new abstract syntactic form
\texttt{ConstructorFVal}.\index{ConstructorFVal@\texttt{ConstructorFVal}}
This takes three parameters:
\begin{itemize}
\item a boolean indicating whether or not the constructor is being
  called for a most-derived object or not;
\item the address of the space which the constructor is to operate
  over; and
\item the name of the class that is being constructed
\end{itemize}
So, if a declaration is made of the form
\begin{verbatim}
{
   class v(x);
}
\end{verbatim}
then, once sufficient space is allocated for the new object \texttt{v}
(at address \texttt{a}, say), the abstract syntax will look like
\begin{alltt}
   VDecInitA (Class \(\mathit{cnm}\))
             (ObjPlace a)
             (DirectInit
                (EX (FnApp (ConstructorFVal T a \(\mathit{cnm}\))
                           [Var "x"])
                    base_se))
\end{alltt}
where $\mathit{cnm}$ is the identifier corresponding to the class
\texttt{class}.

The \texttt{ObjPlace} constructor is used to distinguish this from the
situation where a reference is being initialised.  The \texttt{EX}
constructor specifies that the current form is an expression (as
opposed to the statement that will be in this position once the
constructor body is entered).  The \texttt{base_se} value is the empty
side-effect record.  This will evolve as references to and updates of
memory occur.

Once the parameters to the constructor have been evaluated, the
constructor body can be entered.  This happens in rule
\ruleid{constructor-function-call}, for which see
Figure~\ref{fig:constructor-function-call}.
\begin{figure}[htbp]
\begin{center}
\begin{minipage}{\textwidth}
\index{rule (dynamic)!constructor-function-call@\texttt{constructor-function-call}}%
\begin{alltt}
(* RULE-ID: constructor-function-call *)
     find_constructor_info s0 cnm args params mem_inits body \(\land\)
     (pdecls = MAP (\(\lambda\)((n,ty),a).
                        VDecInit ty (Base n)
                                    (CopyInit (EX a base_se)))
                   (ZIP (params, args))) \(\land\)
     (SOME this = ptr_encode s0 a (Class cnm) [cnm]) \(\land\)
     (cpfx = construct_ctor_pfx s0 mdp a cnm mem_inits) \(\land\)
     (newstmt =
        if is_catch body then
          let (bod,handlers) = dest_catch body
          in
            Block T pdecls
              [Catch (Block F cpfx [bod])
                     (MAP (\(\lambda\)(e,st).
                             (e, Block F [] [st; Throw NONE]))
                          handlers)]
        else Block T (pdecls ++ cpfx) [body])
   \(\Rightarrow\)
     mng (s0, EX (FnApp_sqpt (ConstructorFVal mdp subp a cnm)
                             args) se0)
         (s0 with <| thisvalue :=
                       SOME (ECompVal this (Ptr (Class cnm)));
                     stack updated_by
                       (CONS (s0.env, s0.thisvalue));
                     blockclasses updated_by stackenv_newscope;
                     exprclasses updated_by stackenv_newscope;
                     env := empty_env |>,
          ST newstmt (RVC (\(\lambda\)e. ConstructedVal subp a cnm)
                          se0))
\end{alltt}
    \end{minipage}
  \end{center}

  \caption{Making a call to a class constructor}
\label{fig:constructor-function-call}
\end{figure}
The basic rule is complicated enough, and there is more complexity
hidden behind the auxiliary functions and relations.  The first
auxiliary is the relation \texttt{find_constructor_info}, which
appears in the rule's first hypothesis.  This relation treats its
first three parameters (\texttt{s0}, \texttt{cnm} and \texttt{args})
as inputs.  These are the current state, the name of the class being
constructed, and the actual arguments being passed to the constructor.
The remaining arguments to the relation are ``outputs''.  The variable
\texttt{params} is the list of formal parameters (names and types).
The variable \texttt{mem_inits} is the list of ``mem-initializers''
(see~\cite[\S12.6.2]{cpp-standard-iso14882}) associated with the
constructor, and \texttt{body} is the constructor's body.  The
\texttt{find_constructor_info} auxiliary is responsible for resolving
which constructor needs to be called, based on the types of the actual
arguments.

The second hypothesis of the rule constructs the sequence of variable
declarations corresponding to the parameters, using standard
functional programming auxiliaries \texttt{MAP} and \texttt{ZIP}.
Parameter passing is just like variable declaration\footnote{This does
  away with the \textsf{Cholera} approach which had a number of
  auxiliary relations effectively duplicating what occurred in
  variable declaration}, and so the model's existing treatment of
declarations can be re-used to set up the binding between formal names
and actual values.  Note that the expressions that initialise the
parameters have already been fully evaluated, so that there will be no
expression evaluation done when the declarations come to be evaluated
(except for any class construction that may be called for).

The third hypothesis calculates a value for the \texttt{this} value.
The dynamic and static type of the \texttt{this} pointer will be the
same (as the pair $C$ and $[C]$ are passed to \texttt{ptr_encode}),
and thus there will not be any polymorphic dispatch to functions in
derived classes if any virtual functions are called in the constructor
bodies.

The fourth hypothesis constructs a \texttt{cpfx} of declaration calls
to initialise class members and bases.  This is all done in the
complicated function \texttt{construct_ctor_pfx} (defined in
\texttt{dynamicsScript}).  This constructs a sequence of declarations
to initialise the non-static members of the new class, and the class's
immediate bases.  The mem-initializers are consulted to see what
initializers should be provided.  (If a mem-initializer is not
provided for a given member or base, then that object will be value-
or default-initialized; see~\cite[\S12.6.2, paragraphs
3--4]{cpp-standard-iso14882}.)

For example, in Figure~\ref{fig:mem-inits}, before class \texttt{C}'s
constructor body is even entered, the parameters \texttt{cptr} and
\texttt{i} need to be declared and initialised with actual values.
Subsequently, all of \texttt{C}'s immediate bases (just \texttt{B} in
this case) need to be constructed, followed by its members
(\texttt{ptr} and \texttt{sz}).  Note that while the paramters need to
have space allocated for them, the bases and members do not (because
the space for the entire object was allocated at the \texttt{VDecInit}
stage).

\begin{figure}[htbp]
\begin{verbatim}
#include <cstring>

class B {
  int x;
public:
  B(int i) : x(i) {}
};

class C : public B {
  char *ptr;
  int sz;
public:
  C(char *cptr, int i)
    : B(cptr[i]), ptr(cptr), sz(strlen(cptr)) { }
};
\end{verbatim}
\caption{\cpp{} constructors with \emph{mem-initializers}.  (Available
as \texttt{notes/mem-inits.cpp}.)}
\label{fig:mem-inits}
\end{figure}

Assume that the constructor has been called with parameters \texttt{x}
and \texttt{y}, and that these have evaluated to values \texttt{xval}
and \texttt{yval}. The sequence of declarations that are constructed
to precede the constructor body is given in
Figure~\ref{fig:constructor-vdecs}. The first two declarations are of
the parameters.  The next constructs the base \texttt{B}, and the last
two construct the non-static members.  The body of
\texttt{construct_ctor_pfx} is responsible for calculating the offsets
of the members (given as \texttt{Boff}, \texttt{ptroff} and
\texttt{szoff} in the figure.

\begin{figure}[hbtp]
\begin{verbatim}
  VDecInit (char *) cptr (CopyInit (NormE xval base_se))
  VDecInit int      i    (CopyInit (NormE yval base_se))

  VDecInitA B (ObjPlace (a + Boff))
              (DirectInit
                 (NormE
                    (FnApp (ConstructorFVal F (a + Boff) B)
                           [Deref(Plus (Var "cptr")
                                       (Var "i"))])
                    base_se))

  VDecInitA (char *) (ObjPlace (a + ptroff))
                     (CopyInit (NormE (Var "cptr") base_se))
  VDecInitA int      (ObjPlace (a + szoff))
                     (CopyInit (NormE (FnApp (Var "strlen")
                                             [Var "cptr"])
                                      base_se))
\end{verbatim}
\caption{The variable declarations constructed to precede the body of
  C's constructor (from Figure~\ref{fig:mem-inits}).}
\label{fig:constructor-vdecs}
\end{figure}

Note how the first argument of the \texttt{ConstructorFVal} form in
the construction of the base \texttt{B} is false; this is because
\texttt{B} is not the most-derived object.  If there were any shared
bases in the example, the most-derived object would be ``responsible''
for constructing them (see~\cite[\S12.6.2, paragraph
5]{cpp-standard-iso14882}).  If \texttt{C} had any non-static members
of class type, then these would be constructed with their
$\mathit{mdp}$ flag set to true.

When the constructor for the base class \texttt{B} comes to be called,
it will in turn initialise its members.  The constructor for
\texttt{B} is called with an argument (\texttt{cptr[i]}) that needs to
be evaluated in the context where the parameters are in scope, so it
is clear that the declarations for the parameters must come before the
base and member initialisations.

\paragraph{Object Destruction}
When an object of class type is first declared (with a
\texttt{VDecInit} form), it has memory allocated sufficient to contain
the new class in its entirety (including sub-objects).  This
allocation is reflected in the state's \texttt{allocmap}.  When the
block in which this declaration was made is left, this allocation is
forgotten.  At the same time, the destructor for the object must be
called.  This is modelled with the
\texttt{blockclasses} field of the state.%
\index{blockclasses (state field)@\texttt{blockclasses} (\texttt{state} field)}%
This is of type
\begin{verbatim}
   : constructed list list
\end{verbatim}
Where the type \texttt{constructed} is defined (see \HOLfile{states})
as
\begin{verbatim}
   constructed = NormalConstruct of construction_locn
               | SubObjConstruct of construction_locn
\end{verbatim}
and \texttt{construction_locn} is an abbreviation for
\begin{verbatim}
   :addr # CPP_ID # CPP_ID list
\end{verbatim}
The address is the address of the object which is to be destroyed, and
the two remaining are the class name and path which serve to identify
the object's type.  The inner list constructor of the type of
\texttt{blockclasses} reflects the fact that multiple objects may be
declared at the same scope level.  The outer list constructor appears
because of the stack discipline necessary for multiple nested scopes.

When an object of class type is declared, the rule responsible
(\ruleid{decl-vdecinit-start-evaluate-direct-class}) both allocates
the necessary memory, and adds address and type information for all of
the object's sub-classes and members (not just immediate bases, but
doing a complete traversal of the inheritance graph) to the
\texttt{blockclasses} field.  This is done by the
\texttt{update_blockclasses} relation defined in
\texttt{class_infoScript}.  The object information has to be added
to the list in the correct order so that objects will be destroyed in
reverse order of construction.

The rule for exitting from a block is then adjusted so that it can
only occur if the current scope's \texttt{blockclasses} information is
empty.  As long as it is not empty, the destructor corresponding to
the object on the top of the stack is set up to be called.  This is
done in rule \ruleid{block-exit-destructors-to-call}:
\begin{center}
  \begin{minipage}{\textwidth}
\begin{alltt}
(* RULE-ID: block-exit-destructors-to-call *)
     (s0.blockclasses = destroy_these :: bcs) \(\land\)
     \(\neg\)(destroy_these = []) \(\land\)
     final_stmt st c \(\land\)
     ((destcalls, s) =
        realise_destructor_calls (exception_stmt st) s0)
   \(\Rightarrow\)
     mng (s0, ST (Block T [] [st]) c)
         (s, ST (Block T [] (destcalls ++ [st])) c)
\end{alltt}
  \end{minipage}
\end{center}
This is another example of evolving syntax: the block that the flow of
control is about to leave, has this departure deferred with the
insertion of new statements before the block's final statement.  The
rule allowing an exit to eventually occur is \ruleid{block-exit}:
\[
\infer{
  \statebrack{
    \textsf{St}(\texttt{Block}\;\top\;[]\;[\mathit{st}], c), \sigma_0}
  \longrightarrow
  \statebrack{\textsf{St}(\mathit{st}, c), \sigma}
}{
  \begin{array}{l}
    \sigma_0.\texttt{stack} =
    (\mathit{stm},\mathit{tym},\mathit{vrm},\mathit{this}) ::
    \mathit{stk}
    \\
    \texttt{final_stmt}\;\mathit{st}
    \\
    \sigma_0.\texttt{blockclasses} = [] :: \mathit{bcs}
    \\
    \sigma = \sigma_0 \textrm{ with } \left\langle\begin{array}{ll}
        \texttt{stack := }\mathit{stk}; &
        \texttt{classmap := }\mathit{stm};\\
        \texttt{typemap := }\mathit{tym}; &
        \texttt{varmap := }\mathit{vrm};\\
        \texttt{thisvalue := }\mathit{this}; &
        \texttt{blockclasses := }\mathit{bcs}
      \end{array}\right\rangle
  \end{array}
}
\]
The predicate \texttt{final_stmt} is true of a statement if it is
an abnormal exit form (such as \texttt{break} or \texttt{return}), or
simply \texttt{EmptyStmt}.

Actually calling a destructor is straightforward because there are no
parameters, nor anything comparable to the mem-initializers.  The
requirement in the standard that sub-objects be destroyed before the
body of a destructor is entered is handled by the fact that the
sub-object information is entered into the \texttt{blockclasses} stack
ahead of the final encompassing object.

\section{Validation}
\label{sec:validation}

The deliverable includes a directory \texttt{holsrcs/testfiles}.  In
this directory there is some preliminary work towards the creation of
a symbolic evaluator, for demonstrating that programs in the model can
behave as one might expect.  This work builds on the ideas
in~\cite{netsem:popl2006}, allowing symbolic exploration of a semantic
definition that features non-deterministic branching.  For the moment,
the code only handles a sequence of external declarations not
requiring any expression evaluation, which is very minimalist.

This tool requires some sort of parser for \cpp{} source code, as
having to write out abstract syntax trees by hand is a major
annoyance.  It's possible that the front-end of \texttt{g++} might be
usable in this regard.


\section{Omissions and Possible Fixes}
\label{sec:omissions}

The most significant omission in this semantics is a treatment of
overloading.  This is a complicated feature of the language, but one
that is purely syntactic, and one that is checked and resolved
entirely by the compiler.  If this semantics were to handle
overloading, it would be done in Phases~1~(Name Resolution) and
Phase~2~(Templates).  There a call to a bare \texttt{f} would
ultimately turn into a call into the \texttt{f} whose parameters'
types best matched the types of the actual arguments.  This resolved
call would then be to an exact name and type combination, so that
\texttt{f} might become \texttt{::ns::f(int,char)} for example.

Similarly, there is no treatment of operator overloading.  Again, any
modelling of this feature would naturally occur in Phases~1 and~2,
where calls to operators such as \texttt{+} would be resolved into
calls to functions over particular types, in particular namespaces and
classes.

Two other large omissions in the realm of statics are \texttt{const},
and protection statuses.  In general, the \texttt{const}-ness of an
expression influences the selection of particular functions to call
(more name resolution), and can prevent certain expressions from being
written at all.  These latter constraints are an important part of the
practice of programming with \cpp{}, but again, are checked by the
compiler.  The semantics does model the fact that it is undefined
behaviour to update memory that has been declared as \texttt{const}.


Protection statuses (\ie, the designation of certain fields or base
classes as being \texttt{public}, \texttt{protected} or
\texttt{private}), are similarly a static mechanism, and have almost
no impact on the dynamics of a program.  (They make a difference to
the behaviour of \texttt{dynamic_cast}, and to the dynamic
type-matching that is done in exception handlers.)  I feel that all of
these omissions are justified given the commission to prefer treatment
of dynamics rather than static issues.

I believe the most significant dynamic omission is the failure to
support class r-values.

Other language features completely ignored are: enumerated types,
unions, and the \texttt{goto} and \texttt{switch} statements.  Also,
while I provide a rule for post-increment \texttt{++}, there is no
rule for \texttt{--}.

\section{Future}

The final deliverable calls for sanity theorems, namespaces, run-time
type identification and library functions.  All of these save the last
are strightforward.  It is now not clear to me what is meant by
``library functions''; whether actual functions are to be specified,
or whether this is a reference to the mechanisms for linking to
library functions (paragraph three of \S3 of the Statement of Work).

\begin{center}
\rule{0.5\textwidth}{.1mm}
\end{center}

\appendix
\section{Sources}
\label{sec:sources}

The deliverable consists of a compressed \texttt{tar}-file, that when
unpacked consists of a directory called \texttt{qinetiq-cpp}, which in
turn contains four directories
\begin{itemize}
\item \texttt{holsrcs}, containing the HOL source files of the
  mechanisation.  These files will build with the version of HOL4
  present in the CVS repository at SourceForge, with timestamp
  \texttt{2007-05-30 00:00Z}.  See Section~\ref{sec:getting-hol}
  below for instructions on how this version of HOL can be retrieved,
  and how the deliverable's HOL source files can then be built and
  checked.
\item \texttt{talks}, containing the \LaTeX{} source and a PDF for the
  talk presented at the DARP meeting in Newcastle in April 2006.  The
  source assumes that the \texttt{latex-beamer} and \texttt{PSTricks}
  packages are available.
\item \texttt{docs}, containing \LaTeX{} sources and a PDF version of
  this document, as well as sources for the notes on the earlier
  deliverables (nos.~1--4).
\item \texttt{notes}, some \cpp{} source files that illustrate various
  aspects of \cpp{} behaviour.  An accompanying text file explains some
  of the behaviours.
\end{itemize}

\subsection{Building HOL Source-Files}
\label{sec:getting-hol}

\paragraph{Getting HOL From SourceForge}

To get a particular, dated, version of the HOL4 sources from the CVS
repository, one must first issue the command

{\small
\begin{verbatim}
   cvs -d:pserver:anonymous@hol.cvs.sourceforge.net:/cvsroot/hol login
\end{verbatim}
}

When prompted for a password, just press \texttt{Enter} to send a null
response.  The check-out of source code from SourceForge can now
proceed.  The source code fits into 60MB.  Issue the command

{\small
\begin{alltt}
   cvs \textit{repository-spec} co -D \textit{date} hol98
\end{alltt}
}

\noindent where \textit{\ttfamily repository-spec} is the string

{\small
\begin{alltt}
   -d:pserver:anonymous@hol.cvs.sourceforge.net:/cvsroot/hol
\end{alltt}
}

\noindent (also used in the \texttt{login} command), and where
\textit{\ttfamily date} is the desired date, best specified as an
ISO~8601 string enclosed in double-quotes.  For example,
\texttt{"2007-05-30 00:00Z"}.

Once a copy of the sources have been downloaded, further commands can
be used to update this copy to correspond to different dates.  As long
as such commands are issued from within the \texttt{hol98} directory,
the repository specification can be omitted.  The update command is

{\small
\begin{alltt}
   cvs update -d -D \textit{date}
\end{alltt}
}

\paragraph{Installing HOL} Once the sources have been downloaded, the
installation instructions from the page at
\url{http://hol.sourceforge.net} should be followed to build a copy of
HOL.  An installation of the Moscow~ML compiler (v2.01) will also be
required.

\paragraph{Building Deliverable Sources}
When HOL4 has been installed, the \texttt{Holmake} program (found in
the \texttt{hol98/bin} directory) can be run in the \texttt{holsrcs}
directory to create and check the logical theories.


\bibliographystyle{plain}
\bibliography{deliverables}

\printindex

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
